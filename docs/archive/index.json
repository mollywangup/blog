[{"content":"练一休一，熬夜一早睡一，工作日蹭公司三升水。\n","description":"Me","id":0,"section":"","tags":null,"title":"About","uri":"https://mollywangup.com/about/"},{"content":"练一休一，熬夜一早睡一，工作日蹭公司三升水。\n","description":"Me","id":1,"section":"zh","tags":null,"title":"About","uri":"https://mollywangup.com/zh/about/"},{"content":"Session 定义 官方定义详见 会话定义\n应用会话是指用户在安装后与应用进行交互的行为。\nSession 统计规则 触发机制 每次应用启动时判断，如果本次 Session 已累计超过 30 分钟，则触发一个新 Session 事件，否则不触发。具体规则如下图：\n数据存储 推荐占位符详见 会话回传\nplaceholders 定义 补充说明 last_session_time 上次会话时间戳 所有都生效 session_count 当前 Adjust SDK 记录的第 x 个会话 仅服务端事件不生效 lifetime_session_count 用户生命周期记录的第 x 个会话 所有都生效 last_time_spent 上次会话时长（秒） 仅 session 事件生效 time_spent 用户当前的会话时长（秒） 仅客户端事件生效（不包含 session 事件） 坑：安装和再归因，Dashboard 计 session，但原始数据未计。因此处理导出的原始数据时，需手动将其计入 session； 数据处理 计算平均停留时长 计算留存率 ","description":"Adjust 对 Session 的定义及统计规则。","id":2,"section":"posts","tags":["Adjust"],"title":"Session","uri":"https://mollywangup.com/posts/session/"},{"content":"Session 定义 官方定义详见 会话定义\n应用会话是指用户在安装后与应用进行交互的行为。\nSession 统计规则 触发机制 每次应用启动时判断，如果本次 Session 已累计超过 30 分钟，则触发一个新 Session 事件，否则不触发。具体规则如下图：\n数据存储 推荐占位符详见 会话回传\nplaceholders 定义 补充说明 last_session_time 上次会话时间戳 所有都生效 session_count 当前 Adjust SDK 记录的第 x 个会话 仅服务端事件不生效 lifetime_session_count 用户生命周期记录的第 x 个会话 所有都生效 last_time_spent 上次会话时长（秒） 仅 session 事件生效 time_spent 用户当前的会话时长（秒） 仅客户端事件生效（不包含 session 事件） 坑：安装和再归因，Dashboard 计 session，但原始数据未计。因此处理导出的原始数据时，需手动将其计入 session； 数据处理 计算平均停留时长 计算留存率 ","description":"Adjust 对 Session 的定义及统计规则。","id":3,"section":"zh","tags":["Adjust"],"title":"Session","uri":"https://mollywangup.com/zh/posts/session/"},{"content":"数据库 创建数据库 1 CREATE DATABASE test 删除数据库 1 DROP DATABASE test 数据表 CREATE 1 2 3 4 5 6 7 8 9 10 11 12 CREATE TABLE IF NOT EXISTS test.my_first_table ( `event_name` String, `created_at` DateTime, `user_id` UInt32, `country` String, `login_type` Nullable(Enum(\u0026#39;Google\u0026#39; = 1, \u0026#39;Facebook\u0026#39; = 2, \u0026#39;Apple\u0026#39; = 3, \u0026#39;Vistor\u0026#39; = 4)), `revenue_usd` Nullable(Float64) ) ENGINE = MergeTree PARTITION BY toYYYYMMDD(created_at) ORDER BY (created_at, event_name, user_id) SETTINGS index_granularity = 8192 DROP 1 DROP TABLE my_first_table INSERT 1 INSERT INTO my_first_table (*) VALUES (\u0026#39;install\u0026#39;, \u0026#39;2024-11-01 13:14:45\u0026#39;, 1000034, \u0026#39;SA\u0026#39;, 2, NULL) ALTER 1 2 3 4 5 6 7 8 9 10 11 12 -- 新增列 ALTER TABLE my_first_table ADD COLUMN status Nullable(UInt8) ALTER TABLE my_first_table ADD COLUMN city Nullable(String) AFTER country -- 修改列类型 ALTER TABLE my_first_table MODIFY COLUMN status Nullable(Enum(\u0026#39;离线\u0026#39; = 0, \u0026#39;忙碌\u0026#39; = 1, \u0026#39;空闲\u0026#39; = 2, \u0026#39;Live\u0026#39; = 3)) -- 修改列取值 ALTER TABLE my_first_table UPDATE login_type = 1 WHERE user_id = 1000034 -- 删除列 ALTER TABLE my_first_table DROP COLUMN city SELECT 查看分区 1 2 3 4 5 6 7 8 SELECT * FROM system.parts WHERE table = \u0026#39;my_first_table\u0026#39; ORDER BY partition DESC LIMIT 3 FORMAT Vertical 查询当前时区 1 SELECT timezoneOf(now()) 查看 Host 1 SELECT version(), hostName(), currentDatabase(), currentUser() 设置查询超时时长 1 SELECT COUNT(*) FROM my_first_table SETTINGS max_execution_time=1 检测是否存在某列 1 SELECT hasColumnInTable(\u0026#39;test\u0026#39;, \u0026#39;my_first_table\u0026#39;, \u0026#39;user_id\u0026#39;) 常用函数 字符串函数 1 SELECT splitByChar(\u0026#39;_\u0026#39;, \u0026#39;abc_def_12_\u0026#39;)[3] 日期时间函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 SELECT toDateTime(0), toDateTime(NULL), toDateTime(1713265060), fromUnixTimestamp(1713265060), toDateTime(1713265060, \u0026#39;Asia/Shanghai\u0026#39;), toDate(NOW(), \u0026#39;Asia/Shanghai\u0026#39;), toDateTime(NOW(), \u0026#39;Asia/Shanghai\u0026#39;), toHour(toDateTime(NOW(), \u0026#39;Asia/Shanghai\u0026#39;)), NOW() + INTERVAL 8 HOUR, -- 另一种转时区的方法 toUnixTimestamp(toDateTime(\u0026#39;2024-10-16 03:17:47\u0026#39;)) 其他函数 特点与坑 惊叹的好用 别名既方便，但也容易冲突。 1 2 3 SELECT now() AS x, toDate(x) 删除行记录 删除效率非常低，建议仅追加写入。 方法一：DROP PARTITION 1 ALTER TABLE my_first_table DROP PARTITION 20240418 方法二：DELETE FROM 1 DELETE FROM my_first_table WHERE created_at \u0026gt;= \u0026#39;2024-04-19\u0026#39; ","description":"大部分语法兼容 MySQL, 别名查询很方便也是个坑。","id":4,"section":"posts","tags":["ClickHouse"],"title":"学习笔记：ClickHouse","uri":"https://mollywangup.com/posts/notes-clickhouse/"},{"content":"数据库 创建数据库 1 CREATE DATABASE test 删除数据库 1 DROP DATABASE test 数据表 CREATE 1 2 3 4 5 6 7 8 9 10 11 12 CREATE TABLE IF NOT EXISTS test.my_first_table ( `event_name` String, `created_at` DateTime, `user_id` UInt32, `country` String, `login_type` Nullable(Enum(\u0026#39;Google\u0026#39; = 1, \u0026#39;Facebook\u0026#39; = 2, \u0026#39;Apple\u0026#39; = 3, \u0026#39;Vistor\u0026#39; = 4)), `revenue_usd` Nullable(Float64) ) ENGINE = MergeTree PARTITION BY toYYYYMMDD(created_at) ORDER BY (created_at, event_name, user_id) SETTINGS index_granularity = 8192 DROP 1 DROP TABLE my_first_table INSERT 1 INSERT INTO my_first_table (*) VALUES (\u0026#39;install\u0026#39;, \u0026#39;2024-11-01 13:14:45\u0026#39;, 1000034, \u0026#39;SA\u0026#39;, 2, NULL) ALTER 1 2 3 4 5 6 7 8 9 10 11 12 -- 新增列 ALTER TABLE my_first_table ADD COLUMN status Nullable(UInt8) ALTER TABLE my_first_table ADD COLUMN city Nullable(String) AFTER country -- 修改列类型 ALTER TABLE my_first_table MODIFY COLUMN status Nullable(Enum(\u0026#39;离线\u0026#39; = 0, \u0026#39;忙碌\u0026#39; = 1, \u0026#39;空闲\u0026#39; = 2, \u0026#39;Live\u0026#39; = 3)) -- 修改列取值 ALTER TABLE my_first_table UPDATE login_type = 1 WHERE user_id = 1000034 -- 删除列 ALTER TABLE my_first_table DROP COLUMN city SELECT 查看分区 1 2 3 4 5 6 7 8 SELECT * FROM system.parts WHERE table = \u0026#39;my_first_table\u0026#39; ORDER BY partition DESC LIMIT 3 FORMAT Vertical 查询当前时区 1 SELECT timezoneOf(now()) 查看 Host 1 SELECT version(), hostName(), currentDatabase(), currentUser() 设置查询超时时长 1 SELECT COUNT(*) FROM my_first_table SETTINGS max_execution_time=1 检测是否存在某列 1 SELECT hasColumnInTable(\u0026#39;test\u0026#39;, \u0026#39;my_first_table\u0026#39;, \u0026#39;user_id\u0026#39;) 常用函数 字符串函数 1 SELECT splitByChar(\u0026#39;_\u0026#39;, \u0026#39;abc_def_12_\u0026#39;)[3] 日期时间函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 SELECT toDateTime(0), toDateTime(NULL), toDateTime(1713265060), fromUnixTimestamp(1713265060), toDateTime(1713265060, \u0026#39;Asia/Shanghai\u0026#39;), toDate(NOW(), \u0026#39;Asia/Shanghai\u0026#39;), toDateTime(NOW(), \u0026#39;Asia/Shanghai\u0026#39;), toHour(toDateTime(NOW(), \u0026#39;Asia/Shanghai\u0026#39;)), NOW() + INTERVAL 8 HOUR, -- 另一种转时区的方法 toUnixTimestamp(toDateTime(\u0026#39;2024-10-16 03:17:47\u0026#39;)) 其他函数 特点与坑 惊叹的好用 别名既方便，但也容易冲突。 1 2 3 SELECT now() AS x, toDate(x) 删除行记录 删除效率非常低，建议仅追加写入。 方法一：DROP PARTITION 1 ALTER TABLE my_first_table DROP PARTITION 20240418 方法二：DELETE FROM 1 DELETE FROM my_first_table WHERE created_at \u0026gt;= \u0026#39;2024-04-19\u0026#39; ","description":"大部分语法兼容 MySQL, 别名查询很方便也是个坑。","id":5,"section":"zh","tags":["ClickHouse"],"title":"学习笔记：ClickHouse","uri":"https://mollywangup.com/zh/posts/notes-clickhouse/"},{"content":"挖坑中\u0026hellip;\n激活函数 为了在神经网络中将线性输出转化为非线性输出。\n结论：\n隐藏层建议使用 ReLU； 输出层根据预测值选择： 二分类问题：Sigmoid 多分类问题：Softmax 预测值非负问题：ReLU 预测值可正可负可零问题：Linear（即不使用激活函数） Linear 线性激活函数，也称作 no activation，本质上相当于没有使用激活函数。\n$$\nf(x) = x\n$$\n$$\nf\u0026rsquo;(x) = 1\n$$\nSigmoid 也称作 Logistic function，适用二分类问题。\n$$\nf(x) = \\frac{1}{1+e^{-x}} \\in (0,1)\n$$\n$$\nf\u0026rsquo;(x) = \\frac{e^{-x}}{(1 + e^{-x})^2} \\in (0,0.25)\n$$\ntanh $$\nf(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\in (-1, 1)\n$$\nReLU $$\nf(x) =\n\\begin{cases}\nx \u0026amp; \\text{if $x \\geq 0$} \\\\\n\\\\0 \u0026amp; \\text{if $x \u0026lt; 0$}\n\\end{cases} \\space\\space\\space \\text{or} \\space\\space\\space\nf(x) = \\max(0, x)\n$$\n$$\nf\u0026rsquo;(x) =\n\\begin{cases}\n1 \u0026amp; \\text{if $x \\geq 0$} \\\\\n\\\\0 \u0026amp; \\text{if $x \u0026lt; 0$}\n\\end{cases}\n$$\nSoftmax 适用多分类问题。\n$$\np(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{k}e^{x_j}}, 0 \u0026lt; p(x_i) \u0026lt; 1, \\sum_{i} p(x_i)= 1\n$$\n","description":"（挖坑中...）神经网络。","id":6,"section":"posts","tags":["Deep Learning","TensorFlow"],"title":"学习笔记：吴恩达深度学习","uri":"https://mollywangup.com/posts/notes-deep-learning/"},{"content":"挖坑中\u0026hellip;\n激活函数 为了在神经网络中将线性输出转化为非线性输出。\n结论：\n隐藏层建议使用 ReLU； 输出层根据预测值选择： 二分类问题：Sigmoid 多分类问题：Softmax 预测值非负问题：ReLU 预测值可正可负可零问题：Linear（即不使用激活函数） Linear 线性激活函数，也称作 no activation，本质上相当于没有使用激活函数。\n$$\nf(x) = x\n$$\n$$\nf\u0026rsquo;(x) = 1\n$$\nSigmoid 也称作 Logistic function，适用二分类问题。\n$$\nf(x) = \\frac{1}{1+e^{-x}} \\in (0,1)\n$$\n$$\nf\u0026rsquo;(x) = \\frac{e^{-x}}{(1 + e^{-x})^2} \\in (0,0.25)\n$$\ntanh $$\nf(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\in (-1, 1)\n$$\nReLU $$\nf(x) =\n\\begin{cases}\nx \u0026amp; \\text{if $x \\geq 0$} \\\\\n\\\\0 \u0026amp; \\text{if $x \u0026lt; 0$}\n\\end{cases} \\space\\space\\space \\text{or} \\space\\space\\space\nf(x) = \\max(0, x)\n$$\n$$\nf\u0026rsquo;(x) =\n\\begin{cases}\n1 \u0026amp; \\text{if $x \\geq 0$} \\\\\n\\\\0 \u0026amp; \\text{if $x \u0026lt; 0$}\n\\end{cases}\n$$\nSoftmax 适用多分类问题。\n$$\np(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{k}e^{x_j}}, 0 \u0026lt; p(x_i) \u0026lt; 1, \\sum_{i} p(x_i)= 1\n$$\n","description":"（挖坑中...）神经网络。","id":7,"section":"zh","tags":["Deep Learning","TensorFlow"],"title":"学习笔记：吴恩达深度学习","uri":"https://mollywangup.com/zh/posts/notes-deep-learning/"},{"content":"概率分布 二项分布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import numpy as np import matplotlib.pyplot as plt from scipy.stats import binom def runplt(n: int, p: float, ax: plt.axes, fmt=\u0026#39;yo\u0026#39;, color=\u0026#39;grey\u0026#39;): \u0026#39;\u0026#39;\u0026#39; 绘制单个二项分布的准备工作 \u0026#39;\u0026#39;\u0026#39; x = np.arange(n) y = [binom.pmf(x, n, p) for x in x] ax.plot(x, y, fmt, ms=5, mec=\u0026#39;black\u0026#39;, label=\u0026#39;p={}\\nn={}\u0026#39;.format(p, n)) ax.vlines(x, 0, y, lw=5, color=color, alpha=0.5) ax.vlines(x, 0, y, lw=1, color=color) ax.set_xticks([x for x in range(0, n + 2, 2)]) ax.legend(loc=\u0026#39;best\u0026#39;) def main(): \u0026#39;\u0026#39;\u0026#39; 绘制一组二项分布：参数对比 \u0026#39;\u0026#39;\u0026#39; # 参数 ns = np.array([[10, 10, 10], [10, 15, 20]]) ps = np.array([[0.1, 0.5, 0.7], [0.5, 0.5, 0.5]]) # 绘图 nrows = 2 ncols = 3 fig, axes = plt.subplots(nrows, ncols, figsize=(14, 7), sharey=True) for i in range(nrows): for j in range(ncols): runplt(ns[i, j], ps[i, j], axes[i, j]) fig.suptitle(\u0026#39;PMF of Binomial Distribution\u0026#39;) plt.savefig(\u0026#39;PMF-of-Binomial-distribution.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 泊松分布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import numpy as np import matplotlib.pyplot as plt from scipy.stats import bernoulli, binom, multinomial, poisson def main(): \u0026#39;\u0026#39;\u0026#39; 泊松分布 \u0026#39;\u0026#39;\u0026#39; # 三组参数 mus = [1, 4, 10] # 固定 x 的最大值 x_max = int(poisson.ppf(0.99, np.max(mus) + 2)) x = np.arange(x_max) fig, ax = plt.subplots() fmts = [\u0026#39;bo\u0026#39;, \u0026#39;ro\u0026#39;, \u0026#39;go\u0026#39;] colors = [c[0] for c in fmts] for mu, fmt, color in zip(mus, fmts, colors): # 数据 y = [poisson.pmf(x, mu) for x in x] # 绘图 ax.plot(x, y, fmt, ms=5, mec=\u0026#39;black\u0026#39;, label=\u0026#39;$\\lambda$ = {}\u0026#39;.format(mu)) ax.plot(x, y, c=color, alpha=0.5) ax.set_title(\u0026#39;$X \\sim Poisson(\\lambda)$\u0026#39;) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_ylabel(\u0026#39;$p(X=x)$\u0026#39;) ax.set_xticks([x for x in range(0, x_max, 5)]) ax.legend(loc=\u0026#39;best\u0026#39;, frameon=True) plt.savefig(\u0026#39;Poisson-distribution.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 高斯分布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm def main(): \u0026#39;\u0026#39;\u0026#39; 高斯分布 \u0026#39;\u0026#39;\u0026#39; # 三组参数 means = [0, 1, 0] variances = [1, 1, 0.5] x = np.linspace(-3, 4, 100) fig, ax = plt.subplots() for mean, variance in zip(means, variances): std = np.sqrt(variance) y = norm.pdf(x, loc=mean, scale=std) ax.plot(x, y, label=\u0026#39;$\\mu$={}, $\\sigma^2$={}\u0026#39;.format(mean, variance)) ax.set_title(\u0026#39;$X \\sim N(\\mu, \\sigma^2)$\u0026#39;) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_ylabel(\u0026#39;$p(X=x)$\u0026#39;) ax.set_xticks([x for x in range(-3, 5)]) ax.legend(loc=\u0026#39;best\u0026#39;, frameon=True) plt.savefig(\u0026#39;Gaussian-distribution.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 指数分布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import numpy as np import matplotlib.pyplot as plt from scipy.stats import expon def main(): \u0026#39;\u0026#39;\u0026#39; 指数分布 \u0026#39;\u0026#39;\u0026#39; # 三组参数 mus = [0.5, 1, 1.5] x_max = int(expon.ppf(0.99, 0, 1/np.min(mus))) x = np.linspace(0, x_max, 100) fig, ax = plt.subplots() for mu in mus: y = expon.pdf(x, loc=0, scale=1/mu) ax.plot(x, y, label=\u0026#39;$\\lambda$ = {}\u0026#39;.format(mu)) ax.set_title(\u0026#39;$X \\sim Exp(\\lambda)$\u0026#39;) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_ylabel(\u0026#39;$p(X=x)$\u0026#39;) ax.set_xticks([x for x in range(x_max + 1)]) ax.legend(loc=\u0026#39;best\u0026#39;, frameon=True) plt.savefig(\u0026#39;Exponential-distribution.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 小功能 颜色填充 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 2 * np.pi, 100) y = np.sin(x) fig, ax = plt.subplots() ax.plot(x, y, color=\u0026#39;green\u0026#39;) ax.fill(x, y, facecolor=\u0026#39;green\u0026#39;, edgecolor=None, alpha=0.25) ax.fill_between(x=x, y1=y+1, y2=y+2, color=\u0026#39;lightskyblue\u0026#39;, alpha=0.75) plt.savefig(\u0026#39;fill-and-fill_between.svg\u0026#39;) plt.show() 附：理解画布 figure 可以理解为整个画布，ax/axes 可以理解为具体的绘图区域（包括坐标轴、刻度、标题等）。\nplt 直接绘制在整个画布上，ax/axes 绘制在自己的一亩三分地之中。因此稍微复杂的图都不建议直接使用 plt.\n画一个 画复杂单图推荐。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 2 * np.pi, 50) y = np.sin(x) # 以下两种方式二选一 # 方式一 fig, ax = plt.subplots() # # 方式二 # fig = plt.figure() # ax = fig.add_subplot() ax.plot(x, y-1) ax.plot(x, y) ax.plot(x, y+1) plt.show() 画一组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 2 * np.pi, 50) y = np.sin(x) # 配置画布：1x3 fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6), sharey=True) ax1, ax2, ax3 = axes # 大标题 fig.suptitle(\u0026#39;This is Figure\u0026#39;, fontweight=\u0026#39;bold\u0026#39;) # Axes # Tip: 可以在以下三行中的任意一行后，测试直接 plt 的效果 ax1.plot(x, y-1, color=\u0026#39;#4EACC5\u0026#39;, label=r\u0026#39;$y=\\sin(x)-1$\u0026#39;) ax2.plot(x, y, color=\u0026#39;#FF9C34\u0026#39;, label=r\u0026#39;$y=\\sin(x)$\u0026#39;) ax3.plot(x, y+1, color=\u0026#39;#4E9A06\u0026#39;, label=r\u0026#39;$y=\\sin(x)+1$\u0026#39;) # Axes 标题 ax1.set_title(\u0026#39;This is Axes1\u0026#39;) ax2.set_title(\u0026#39;This is Axes2\u0026#39;) ax3.set_title(\u0026#39;This is Axes3\u0026#39;) # Axes 图例 ax1.legend(loc=\u0026#39;best\u0026#39;) ax2.legend(loc=\u0026#39;best\u0026#39;) ax3.legend(loc=\u0026#39;best\u0026#39;, frameon=False) # Axes 轴标签和刻度 ax1.set_xlabel(\u0026#39;xlabel\u0026#39;) ax1.set_ylabel(\u0026#39;ylabel\u0026#39;) ax2.set_xticks([i for i in range(0, 7, 2)]) ax3.set_xticks(()) plt.savefig(\u0026#39;multiple-axes.svg\u0026#39;) plt.show() ","description":"包括概率分布函数，激活函数，SST/SSR/SSE，2D vs. 3D 等。","id":8,"section":"posts","tags":["Matplotlib"],"title":"Matplotlib 绘图实践","uri":"https://mollywangup.com/posts/practice-of-matplotlib/"},{"content":"概率分布 二项分布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import numpy as np import matplotlib.pyplot as plt from scipy.stats import binom def runplt(n: int, p: float, ax: plt.axes, fmt=\u0026#39;yo\u0026#39;, color=\u0026#39;grey\u0026#39;): \u0026#39;\u0026#39;\u0026#39; 绘制单个二项分布的准备工作 \u0026#39;\u0026#39;\u0026#39; x = np.arange(n) y = [binom.pmf(x, n, p) for x in x] ax.plot(x, y, fmt, ms=5, mec=\u0026#39;black\u0026#39;, label=\u0026#39;p={}\\nn={}\u0026#39;.format(p, n)) ax.vlines(x, 0, y, lw=5, color=color, alpha=0.5) ax.vlines(x, 0, y, lw=1, color=color) ax.set_xticks([x for x in range(0, n + 2, 2)]) ax.legend(loc=\u0026#39;best\u0026#39;) def main(): \u0026#39;\u0026#39;\u0026#39; 绘制一组二项分布：参数对比 \u0026#39;\u0026#39;\u0026#39; # 参数 ns = np.array([[10, 10, 10], [10, 15, 20]]) ps = np.array([[0.1, 0.5, 0.7], [0.5, 0.5, 0.5]]) # 绘图 nrows = 2 ncols = 3 fig, axes = plt.subplots(nrows, ncols, figsize=(14, 7), sharey=True) for i in range(nrows): for j in range(ncols): runplt(ns[i, j], ps[i, j], axes[i, j]) fig.suptitle(\u0026#39;PMF of Binomial Distribution\u0026#39;) plt.savefig(\u0026#39;PMF-of-Binomial-distribution.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 泊松分布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import numpy as np import matplotlib.pyplot as plt from scipy.stats import bernoulli, binom, multinomial, poisson def main(): \u0026#39;\u0026#39;\u0026#39; 泊松分布 \u0026#39;\u0026#39;\u0026#39; # 三组参数 mus = [1, 4, 10] # 固定 x 的最大值 x_max = int(poisson.ppf(0.99, np.max(mus) + 2)) x = np.arange(x_max) fig, ax = plt.subplots() fmts = [\u0026#39;bo\u0026#39;, \u0026#39;ro\u0026#39;, \u0026#39;go\u0026#39;] colors = [c[0] for c in fmts] for mu, fmt, color in zip(mus, fmts, colors): # 数据 y = [poisson.pmf(x, mu) for x in x] # 绘图 ax.plot(x, y, fmt, ms=5, mec=\u0026#39;black\u0026#39;, label=\u0026#39;$\\lambda$ = {}\u0026#39;.format(mu)) ax.plot(x, y, c=color, alpha=0.5) ax.set_title(\u0026#39;$X \\sim Poisson(\\lambda)$\u0026#39;) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_ylabel(\u0026#39;$p(X=x)$\u0026#39;) ax.set_xticks([x for x in range(0, x_max, 5)]) ax.legend(loc=\u0026#39;best\u0026#39;, frameon=True) plt.savefig(\u0026#39;Poisson-distribution.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 高斯分布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm def main(): \u0026#39;\u0026#39;\u0026#39; 高斯分布 \u0026#39;\u0026#39;\u0026#39; # 三组参数 means = [0, 1, 0] variances = [1, 1, 0.5] x = np.linspace(-3, 4, 100) fig, ax = plt.subplots() for mean, variance in zip(means, variances): std = np.sqrt(variance) y = norm.pdf(x, loc=mean, scale=std) ax.plot(x, y, label=\u0026#39;$\\mu$={}, $\\sigma^2$={}\u0026#39;.format(mean, variance)) ax.set_title(\u0026#39;$X \\sim N(\\mu, \\sigma^2)$\u0026#39;) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_ylabel(\u0026#39;$p(X=x)$\u0026#39;) ax.set_xticks([x for x in range(-3, 5)]) ax.legend(loc=\u0026#39;best\u0026#39;, frameon=True) plt.savefig(\u0026#39;Gaussian-distribution.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 指数分布 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import numpy as np import matplotlib.pyplot as plt from scipy.stats import expon def main(): \u0026#39;\u0026#39;\u0026#39; 指数分布 \u0026#39;\u0026#39;\u0026#39; # 三组参数 mus = [0.5, 1, 1.5] x_max = int(expon.ppf(0.99, 0, 1/np.min(mus))) x = np.linspace(0, x_max, 100) fig, ax = plt.subplots() for mu in mus: y = expon.pdf(x, loc=0, scale=1/mu) ax.plot(x, y, label=\u0026#39;$\\lambda$ = {}\u0026#39;.format(mu)) ax.set_title(\u0026#39;$X \\sim Exp(\\lambda)$\u0026#39;) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_ylabel(\u0026#39;$p(X=x)$\u0026#39;) ax.set_xticks([x for x in range(x_max + 1)]) ax.legend(loc=\u0026#39;best\u0026#39;, frameon=True) plt.savefig(\u0026#39;Exponential-distribution.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 小功能 颜色填充 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 2 * np.pi, 100) y = np.sin(x) fig, ax = plt.subplots() ax.plot(x, y, color=\u0026#39;green\u0026#39;) ax.fill(x, y, facecolor=\u0026#39;green\u0026#39;, edgecolor=None, alpha=0.25) ax.fill_between(x=x, y1=y+1, y2=y+2, color=\u0026#39;lightskyblue\u0026#39;, alpha=0.75) plt.savefig(\u0026#39;fill-and-fill_between.svg\u0026#39;) plt.show() 附：理解画布 figure 可以理解为整个画布，ax/axes 可以理解为具体的绘图区域（包括坐标轴、刻度、标题等）。\nplt 直接绘制在整个画布上，ax/axes 绘制在自己的一亩三分地之中。因此稍微复杂的图都不建议直接使用 plt.\n画一个 画复杂单图推荐。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 2 * np.pi, 50) y = np.sin(x) # 以下两种方式二选一 # 方式一 fig, ax = plt.subplots() # # 方式二 # fig = plt.figure() # ax = fig.add_subplot() ax.plot(x, y-1) ax.plot(x, y) ax.plot(x, y+1) plt.show() 画一组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import numpy as np import matplotlib.pyplot as plt x = np.linspace(0, 2 * np.pi, 50) y = np.sin(x) # 配置画布：1x3 fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 6), sharey=True) ax1, ax2, ax3 = axes # 大标题 fig.suptitle(\u0026#39;This is Figure\u0026#39;, fontweight=\u0026#39;bold\u0026#39;) # Axes # Tip: 可以在以下三行中的任意一行后，测试直接 plt 的效果 ax1.plot(x, y-1, color=\u0026#39;#4EACC5\u0026#39;, label=r\u0026#39;$y=\\sin(x)-1$\u0026#39;) ax2.plot(x, y, color=\u0026#39;#FF9C34\u0026#39;, label=r\u0026#39;$y=\\sin(x)$\u0026#39;) ax3.plot(x, y+1, color=\u0026#39;#4E9A06\u0026#39;, label=r\u0026#39;$y=\\sin(x)+1$\u0026#39;) # Axes 标题 ax1.set_title(\u0026#39;This is Axes1\u0026#39;) ax2.set_title(\u0026#39;This is Axes2\u0026#39;) ax3.set_title(\u0026#39;This is Axes3\u0026#39;) # Axes 图例 ax1.legend(loc=\u0026#39;best\u0026#39;) ax2.legend(loc=\u0026#39;best\u0026#39;) ax3.legend(loc=\u0026#39;best\u0026#39;, frameon=False) # Axes 轴标签和刻度 ax1.set_xlabel(\u0026#39;xlabel\u0026#39;) ax1.set_ylabel(\u0026#39;ylabel\u0026#39;) ax2.set_xticks([i for i in range(0, 7, 2)]) ax3.set_xticks(()) plt.savefig(\u0026#39;multiple-axes.svg\u0026#39;) plt.show() ","description":"包括概率分布函数，激活函数，SST/SSR/SSE，2D vs. 3D 等。","id":9,"section":"zh","tags":["Matplotlib"],"title":"Matplotlib 绘图实践","uri":"https://mollywangup.com/zh/posts/practice-of-matplotlib/"},{"content":"数据源：SMS Spam Collection\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import time import pandas as pd import matplotlib.pyplot as plt from sklearn.feature_extraction.text import CountVectorizer from sklearn.preprocessing import LabelEncoder from sklearn.model_selection import train_test_split from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score from sklearn.neighbors import KNeighborsClassifier from sklearn.linear_model import LogisticRegression from sklearn.svm import SVC from sklearn.naive_bayes import MultinomialNB from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier import xgboost as xgb def runplt(): \u0026#39;\u0026#39;\u0026#39; 绘制 ROC 曲线的准备工作 \u0026#39;\u0026#39;\u0026#39; fig, ax = plt.subplots() ax.set_title(\u0026#39;ROC curve and AUC\u0026#39;) ax.set_xlabel(\u0026#39;FPR (False Positive Rate)\u0026#39;) ax.set_ylabel(\u0026#39;TPR (True Positive Rate)\u0026#39;) ax.plot([0, 1], [0, 1], color=\u0026#39;navy\u0026#39;, ls=\u0026#39;--\u0026#39;, label=\u0026#39;random: 0.5\u0026#39;) ax.plot([0, 0, 1, 1], [0, 1, 1, 1], color=\u0026#39;forestgreen\u0026#39;, ls=\u0026#39;--\u0026#39;, label=\u0026#39;perfect: 1\u0026#39;) return ax def main(): \u0026#39;\u0026#39;\u0026#39; 任务：垃圾邮件分类 \u0026#39;\u0026#39;\u0026#39; # 加载数据集 df = pd.read_table(\u0026#39;/path/to/SMSSpamCollection.txt\u0026#39;, header=None) feature, target = df[1], df[0] # 拆分训练集 X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.3, random_state=777) print(\u0026#39;\u0026gt;\u0026gt;\u0026gt; 训练集：{} 组, 测试集：{} 组 \u0026lt;\u0026lt;\u0026lt;\u0026#39;.format(X_train.shape[0], X_test.shape[0])) # 预处理: 处理文本 (词袋模型) cv = CountVectorizer(stop_words=\u0026#39;english\u0026#39;) X_train = cv.fit_transform(X_train) X_test = cv.transform(X_test) le = LabelEncoder() y_train = le.fit_transform(y_train) y_test = le.transform(y_test) # 构建多个分类器 names = [ \u0026#39;KNN\u0026#39;, \u0026#39;Logistic\u0026#39;, \u0026#39;SVM\u0026#39;, \u0026#39;NaiveBayes\u0026#39;, \u0026#39;DecisionTree\u0026#39;, \u0026#39;RandomForest\u0026#39;, \u0026#39;XGBoost\u0026#39;, ] classifiers = [ KNeighborsClassifier(n_neighbors=3), LogisticRegression(), SVC(kernel=\u0026#39;linear\u0026#39;, probability=True), MultinomialNB(), DecisionTreeClassifier(), RandomForestClassifier(n_estimators=100), xgb.XGBClassifier(tree_method=\u0026#39;hist\u0026#39;), ] # 批处理: 模型训练, 保存评估指标, 绘制 ROC 曲线 ax = runplt() report = [] for name, clf in zip(names, classifiers): # 模型训练 start_time = time.time() clf.fit(X_train, y_train) duration = time.time() - start_time # 模型评估: 拟合度 score_train = clf.score(X_train, y_train) score_test = clf.score(X_test, y_test) print(\u0026#39;{} (耗时 {:.5f} 秒):\\n 训练集准确率: {:.3f}\\n 测试集准确率: {:.3f}\u0026#39;.format(name, duration, score_train, score_test)) # 模型评估: 准确率/精确率/召回率/F1 y_pred = clf.predict(X_test) accuracy = accuracy_score(y_test, y_pred) precision = precision_score(y_test, y_pred) recall = recall_score(y_test, y_pred) f1 = f1_score(y_test, y_pred) # 模型评估: 绘制 ROC 曲线并标注 AUC 值 y_score = clf.predict_proba(X_test) if y_score.shape[1] == 2: y_score = y_score[:,1] fpr, tpr, thresholds = roc_curve(y_test, y_score) auc = roc_auc_score(y_test, y_score) ax.plot(fpr, tpr, label=\u0026#39;{}: ${:.3f}$\u0026#39;.format(name, auc)) # 将所有评估指标保存在 dataframe _ = { \u0026#39;classifier\u0026#39;: name, \u0026#39;duration\u0026#39;: duration, \u0026#39;accuracy_train\u0026#39;: score_train, \u0026#39;accuracy_test\u0026#39;: score_test, \u0026#39;accuracy\u0026#39;: accuracy, \u0026#39;precision\u0026#39;: precision, \u0026#39;recall\u0026#39;: recall, \u0026#39;f1\u0026#39;: f1, \u0026#39;AUC\u0026#39;: auc, } report.append(_) # 打印 dataframe df = pd.DataFrame(report) df = df.sort_values(by=\u0026#39;AUC\u0026#39;, ascending=False) print(df) # 保存 ROC 曲线 ax.legend(loc=\u0026#39;best\u0026#39;, frameon=True, fontsize=\u0026#39;small\u0026#39;) plt.savefig(\u0026#39;ROC.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 运行结果 指标意义详见：分类指标\n","description":"对比 KNN、逻辑回归、SVM、朴素贝叶斯、决策树、随机森林、XGBoost 等多个分类器来对垃圾邮件进行分类。","id":10,"section":"posts","tags":["sklearn","Classification"],"title":"机器学习实践 - 垃圾邮件分类器","uri":"https://mollywangup.com/posts/practice-of-ml-classification/"},{"content":"数据源：SMS Spam Collection\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import time import pandas as pd import matplotlib.pyplot as plt from sklearn.feature_extraction.text import CountVectorizer from sklearn.preprocessing import LabelEncoder from sklearn.model_selection import train_test_split from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score from sklearn.neighbors import KNeighborsClassifier from sklearn.linear_model import LogisticRegression from sklearn.svm import SVC from sklearn.naive_bayes import MultinomialNB from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier import xgboost as xgb def runplt(): \u0026#39;\u0026#39;\u0026#39; 绘制 ROC 曲线的准备工作 \u0026#39;\u0026#39;\u0026#39; fig, ax = plt.subplots() ax.set_title(\u0026#39;ROC curve and AUC\u0026#39;) ax.set_xlabel(\u0026#39;FPR (False Positive Rate)\u0026#39;) ax.set_ylabel(\u0026#39;TPR (True Positive Rate)\u0026#39;) ax.plot([0, 1], [0, 1], color=\u0026#39;navy\u0026#39;, ls=\u0026#39;--\u0026#39;, label=\u0026#39;random: 0.5\u0026#39;) ax.plot([0, 0, 1, 1], [0, 1, 1, 1], color=\u0026#39;forestgreen\u0026#39;, ls=\u0026#39;--\u0026#39;, label=\u0026#39;perfect: 1\u0026#39;) return ax def main(): \u0026#39;\u0026#39;\u0026#39; 任务：垃圾邮件分类 \u0026#39;\u0026#39;\u0026#39; # 加载数据集 df = pd.read_table(\u0026#39;/path/to/SMSSpamCollection.txt\u0026#39;, header=None) feature, target = df[1], df[0] # 拆分训练集 X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.3, random_state=777) print(\u0026#39;\u0026gt;\u0026gt;\u0026gt; 训练集：{} 组, 测试集：{} 组 \u0026lt;\u0026lt;\u0026lt;\u0026#39;.format(X_train.shape[0], X_test.shape[0])) # 预处理: 处理文本 (词袋模型) cv = CountVectorizer(stop_words=\u0026#39;english\u0026#39;) X_train = cv.fit_transform(X_train) X_test = cv.transform(X_test) le = LabelEncoder() y_train = le.fit_transform(y_train) y_test = le.transform(y_test) # 构建多个分类器 names = [ \u0026#39;KNN\u0026#39;, \u0026#39;Logistic\u0026#39;, \u0026#39;SVM\u0026#39;, \u0026#39;NaiveBayes\u0026#39;, \u0026#39;DecisionTree\u0026#39;, \u0026#39;RandomForest\u0026#39;, \u0026#39;XGBoost\u0026#39;, ] classifiers = [ KNeighborsClassifier(n_neighbors=3), LogisticRegression(), SVC(kernel=\u0026#39;linear\u0026#39;, probability=True), MultinomialNB(), DecisionTreeClassifier(), RandomForestClassifier(n_estimators=100), xgb.XGBClassifier(tree_method=\u0026#39;hist\u0026#39;), ] # 批处理: 模型训练, 保存评估指标, 绘制 ROC 曲线 ax = runplt() report = [] for name, clf in zip(names, classifiers): # 模型训练 start_time = time.time() clf.fit(X_train, y_train) duration = time.time() - start_time # 模型评估: 拟合度 score_train = clf.score(X_train, y_train) score_test = clf.score(X_test, y_test) print(\u0026#39;{} (耗时 {:.5f} 秒):\\n 训练集准确率: {:.3f}\\n 测试集准确率: {:.3f}\u0026#39;.format(name, duration, score_train, score_test)) # 模型评估: 准确率/精确率/召回率/F1 y_pred = clf.predict(X_test) accuracy = accuracy_score(y_test, y_pred) precision = precision_score(y_test, y_pred) recall = recall_score(y_test, y_pred) f1 = f1_score(y_test, y_pred) # 模型评估: 绘制 ROC 曲线并标注 AUC 值 y_score = clf.predict_proba(X_test) if y_score.shape[1] == 2: y_score = y_score[:,1] fpr, tpr, thresholds = roc_curve(y_test, y_score) auc = roc_auc_score(y_test, y_score) ax.plot(fpr, tpr, label=\u0026#39;{}: ${:.3f}$\u0026#39;.format(name, auc)) # 将所有评估指标保存在 dataframe _ = { \u0026#39;classifier\u0026#39;: name, \u0026#39;duration\u0026#39;: duration, \u0026#39;accuracy_train\u0026#39;: score_train, \u0026#39;accuracy_test\u0026#39;: score_test, \u0026#39;accuracy\u0026#39;: accuracy, \u0026#39;precision\u0026#39;: precision, \u0026#39;recall\u0026#39;: recall, \u0026#39;f1\u0026#39;: f1, \u0026#39;AUC\u0026#39;: auc, } report.append(_) # 打印 dataframe df = pd.DataFrame(report) df = df.sort_values(by=\u0026#39;AUC\u0026#39;, ascending=False) print(df) # 保存 ROC 曲线 ax.legend(loc=\u0026#39;best\u0026#39;, frameon=True, fontsize=\u0026#39;small\u0026#39;) plt.savefig(\u0026#39;ROC.svg\u0026#39;) plt.show() if __name__ == \u0026#39;__main__\u0026#39;: main() 运行结果 指标意义详见：分类指标\n","description":"对比 KNN、逻辑回归、SVM、朴素贝叶斯、决策树、随机森林、XGBoost 等多个分类器来对垃圾邮件进行分类。","id":11,"section":"zh","tags":["sklearn","Classification"],"title":"机器学习实践 - 垃圾邮件分类器","uri":"https://mollywangup.com/zh/posts/practice-of-ml-classification/"},{"content":"K-means 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import time import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import make_blobs from sklearn.cluster import KMeans from sklearn.metrics.pairwise import pairwise_distances_argmin # 模拟测试数据 np.random.seed(0) batch_size = 45 centers = np.array([[1, 1], [-1, -1], [1, -1]]) n_clusters = centers.shape[0] X, labels_true = make_blobs(n_samples=3000, centers=centers, cluster_std=[0.3, 0.7, 1]) # 使用 K-means 聚类 k_means = KMeans(init=\u0026#39;k-means++\u0026#39;, n_clusters=3, n_init=10) t0 = time.time() k_means.fit(X) t_batch = time.time() - t0 # 校验 k_means_cluster_centers = k_means.cluster_centers_ k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers) # 绘图 fig = plt.figure(figsize=(8, 3)) fig.subplots_adjust(left=0.01, right=0.98, bottom=0.05, top=0.9) colors = [\u0026#34;#4EACC5\u0026#34;, \u0026#34;#FF9C34\u0026#34;, \u0026#34;#4E9A06\u0026#34;] ax = fig.add_subplot(1, 3, 1) for k, col in zip(range(n_clusters), colors): my_members = k_means_labels == k cluster_center = k_means_cluster_centers[k] ax.plot(X[my_members, 0], X[my_members, 1], \u0026#34;w\u0026#34;, markerfacecolor=col, marker=\u0026#34;.\u0026#34;) ax.plot( cluster_center[0], cluster_center[1], \u0026#34;o\u0026#34;, markerfacecolor=col, markeredgecolor=\u0026#34;k\u0026#34;, markersize=6, ) ax.set_title(\u0026#34;KMeans\u0026#34;) ax.set_xticks(()) ax.set_yticks(()) # plt.text(-3.5, 1.8, \u0026#34;train time: %.2fs\\ninertia: %f\u0026#34; % (t_batch, k_means.inertia_)) DBSCAN ","description":"直接使用 sklearn.","id":12,"section":"posts","tags":["sklearn","Clustering"],"title":"机器学习实践 - 聚类问题","uri":"https://mollywangup.com/posts/practice-of-ml-clustering/"},{"content":"K-means 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import time import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import make_blobs from sklearn.cluster import KMeans from sklearn.metrics.pairwise import pairwise_distances_argmin # 模拟测试数据 np.random.seed(0) batch_size = 45 centers = np.array([[1, 1], [-1, -1], [1, -1]]) n_clusters = centers.shape[0] X, labels_true = make_blobs(n_samples=3000, centers=centers, cluster_std=[0.3, 0.7, 1]) # 使用 K-means 聚类 k_means = KMeans(init=\u0026#39;k-means++\u0026#39;, n_clusters=3, n_init=10) t0 = time.time() k_means.fit(X) t_batch = time.time() - t0 # 校验 k_means_cluster_centers = k_means.cluster_centers_ k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers) # 绘图 fig = plt.figure(figsize=(8, 3)) fig.subplots_adjust(left=0.01, right=0.98, bottom=0.05, top=0.9) colors = [\u0026#34;#4EACC5\u0026#34;, \u0026#34;#FF9C34\u0026#34;, \u0026#34;#4E9A06\u0026#34;] ax = fig.add_subplot(1, 3, 1) for k, col in zip(range(n_clusters), colors): my_members = k_means_labels == k cluster_center = k_means_cluster_centers[k] ax.plot(X[my_members, 0], X[my_members, 1], \u0026#34;w\u0026#34;, markerfacecolor=col, marker=\u0026#34;.\u0026#34;) ax.plot( cluster_center[0], cluster_center[1], \u0026#34;o\u0026#34;, markerfacecolor=col, markeredgecolor=\u0026#34;k\u0026#34;, markersize=6, ) ax.set_title(\u0026#34;KMeans\u0026#34;) ax.set_xticks(()) ax.set_yticks(()) # plt.text(-3.5, 1.8, \u0026#34;train time: %.2fs\\ninertia: %f\u0026#34; % (t_batch, k_means.inertia_)) DBSCAN ","description":"直接使用 sklearn.","id":13,"section":"zh","tags":["sklearn","Clustering"],"title":"机器学习实践 - 聚类问题","uri":"https://mollywangup.com/zh/posts/practice-of-ml-clustering/"},{"content":"一元线性回归 以下示例来源于 sklearn 的糖尿病数据集。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import load_diabetes from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error, r2_score # 加载数据集：仅取其中一个特征，并拆分训练集/测试集（7/3） features, target = load_diabetes(return_X_y=True) feature = features[:, np.newaxis, 2] X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.3, random_state=8) print(\u0026#39;特征数量：{} 个（原始数据集共 {} 个特征）\\n总样本量：共 {} 组，其中训练集 {} 组，测试集 {} 组\u0026#39;.format(feature.shape[1], features.shape[1], target.shape[0], X_train.shape[0], X_test.shape[0])) # 创建线性回归模型并拟合数据 model = LinearRegression() model.fit(X_train, y_train) # 获取模型参数 w = model.coef_ b = model.intercept_ print(\u0026#39;模型参数：w={}, b={}\u0026#39;.format(w, b)) # 衡量模型性能：R2 和 MSE y_train_pred = model.predict(X_train) y_test_pred = model.predict(X_test) # R2（决定系数，1最佳），计算等同于 r2_score(y_true, y_pred) r2_train = model.score(X_train, y_train) r2_test = model.score(X_test, y_test) # MSE（均方误差） mse_train = mean_squared_error(y_train, y_train_pred) mse_test = mean_squared_error(y_test, y_test_pred) print(\u0026#39;模型性能：\\n 训练集：R2={:.3f}, MSE={:.3f}\\n 测试集：R2={:.3f}, MSE={:.3f}\u0026#39;.format(r2_train, mse_train, r2_test, mse_test)) # 绘图 plt.title(\u0026#39;LinearRegression (One variable)\u0026#39;) plt.scatter(X_train, y_train, color=\u0026#39;red\u0026#39;, marker=\u0026#39;X\u0026#39;) plt.plot(X_test, y_pred, linewidth=3) plt.legend([\u0026#39;training points\u0026#39;, \u0026#39;model: $y={:.2f}x+{:.2f}$\u0026#39;.format(w[0], b)]) plt.savefig(\u0026#39;LinearRegression_diabetes.svg\u0026#39;) 多元线性回归 以下示例来源于 sklearn 的糖尿病数据集，选取了所有的特征，并对比了普通最小二乘/Lasso/Ridge 三种回归模型的性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import load_diabetes from sklearn.linear_model import LinearRegression, Lasso, Ridge from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error # 加载数据集：取所有特征，并拆分训练集/测试集（7/3） features, target = load_diabetes(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=8) print(\u0026#39;特征数量：{} 个\\n总样本量：共 {} 组，其中训练集 {} 组，测试集 {} 组\u0026#39;.format(features.shape[1], target.shape[0], X_train.shape[0], X_test.shape[0])) def _models(alpha=1): lr = LinearRegression().fit(X_train, y_train) # 第一种：普通最小二乘回归 lasso = Lasso(alpha=alpha).fit(X_train, y_train) # 第二种：Lasso/L1/套索回归 ridge = Ridge(alpha=alpha).fit(X_train, y_train) # 第三种：Ridge/L2/岭回归 return lr, lasso, ridge # 对比四组 alpha 取值 alphas_list = [0.05, 0.1, 0.5, 1] for i in range(len(alphas_list)): alpha = alphas_list[i] print(\u0026#39;\\n======== alpha={} ========\u0026#39;.format(alpha)) # 对比三种线性模型 models = _models(alpha=alpha) for model in models: # 模型参数 w = model.coef_ b = model.intercept_ # 模型性能：R2 和 MSE r2_train = model.score(X_train, y_train) r2_test = model.score(X_test, y_test) mse_train = mean_squared_error(y_train, model.predict(X_train)) mse_test = mean_squared_error(y_test, model.predict(X_test)) # 打印 model_name = model.__class__.__name__ print(\u0026#39;{}：\\n 模型参数：w={}, b={:.3f}\\n 训练集：R2={:.3f}, MSE={:.3f}\\n 测试集：R2={:.3f}, MSE={:.3f}\u0026#39;.format(model_name, w, b, r2_train, mse_train, r2_test, mse_test)) 多项式回归 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 import numpy as np import matplotlib.pyplot as plt from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score rng = np.random.RandomState(0) # 数据集 x = np.linspace(-3, 7, 10) y = np.power(x, 3) + np.power(x, 2) + x + 1 + rng.randn(1) X = x[:, np.newaxis] # 绘制训练集 fig, ax = plt.subplots(figsize=(8, 6)) ax.scatter(X, y, color=\u0026#39;red\u0026#39;, marker=\u0026#39;X\u0026#39;, label=\u0026#39;training points\u0026#39;) # 多项式特征的线性回归模型 for degree in range(10): # 创建多项式特征 poly = PolynomialFeatures(degree) X_poly = poly.fit_transform(X) # 创建线性回归模型：X_poly 与 y 为线性关系 model = LinearRegression() model.fit(X_poly, y) # 使用模型预测 y_pred = model.predict(X_poly) # 获取模型参数和性能指标 w = model.coef_ b = model.intercept_ r2 = model.score(X_poly, y) mse = mean_squared_error(y, y_pred) # 绘图 ax.plot(X, y_pred, label=\u0026#39;Degree {}: MSE {:.3f}, $R^2$ {:.3f}\u0026#39;.format(degree, round(mse, 3), r2)) # 添加图例 plt.legend(loc=\u0026#39;best\u0026#39;, fontsize=\u0026#39;small\u0026#39;) plt.savefig(\u0026#39;PolynomialFeatures_LinearRegression.svg\u0026#39;) plt.show() ","description":"一元/多元线性回归，多项式回归，回归树。","id":14,"section":"posts","tags":["sklearn","Regression"],"title":"机器学习实践 - 回归问题","uri":"https://mollywangup.com/posts/practice-of-ml-regression/"},{"content":"一元线性回归 以下示例来源于 sklearn 的糖尿病数据集。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import load_diabetes from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error, r2_score # 加载数据集：仅取其中一个特征，并拆分训练集/测试集（7/3） features, target = load_diabetes(return_X_y=True) feature = features[:, np.newaxis, 2] X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.3, random_state=8) print(\u0026#39;特征数量：{} 个（原始数据集共 {} 个特征）\\n总样本量：共 {} 组，其中训练集 {} 组，测试集 {} 组\u0026#39;.format(feature.shape[1], features.shape[1], target.shape[0], X_train.shape[0], X_test.shape[0])) # 创建线性回归模型并拟合数据 model = LinearRegression() model.fit(X_train, y_train) # 获取模型参数 w = model.coef_ b = model.intercept_ print(\u0026#39;模型参数：w={}, b={}\u0026#39;.format(w, b)) # 衡量模型性能：R2 和 MSE y_train_pred = model.predict(X_train) y_test_pred = model.predict(X_test) # R2（决定系数，1最佳），计算等同于 r2_score(y_true, y_pred) r2_train = model.score(X_train, y_train) r2_test = model.score(X_test, y_test) # MSE（均方误差） mse_train = mean_squared_error(y_train, y_train_pred) mse_test = mean_squared_error(y_test, y_test_pred) print(\u0026#39;模型性能：\\n 训练集：R2={:.3f}, MSE={:.3f}\\n 测试集：R2={:.3f}, MSE={:.3f}\u0026#39;.format(r2_train, mse_train, r2_test, mse_test)) # 绘图 plt.title(\u0026#39;LinearRegression (One variable)\u0026#39;) plt.scatter(X_train, y_train, color=\u0026#39;red\u0026#39;, marker=\u0026#39;X\u0026#39;) plt.plot(X_test, y_pred, linewidth=3) plt.legend([\u0026#39;training points\u0026#39;, \u0026#39;model: $y={:.2f}x+{:.2f}$\u0026#39;.format(w[0], b)]) plt.savefig(\u0026#39;LinearRegression_diabetes.svg\u0026#39;) 多元线性回归 以下示例来源于 sklearn 的糖尿病数据集，选取了所有的特征，并对比了普通最小二乘/Lasso/Ridge 三种回归模型的性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import load_diabetes from sklearn.linear_model import LinearRegression, Lasso, Ridge from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error # 加载数据集：取所有特征，并拆分训练集/测试集（7/3） features, target = load_diabetes(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=8) print(\u0026#39;特征数量：{} 个\\n总样本量：共 {} 组，其中训练集 {} 组，测试集 {} 组\u0026#39;.format(features.shape[1], target.shape[0], X_train.shape[0], X_test.shape[0])) def _models(alpha=1): lr = LinearRegression().fit(X_train, y_train) # 第一种：普通最小二乘回归 lasso = Lasso(alpha=alpha).fit(X_train, y_train) # 第二种：Lasso/L1/套索回归 ridge = Ridge(alpha=alpha).fit(X_train, y_train) # 第三种：Ridge/L2/岭回归 return lr, lasso, ridge # 对比四组 alpha 取值 alphas_list = [0.05, 0.1, 0.5, 1] for i in range(len(alphas_list)): alpha = alphas_list[i] print(\u0026#39;\\n======== alpha={} ========\u0026#39;.format(alpha)) # 对比三种线性模型 models = _models(alpha=alpha) for model in models: # 模型参数 w = model.coef_ b = model.intercept_ # 模型性能：R2 和 MSE r2_train = model.score(X_train, y_train) r2_test = model.score(X_test, y_test) mse_train = mean_squared_error(y_train, model.predict(X_train)) mse_test = mean_squared_error(y_test, model.predict(X_test)) # 打印 model_name = model.__class__.__name__ print(\u0026#39;{}：\\n 模型参数：w={}, b={:.3f}\\n 训练集：R2={:.3f}, MSE={:.3f}\\n 测试集：R2={:.3f}, MSE={:.3f}\u0026#39;.format(model_name, w, b, r2_train, mse_train, r2_test, mse_test)) 多项式回归 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 import numpy as np import matplotlib.pyplot as plt from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score rng = np.random.RandomState(0) # 数据集 x = np.linspace(-3, 7, 10) y = np.power(x, 3) + np.power(x, 2) + x + 1 + rng.randn(1) X = x[:, np.newaxis] # 绘制训练集 fig, ax = plt.subplots(figsize=(8, 6)) ax.scatter(X, y, color=\u0026#39;red\u0026#39;, marker=\u0026#39;X\u0026#39;, label=\u0026#39;training points\u0026#39;) # 多项式特征的线性回归模型 for degree in range(10): # 创建多项式特征 poly = PolynomialFeatures(degree) X_poly = poly.fit_transform(X) # 创建线性回归模型：X_poly 与 y 为线性关系 model = LinearRegression() model.fit(X_poly, y) # 使用模型预测 y_pred = model.predict(X_poly) # 获取模型参数和性能指标 w = model.coef_ b = model.intercept_ r2 = model.score(X_poly, y) mse = mean_squared_error(y, y_pred) # 绘图 ax.plot(X, y_pred, label=\u0026#39;Degree {}: MSE {:.3f}, $R^2$ {:.3f}\u0026#39;.format(degree, round(mse, 3), r2)) # 添加图例 plt.legend(loc=\u0026#39;best\u0026#39;, fontsize=\u0026#39;small\u0026#39;) plt.savefig(\u0026#39;PolynomialFeatures_LinearRegression.svg\u0026#39;) plt.show() ","description":"一元/多元线性回归，多项式回归，回归树。","id":15,"section":"zh","tags":["sklearn","Regression"],"title":"机器学习实践 - 回归问题","uri":"https://mollywangup.com/zh/posts/practice-of-ml-regression/"},{"content":"本笔记基于以下学习资料（侧重实际应用）：\n入门机器学习：(强推|双字)2022吴恩达机器学习Deeplearning.ai课程\nPython 代码库：scikit-learn 官网\n复习线性代数：3Blue1Brown 的 线性代数的本质 - 系列合集\n统一口径 术语 特征（feature）：指输入变量； 标签（label）：指输出变量，真实值（target 或 ground truth），预测值（prediction）； 训练集（training set）：用于训练模型； 验证集（validation set）：用于防止模型过拟合； 测试集（test set）：用于评估模型效果； 训练示例（training example）：指训练集中的一组数据； 模型（model）：指拟合函数或概率模型； 模型参数（parameter）：调整模型的本质是调整模型参数； 损失函数（Loss function）：衡量预测值与真实值之间的差异程度，\u0026ldquo;单个损失\u0026rdquo;； 成本函数（Cost function）：用于评估模型性能，\u0026ldquo;总损失\u0026rdquo;； 特征工程（feature engineering）：对特征进行选择、提取和转换等操作，用于提高模型性能； 符号 约定如下：\nm 个训练示例，n 个特征； $\\mathbb{R}$ 表示标量，$\\mathbb{R}^n$ 表示向量，$\\mathbb{R}^{m \\times n}$ 表示矩阵，$\\mathbb{R}^{m \\times n \\times p \\times \\cdots}$ 表示张量（Tensor）； 具体符号：\n$x \\in \\mathbb{R}^n$ 表示输入变量，$w \\in \\mathbb{R}^n$ 表示回归系数； $X \\in \\mathbb{R}^{m \\times n}$ 表示训练集，$y,\\hat{y} \\in \\mathbb{R}^m$ 分别表示真实值和预测值。 $x^{(i)} \\in \\mathbb{R}^n$ 表示第 $i$ 个训练示例；（第 $i$ 行） $x_j \\in \\mathbb{R}^m$ 表示第 $j$ 个特征；（第 $j$ 列） $x_j^{(i)} \\in \\mathbb{R}$ 表示第 $i$ 个训练示例的第 $j$ 个特征； $y^{(i)},\\hat{y}^{(i)} \\in \\mathbb{R}$ 分别表示第 $i$ 个训练示例的真实值和预测值； $$\nx = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}\n\\space\nw = \\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix}\n\\space\ny = \\begin{bmatrix}y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}\n\\space\n\\hat{y} = \\begin{bmatrix}\\hat{y}^{(1)} \\\\ \\hat{y}^{(2)} \\\\ \\vdots \\\\ \\hat{y}^{(m)} \\end{bmatrix}\n\\space\n$$\n$$\nX =\n\\begin{bmatrix}\nx_1^{(1)} \u0026amp; x_2^{(1)} \u0026amp; \\dots \u0026amp; x_n^{(1)} \\\\\nx_1^{(2)} \u0026amp; x_2^{(2)} \u0026amp; \\dots \u0026amp; x_n^{(2)} \\\\\n\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\nx_1^{(m)} \u0026amp; x_2^{(m)} \u0026amp; \\dots \u0026amp; x_n^{(m)}\n\\end{bmatrix}\n\\space\nx^{(i)} = \\begin{bmatrix}x_1^{(i)} \\\\ x_2^{(i)} \\\\ \\vdots \\\\ x_n^{(i)} \\end{bmatrix}\n\\space\nx_j = \\begin{bmatrix}x_j^{(1)} \\\\ x_j^{(2)} \\\\ \\vdots \\\\ x_j^{(m)} \\end{bmatrix}\n$$\n监督学习 有标签的是监督学习。预测连续值的是回归任务，预测离散值的是分类任务。 给定包含标签的训练集 $(X,y)$，通过算法构建一个模型，学习如何从 $x$ 预测 $\\hat{y}$，即：$$ (X,y) \\to f(x) \\to \\hat{y} $$\n线性回归 线性回归（Linear Regression），解决线性的回归问题。\n原理 模型 $n$ 元线性回归的模型 $f: \\mathbb{R}^n \\to \\mathbb{R}$ 如下：\n$$\nf_{w,b}(x) = w \\cdot x + b =\n\\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix}\n\\cdot\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} + b =\n\\sum_{j=1}^{n}w_jx_j + b\n$$\n其中，模型参数：\n$w \\in \\mathbb{R}^n$：回归系数，分别对应 n 个特征的权重（weights）或系数（coefficients）；\n$b \\in \\mathbb{R}$：偏差（bias）或截距（intercept）；\n成本函数 使用最小二乘损失：\n$$\n\\begin{split}\nL(w,b) \u0026amp;= \\frac{1}{2} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \\\\\n\\\\\u0026amp;= \\frac{1}{2} (w \\cdot x^{(i)} + b - y^{(i)})^2\n\\end{split}\n$$\n基于最小二乘损失，常见的三种成本函数：\n$$ J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \\tag{OLS} $$\n$$ J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\lvert w_j \\rvert \\tag{Lasso} $$\n$$ J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2 \\tag{Ridge} $$\n说明：\n使用 $\\frac{1}{2m}$ 取均值，仅是为了在求偏导时消去常数 2，不影响结果； OLS：普通最小二乘回归； Lasso：Lasso 回归，用于特征选择。在 OLS 的基础上添加了 $w$ 的 L1 范数 作为正则化项； Ridge：岭回归，用于防止过拟合。是在 OLS 的基础上，添加了 $w$ 的 L2 范数 的平方作为正则化项； $\\lambda$：超参数，非负标量，为了控制惩罚项的大小。 矩阵乘向量写法 $$\nJ(w,b) = \\frac{1}{2m} \\lVert X_{new} \\cdot w_{new} - y \\rVert_2^2\n$$\n其中：\n$$\n(X_{new}|y) = \\left [\n\\begin{array}{ccccc|c}\n1 \u0026amp; x_1^{(1)} \u0026amp; x_2^{(1)} \u0026amp; \\dots \u0026amp; x_n^{(1)} \u0026amp; y^{(1)} \\\\\n1 \u0026amp; x_1^{(2)} \u0026amp; x_2^{(2)} \u0026amp; \\dots \u0026amp; x_n^{(2)} \u0026amp; y^{(2)} \\\\\n\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \\\\\n1 \u0026amp; x_1^{(m)} \u0026amp; x_2^{(m)} \u0026amp; \\dots \u0026amp; x_n^{(m)} \u0026amp; y^{(m)}\n\\end{array}\n\\right ]\n\\space\nw_{new} = \\begin{bmatrix}b \\\\ w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix}\n$$\n求解模型参数 求解一组模型参数 $(w,b)$ 使得成本函数 $J$ 最小化。方法见梯度下降算法\n$$ \\arg \\min_{w,b} J(w,b) $$\n多项式回归 通过添加特征的多项式可提高模型复杂度，将其视作新特征则归来仍是线性回归问题。 例子：以下式 $(1)(2)(3)$ 依次对应一元二次多项式、一元三次多项式、二元二次多项式模型：\n$$ f_{w,b}(x) = w_1x + w_2x^2 + b \\tag{1} $$\n$$ f_{w,b}(x) = w_1x + w_2x^2 + w_3x^3 + b \\tag{2} $$\n$$ f_{w,b}(x) = w_1x_1 + w_2x_2 + w_3x_1x_2 + w_4x_1^2 + w_5x_2^2 + b \\tag{3} $$\n以式 $(1)$ 的模型为例，将将非一次项的 $x^2$ 视作新特征，即可按照线性回归模型训练。\n逻辑回归 逻辑回归（Logistic Regression）是 Softmax 回归的特殊情况，都属于线性分类器。\n问题背景 二分类（逻辑回归） 即二选一问题。将 $y|x \\in \\lbrace C_1,C_2 \\rbrace$ 视为 $y$ 的条件概率下的伯努利分布，即：\n$p(y=1|x)$ 表示是 $C_1$ 的概率； $1 - p(y=1|x)$ 表示不是 $C_1$ 即是 $C_2$ 的概率； 因此仅需要找到一个概率分布函数：\n$$ p(y=1|x) $$\n然后取 $\\displaystyle \\max \\lbrace p,1-p \\rbrace$ 即以 $0.5$ 为分界，若 $p \\geq 0.5$ 则分类为 $C_1$，否则分类为 $C_2$.\n多分类（Softmax 回归） 即多选一问题。为 $y|x \\in \\lbrace C_1,C_2,\\cdots,C_k \\rbrace$ 找到 k 个 概率分布函数：\n$$\n\\begin{cases}\np(y=1|x) \\\\\n\\\\p(y=2|x) \\\\\n\\\\ \\cdots \\\\\n\\\\p(y=k|x)\n\\end{cases}\n$$\n其中 $\\displaystyle\\sum_{i=1}^{k} p(y=i|x) = 1$，然后取 $\\displaystyle \\max_{i} p(y=i|x)$ 为最终分类类别。\n逻辑回归 模型 逻辑回归假设 $y|x \\sim Bernoulli(p)$，即 $y$ 的条件概率服从伯努利分布（0-1分布）。\nSigmoid 函数：\n$$ g(z) = \\frac{1}{1+e^{-z}} \\in (0,1) $$\n令\n$$ z = w \\cdot x + b $$ 则 $y=1$（也称作正例）的概率模型：\n$$\np(y=1|x;w,b) = g(z) = \\frac{1}{1 + e^{-(w \\cdot x + b)}}\n$$\n说明：\n模型直接输出 $y=1$ 即正例的概率，即属于 $\\mathbb{R}^n \\to \\mathbb{R}$ 单值函数； 如 $y^{(i)}$ 形如 $[0]$，$\\hat{y}^{(i)}$ 形如 $[0.4]$. 以 0.5 为分界，若 $p \\geq 0.5$ 则分类为 $1$，否则分类为 $0$. 因此别名对数逻辑回归； 模型参数同线性回归。本质上是构造了一个线性决策边界 $z = w \\cdot x + b = 0$； 成本函数 以下两种角度殊途同归。\n极大似然估计角度 极大似然估计假设样本独立同分布，由模型 $p(y=1|x;w,b)$ 构造似然函数 $L(w,b)$：\n$$\n\\begin{split}\nL(w,b) \u0026amp;= \\prod_{i:y^{(i)}=1} p(x^{(i)};w,b) \\prod_{i:y^{(i)}=0} \\left(1 - p(x^{(i)};w,b)\\right) \\\\\n\\\\\u0026amp;= \\prod_{i=1}^{m} \\left(p(x^{(i)};w,b)\\right)^{y^{(i)}} \\left(1 - p(x^{(i)};w,b)\\right)^{1 - y^{(i)}}\n\\end{split}\n$$\n将目标由 $\\displaystyle\\arg \\max_{w,b} L(w,b)$ 转化为取对数再取负号后求极小值问题，取均值后成本函数：\n$$\nJ(w,b) = \\frac{1}{m} \\sum_{i=1}^{m} - y^{(i)} \\ln p(x^{(i)};w,b) - (1 - y^{(i)}) \\ln\\left(1 - p(x^{(i)};w,b)\\right)\n$$\n交叉熵损失角度 将真实类别 $y$ 和预测类别 $p(x;w,b)$ 看作分类类别的两个概率分布，则可使用交叉熵来衡量差异程度，即：\n$$\n\\begin{split}\nJ(w,b) \u0026amp;= \\frac{1}{m} \\sum_{i=1}^{m} L(\\hat{y}^{(i)}, y^{(i)}) = \\frac{1}{m} \\sum_{i=1}^{m} H(y^{(i)}, \\hat{y}^{(i)}) \\\\\n\u0026amp;= \\frac{1}{m} \\sum_{i=1}^{m} - y^{(i)} \\ln p(x^{(i)};w,b) - (1 - y^{(i)}) \\ln\\left(1 - p(x^{(i)};w,b)\\right)\n\\end{split}\n$$\n求解模型参数 求解一组模型参数 $(w,b)$ 使得成本函数 $J$ 最小化。方法见梯度下降算法\n$$ \\arg \\min_{w,b} J(w,b) $$\nSoftmax 回归 模型 Softmax 解决多分类问题，设共 $k$ 个类别，对于每个类别，都对应一个线性映射：\n$$ z_i = w_i \\cdot x + b_i $$\n则第 $i$ 个类别的概率模型：\n$$\np(y=i|x;w_i,b_i) = g(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{k} e^{z_j}}\n$$\n其中 $w_i \\in \\mathbb{R}^n, \\space i \\in \\lbrace 1, 2, \u0026hellip;, k \\rbrace$，显然 $\\displaystyle\\sum_{i=1}^{k} p(y=i|x;w_i,b_i) = 1$.\n说明：\n模型直接输出 $k$ 个类别的概率，即属于 $\\mathbb{R}^n \\to \\mathbb{R}^k$ 多值函数； 如 $k$ 取 3，则 $y^{(i)}$ 形如 $[0, 0, 1]$，$\\hat{y}^{(i)}$ 形如 $[0.1, 0.4, 0.5]$. 最终分类类别取 $\\displaystyle \\max_i p(y=i|x)$ 对应的即可； 成本函数 使用交叉熵损失：\n$$\n\\begin{split}\nJ \u0026amp;= \\frac{1}{m} \\sum_{i=1}^{m} L(\\hat{y}^{(i)}, y^{(i)})\n= \\frac{1}{m} \\sum_{i=1}^{m} H(y^{(i)}, \\hat{y}^{(i)}) \\\\\n\\\\\u0026amp;= \\frac{1}{m} \\sum_{i=1}^{m} \\sum_{j=1}^{k} -y^{(i,j)} \\ln p(x^{(i)};w_j,b_j)\n\\end{split}\n$$\n其中，$y^{(i,j)}$ 表示第 $i$ 个训练示例的第 $j$ 个分类的概率。\nSVM 支持向量机，解决分类问题。\n属于线性分类器。非线性问题，可通过 kernal SVM 解决（映射到高维）；\n超平面：\n决策分界面（decision boundary） 边界分界面（margin boundary） Hard-margin SVM\nSoft-margin SVM：加入了容错率\n核函数需满足：\n$$ k(x,z) = g(x) g(z) $$\n朴素贝叶斯 朴素贝叶斯（Naive Bayes），解决分类问题。\n原理 朴素贝叶斯基于贝叶斯定理，并假设每个样本点的特征相互独立。\n设 $x \\in \\mathbb{R}^n$，$y|x \\in \\lbrace C_1,C_2,\\cdots,C_k \\rbrace$，则给定待分类的 $x$，其属于 $C_i$ 类别的概率是：\n$$\np(y=C_i|x) = \\frac{p(y=C_i) p(x|y=C_i)}{p(x)} =\n\\frac{p(y=C_i) \\prod_{j=1}^{n} p(x_j|y=C_i)}{\\prod_{j=1}^{n} p(x_j)}\n$$\n然后取 $k$ 个类别中概率最大的作为预测类别，即：\n$$\n\\arg \\max_{C_i} p(y=C_i|x)\n$$\n说明：由于是比大小，因此可省去计算常量分母 $p(x)$，即：\n$$\np(y=C_i|x)\n\\propto\tp(y=C_i) \\prod_{j=1}^{n} p(x_j|y=C_i)\n$$\n拉普拉斯平滑 拉普拉斯平滑（Laplace smoothing）用于修正当 $p(x_j|y=C_i) = 0$ 时导致的连乘结果为零的零概率问题。方法是计算概率时分子+1\n决策树 决策树（Decision tree）可解决分类和回归问题。核心思想是使用信息纯度的提升程度来衡量分类效率。\n问题背景 特征：包含离散值和连续值；\n标签：\n离散值：决策树，使用熵或基尼系数衡量信息不纯度； 连续值：回归树，使用方差衡量信息不纯度； 决策树 设训练集有 $n$ 个类别特征，$k$ 个分类标签，则ID3算法的决策树基本原理如下：\n步骤零 设置一个阈值 $\\varepsilon$，当熵小于该值，则停止分类，因为此时信息纯度已足够高；\n步骤一 计算分类前 $y$ 的熵：\n$$ H(y) = - \\sum_{i=1}^{k} p(y=i) \\ln p(y=i) $$\n说明：当 $H(y) \u0026lt; \\varepsilon$ 时，没有分类的必要了。\n步骤二 对于每个类别特征 $x_j$，计算其将 $y$ 分类后的熵：\n$$ H(y|x_j), \\space j \\in \\lbrace1,2,\\cdots,n \\rbrace$$\n再计算分类前后的熵减即信息增益，选信息增益最大的那个特征作为分类特征：\n$$ Gain(y,x_j) = H(y) - H(y|x_j) $$\n说明：ID3算法使用信息增益，C4.5算法使用信息增益率。\n步骤三 对于每个子类别节点，重复步骤一和步骤二（记得剔除已分类特征），直至所有的子类别节点都停止分类。\n可选：连续特征离散化 回归树 对于回归树，使用方差衡量信息不纯度。其他类比决策树。\n随机森林 随机森林（Random forest）是一种基于树模型的集成学习（Ensemble learning）方法。\n思想：通过重复多次有放回抽样，且每次随机选择 $k\u0026lt;n$ 个特征，训练若干个权重相等的决策树（弱学习器），然后投票机制，分类问题则求众数，回归问题则求均值。\nBagging\nXGBoost 也是一种集成学习方法，Boosting.\nKNN KNN (K-Nearest Neighbors)，解决分类+回归问题。K 个邻居的意思。\n原理 给定训练集 $X \\in \\mathbb{R}^{m \\times n}, y \\in \\mathbb{R}^m$，则给定待分类的点（特征） $x$，其所属类别由距离其最近的 k 个点（邻居）决定。\n其中，距离计算方式有多种，较常使用的欧氏距离如下：\n$$\nd(x, x^{(i)}) = \\lVert x - x^{(i)} \\rVert\n= \\sqrt{\\sum_{j=1}^{n} (x_j - x_j^{(i)})^2}\n$$\n说明：非参数，投票制。回归问题，可取均值。\n无监督学习 无标签的是无监督学习。 给定不包含标签的训练集 $X$，通过算法构建一个模型，揭示数据的内在分布特性及规律，即：$$ X \\to f(x) \\to \\hat{y} $$\n无监督学习任务分为聚类（Clustering）和降维（Dimensionality reduction）。\nK-means 解决聚类问题。K 个类别的意思。\n原理 给定训练集 $X \\in \\mathbb{R}^{m \\times n}$，K-means 要实现的是将 $m$ 个点（训练示例）聚类为 $k$ 个簇（Cluster），步骤如下：\n步骤一：随机初始化 $k$ 个簇中心，记作 $\\mu_j \\in \\mathbb{R}^n$；\n步骤二：为每个点 $x^{(i)}$ 分配距离最近的簇，记作 $c^{(i)}$：$$ c^{(i)} = \\displaystyle\\min_{j} \\lVert x^{(i)} - \\mu_j\\rVert_2^2 $$\n步骤三：为每个簇重新计算簇中心 $\\mu_{j}$，方法是该簇中所有点的均值；\n重复以上步骤二和步骤三，直至 $k$ 个簇中心不再发生变化（即收敛）。\n成本函数可以表示为：\n$$\nJ(c^{(1)}, \\cdots, c^{(m)}, \\mu_1, \\cdots, \\mu_k) = \\frac{1}{m} \\sum_{i=1}^{m} \\lVert x^{(i)} - \\mu_{c^{(i)}}\\rVert_2^2\n$$\n其中：$\\mu_{c^{(i)}}$ 表示 $x^{(i)}$ 所属的簇中心；\nPCA 主成分分析（Principal Component Analysis, PCA），解决降维问题。\n用最少的特征尽可能解释所有的方差（越离散方差越大）。\n用途：特征工程，可视化。\n机器学习基础 距离和相似度 距离和相似度常用于分/聚类，距离越近或相似度越高，则被认为可以分/聚为一类。 对于向量 $x,y \\in \\mathbb{R}^n$，或空间中两个点，计算距离可使用差向量的大小的衡量如范数，计算相似度可通过两向量夹角等来衡量。\n闵可夫斯基距离 是含参数 p 的距离函数。当 p 依次取 1, 2, $\\infty$ 时，分别对应曼哈顿距离、欧氏距离、切比雪夫距离；\n$$ \\left(\\sum_{j=1}^{n} {\\lvert x_j - y_j \\rvert}^p\\right)^{1/p} \\tag{$L_p$} $$\n曼哈顿距离 $$ \\sum_{j=1}^{n} \\lvert x_j - y_j \\rvert \\tag{$L_1$} $$\n欧氏距离 $$ \\sqrt{\\sum_{j=1}^{n} (x_j - y_j)^2} \\tag{$L_2$} $$\n切比雪夫距离 $$ \\max_{j} {\\lvert x_j - y_j \\rvert} \\tag{$L_{+\\infty}$} $$\n余弦相似度 使用两个向量夹角的余弦值来衡量相似度，公式如下：\n$$ Cosine \\space Similarity = \\cos(\\theta) = \\frac{x \\cdot y}{\\lVert x \\rVert \\lVert y \\rVert} $$\n说明：由向量点积计算公式推导而来。越接近于 1，夹角越接近于 0，越相似。\n皮尔逊相关系数 使用标准化后的协方差来衡量两个随机变量的线性相关性。\n$$\n\\rho = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y} \\in [-1, 1]\n$$\n说明：越接近于 1 越正线性相关，越接近于 -1 越负线性相关，等于 0 不线性相关。\nKL 散度 给定两个概率分布 $p(x)$ 和 $q(x)$，使用 KL 散度来衡量两者之间的差异程度，公式如下：\n$$ D_{KL}(p||q) = \\sum_x p(x) \\ln \\frac{p(x)}{q(x)} \\in [0, \\infty] $$\n说明：也称作相对熵。非负，越小越相似。\n特征工程 EDA 探索阶段，包括：\n缺失值； 异常值；（PCA 后可视化） 线性相关性； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import pandas as pd import seaborn as sns df = pd.read_csv(\u0026#39;/path/to/xxx.csv\u0026#39;) # 查看前 5 行 df.head() # 查看每列的数据类型 df.info() # 描述性统计: 个数、均值、标准差、最大/小值、四分位数、中位数 df.describe() # 探索特征两两相关性矩阵 (超好用) sns.pairplot(data=df, hue=\u0026#39;your_label\u0026#39;) # 探索单个特征和标签 (小提琴图) sns.catplot(x=\u0026#39;your_feature\u0026#39;, y=\u0026#39;your_label\u0026#39;, hue=\u0026#39;your_label\u0026#39;, kind=\u0026#39;violin\u0026#39;, data=df) 缺失值处理 离散值 删除：缺失比例严重时； 取众数； 逻辑回归：使用完整数据预测缺失数据； 不处理：算法不敏感时，如 XGBoost; 连续值 删除：缺失比例严重时； 取中位数：（相对均值更能兼容偏态分布） 线性回归：使用完整数据预测缺失数据； 不处理：算法不敏感时，如 XGBoost; 异常值处理 如何发现：\nLabelEncoder 主要用于将离散特征的多个（有序）类别，映射为有序数字。例子：\n原特征 新特征 $C_1$ 0 $C_2$ 1 $C_3$ 2 One-Hot 编码 主要用于将离散特征的多个（无序）类别，转为稀疏矩阵。例子：\n原特征 新特征1 新特征2 新特征3 $C_1$ 1 0 0 $C_2$ 0 1 0 $C_3$ 0 0 1 分箱 主要用于连续特征的离散化。例子：\n原特征 新特征 $[0, 60)$ 0 $[60,80)$ 1 $[80,100]$ 2 特征缩放 特征缩放（Feature scaling）主要通过归一化（Normalization）和标准化（Standardization）实现。主要目的是：\n剔除量纲，解决数据可比性问题； 提高求解速度，如运行梯度下降时更快收敛。 最大最小归一化 Min-max normalization (Rescaling)：\n$$\nx^{\\prime} = \\frac{x - min(x)}{max(x) - min(x)}\n$$\n说明：归一化后取值范围为 $[0,1]$，适用于最大最小值较稳定的情况；\n均值归一化 Mean normalization：\n$$\nx^{\\prime} = \\frac{x - \\bar{x}}{max(x) - min(x)}\n$$\n说明：归一化后取值范围为 $[-1,1]$；\nZ 分数归一化 Z-score normalization，也称作标准化(Standardization)：\n$$\nx^{\\prime} = \\frac{x - \\mu}{\\sigma}\n$$\n说明：归一化后取值范围为 $[-\\infty,+\\infty]$，且均值为 $0$，标准差为 $1$；\n特征提取 如从文本、图像中提取机器学习可支持的特征。\n1 from sklearn.feature_extraction.text import CountVectorizer 特征选择 去除变化小（方差小）的特征：\n去除共线（线性相关）的特征：\n损失函数 损失函数用于衡量单个预测值与真实值之间的差异程度。 损失函数通常表示为 $L(\\hat{y}, y)$，成本函数通常表示为 $J = \\frac{1}{m} \\displaystyle \\sum_{i=1}^{m} L\\left(\\hat{y}^{(i)}, y^{(i)}\\right)$.\n最小二乘 适用于回归模型。给定 $\\hat{y},y \\in \\mathbb{R}$，分别表示预测值和真实值，则：\n$$ L(\\hat{y}, y) = \\frac{1}{2} (\\hat{y} - y)^2 $$\n交叉熵 适用于分类模型。将 $\\hat{y},y$ 分别看作 预测类别的分布和真实类别的分布，则：\n$$ L(\\hat{y}, y) = H(y,\\hat{y}) = - \\sum_k y \\ln \\hat{y} $$\n其中 $k$ 为分类的数量，$\\displaystyle\\sum_{k} y = \\sum_{k} \\hat{y} = 1$. 推导详见交叉熵。\n特别的，对于二分类问题：\n$$ L(\\hat{y}, y) = -y\\ln\\hat{y} - (1-y)\\ln(1-\\hat{y}) $$\n举例说明：\n对于二分类，$\\hat{y},y$ 的一组取值形如 $[0.6]$ 和 $[1]$，本质上是 $[0.6, 0.4]$ 和 $[1, 0]$；\n对于三分类问题，$\\hat{y},y$ 的一组取值形如 $[0.1, 0.3, 0.6]$ 和 $[0, 0, 1]$；\n优化算法 梯度下降算法 核心原理是可微函数 在某点沿着梯度反方向，函数值下降最快。 梯度下降（Gradient Descent, GD）是一种迭代优化算法，用于求解任意一个可微函数的局部最小值。在机器学习中，常用于最小化成本函数，即：\n给定成本函数 $J(w,b)$，求解一组 $(w,b)$，使得\n$$ arg\\min_{w,b} J(w,b) $$\n实现方法 步骤一：选定初始点 $(w_{init},b_{init})$；\n步骤二：为了使函数值下降，需要沿着梯度反方向迭代，即重复以下步骤，直至收敛，即可得到局部最小值的解：\n$$\nw \\leftarrow w - \\alpha \\frac{\\partial J}{\\partial w}\n$$\n$$\nb \\leftarrow b - \\alpha \\frac{\\partial J}{\\partial b}\n$$\n即：\n$$\n\\begin{equation}\n\\begin{pmatrix}\nw_1 \\\\\nw_2 \\\\\n\\vdots \\\\\nw_n \\\\\nb\n\\end{pmatrix}\n\\leftarrow\n\\begin{pmatrix}\nw_1 \\\\\nw_2 \\\\\n\\vdots \\\\\nw_n \\\\\nb\n\\end{pmatrix}\n- \\alpha\n\\begin{pmatrix}\n\\frac{\\partial J}{\\partial w_1} \\\\\n\\frac{\\partial J}{\\partial w_2} \\\\\n\\vdots \\\\\n\\frac{\\partial J}{\\partial w_n} \\\\\n\\frac{\\partial J}{\\partial b}\n\\end{pmatrix}\n\\end{equation}\n$$\n其中：$\\alpha \\geq 0$ 指学习率（Learning rate），也称作步长，决定了迭代的次数。\n批量梯度下降 （Batch Gradient Descent, BGD）：使用训练集中的所有数据\n随机梯度下降 （stotastic gradient descent, SGD）：？？根据每个训练样本进行参数更新\n模型评估 过拟合问题 定义过拟合：训练方差小，测试方差大。\n解决过拟合的方法：\n收集更多的训练示例； 特征选择； 正则化； 评估方法 留出法（Hold-out）：拆分训练集和测试集，如经验上 8/2 或 7/3；\n交叉验证法（Cross Validation）：将数据集分成 N 块，使用 N-1 块进行训练，再用最后一块进行测试；\n自助法（Bootstrap）：有放回随机抽样；\n回归指标 MAE MAE（Mean Absolute Error），平均绝对误差。\n$$ MAE = \\frac{1}{m} \\sum_{i=1}^{m} \\lvert \\hat{y}^{(i)} - y^{(i)} \\rvert $$\nMAPE MAPE（Mean Absolute Percentage Error），平均绝对百分误差。\n$$ MAPE = \\frac{100}{m} \\sum_{i=1}^{m} \\lvert \\frac{y^{(i)} - \\hat{y}^{(i)}}{y^{(i)}} \\rvert $$\nMSE MSE（Mean Squared Error），均方误差。最小二乘的均值版，常用于回归模型。\n$$ MSE = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 $$\nRMSE RMSE（Root Mean Square Error），均方根误差。\n$$ RMSE = \\sqrt{MSE} $$\nR2 R2 (coefficient of determination)，决定系数。衡量总误差（客观存在且无关回归模型）中可以被回归模型解释的比例，即拟合程度。\n$$ R^2 = \\frac{SSR}{SST} = 1- \\frac{SSE}{SST} $$\n说明：\n当 $R^2 \\to 1$ 时，表明拟合程度越好，因为此时 SSR 趋向于 SST（或 SSE 趋向于 0）；\n当 $R^2 \\to 0$ 时，表明拟合程度越差，因为此时 SSR 趋向于 0（或 SSE 趋向于 SST）；\n关于 SST/SSR/SSE 助记小技巧：T is short for total, R is short for regression, E is short for error. SST (sum of squares total)，总平方和，用于衡量真实值相对均值的离散程度。SST 客观存在且与回归模型无关；\n$$ SST = \\sum_{i=1}^{m} (y^{(i)} - \\bar{y})^2 $$\nSSR (sum of squares due to regression)，回归平方和，用于衡量预测值相对均值的离散程度。当 SSR = SST 时，回归模型完美；\n$$ SSR = \\sum_{i=1}^{m} (\\hat{y}^{(i)} - \\bar{y})^2 $$\nSSE (sum of squares error)，误差平方和，用于衡量预测值相对真实值的离散程度；\n$$ SSE = \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 $$\n且三者之间的关系是 $SST = SSR + SSE$.\n分类指标 二分类问题的混淆矩阵（Confusion Matrix）如下：\nactual/predicted Positive Negative Positive TP（真阳） FN（假阴） Negative FP（假阳） TN（真阴） 其中：T/F 表示预测是否正确，P/N 表示预测结果（P=1, N=0）。\n准确率 指预测正确的比例，即：\n$$ accuracy = \\frac{TP+TN}{TP+TN+FP+FN} $$\n精确率 也称作查准率，指预测为正的样本中，实际也为正的比例，即：\n$$ precision = \\frac{True \\space P}{predicted \\space P} = \\frac{TP}{TP+FP} $$\n召回率 也称作查全率，指实际为正的样本中，判定也为正的比例，即：\n$$ recall = \\frac{True \\space P}{actual \\space P} = \\frac{TP}{TP+FN} $$\nF1 $$ F1 = \\frac{2 \\times precision \\times recall}{precision + recall} $$\nROC 曲线 指以 FPR 为横轴, TPR 为纵轴绘制成的曲线。其中：\nFPR 指假阳率，也称作误诊率，指实际为阴，但判定为阳的比例，即：\n$$ FPR = \\frac{FP}{FP+TN} $$\nTPR 指真阳率，就是召回率，指实际为阳，判断也为阳的比例，即：\n$$ TPR = \\frac{TP}{TP+FN} $$\n说明：FPR 越低，TPR 越高，也就是越靠近 (0, 1)，说明模型分类能力越好。\nAUC AUC (Area Under ROC Curve)指的是 ROC 曲线下方的面积，相较于 ROC，是一个直观的标量来衡量模型分类能力。\n$AUC=1$: 即左上角，完美分类； $AUC=0.5$: 即分类能力与随机的抛硬币毫无差异，比较差； $AUC\u0026lt;0.5$: 分类能力很差，反着来； 实际中，一般在 $0.5 \\to 1$ 之间。\nPR 曲线 指以 Recall 为横轴, precision 为纵轴绘制成的曲线。\n数学基础 矩 一阶原点矩是期望值，二阶中心矩是方差，三阶标准矩是偏度，四阶标准矩减常数3是峰度，二阶混合中心矩是协方差。 设随机变量 $X$ 和 $Y$，正整数 $k$ 和 $l$.\n原点矩 原点指坐标原点。$X$ 的 $k$ 阶原点矩：\n$$ E(X^k) $$\n中心矩 中心指期望值。$X$ 的 $k$ 阶中心矩记作 $\\mu_k$：\n$$ \\mu_k = E\\lbrack X - E(X)\\rbrack^k $$\n标准矩 标准化指除以标准差以剔除量纲，标准矩是标准化的中心矩。$X$ 的 $k$ 阶标准矩：\n$$\n\\frac{\\mu_k}{\\sigma^k} = \\frac{\\mu_k}{\\mu_2^{\\frac{k}{2}}} = \\frac{E\\lbrack X - E(X)\\rbrack^k}{\\left(E\\lbrack X - E(X)\\rbrack^2\\right)^{\\frac{k}{2}}}\n$$\n混合矩 $X$ 和 $Y$ 的 $k+l$ 阶混合矩：\n$$ E(X^kY^l) $$\n混合中心矩 $X$ 和 $Y$ 的 $k+l$ 阶混合中心矩：\n$$ E\\lbrace\\lbrack X - E(X)\\rbrack^k \\lbrack Y - E(Y)\\rbrack^l \\rbrace $$\n统计指标 注意这里不严格区分总体和样本，并使用样本估计整体。\n极差 $$ \\max(x) - \\min(x) $$\n期望值 这里使用样本均值估计总体期望值。\n$$\n\\begin{split}\n\\mu \u0026amp;= E(X) = \\sum_{j=1}^{N} p(x_j) x_j \\\\\n\u0026amp;\\approx \\bar{x} = \\frac{1}{n} \\sum_{j=1}^{n} x_j\n\\end{split}\n$$\n说明：根据强大数定律，当 n 趋向于无穷时，样本均值依概率 1 收敛于期望值。 期望值与均值 总体期望值是常数标量，样本均值依赖于具体的随机抽样。\n如抛硬币（伯努利试验），总体期望值是 $0.5 * 1 + 0.5 * 0 = 0.5$，但样本均值比如抛 3 次 $(1+1+0)/3 \\neq 0.5$.\n方差 方差（Variance）用于衡量相对均值的离散程度。\n$$\n\\begin{split}\n\\sigma^2 \u0026amp;= Var(X) = E\\lbrack X - E(X)\\rbrack^2 = \\sum_{j=1}^{N} p(x_j)(x_j - \\mu)^2 \\\\\n\u0026amp;\\approx \\frac{1}{n} \\sum_{j=1}^{n} (x_j - \\bar{x})^2\n\\end{split}\n$$\n说明：越大，越扁，越离散，熵越大。\n标准差 标准差（Standard deviation）是方差的正平方根。\n$$ \\sigma = \\sqrt{\\sigma^2} $$\n协方差 协方差（Covariance）用于衡量两个变量的线性相关性。\n$$\nCov(X,Y) = E\\lbrace\\lbrack X - E(X)\\rbrack \\lbrack Y - E(Y)\\rbrack \\rbrace\n$$\n说明：$Cov(X,X) = Var(X)$，即方差是协方差的特殊情形。\n相关系数 标准化的协方差。\n$$\n\\rho = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}\n$$\n偏度 偏度（Skewness）用于衡量分布的对称性。\n$$\nSkewness = \\frac{\\mu_3}{\\sigma^3} = \\frac{\\mu_3}{\\mu_2^{\\frac{3}{2}}}\n$$\n说明：尾巴在哪边就偏哪边。\n峰度 峰度（Kurtosis）用于衡量相对高斯分布的陡峭程度。\n$$\nKurtosis = \\frac{\\mu_4}{\\sigma^4} - 3 = \\frac{\\mu_4}{\\mu_2^2} - 3\n$$\n说明：减常数 3 是为了使高斯分布的峰度为零。\n导数 一阶导用于单调性判断，二阶导用于凹凸性判断。 给定函数 $f: \\mathbb{R} \\to \\mathbb{R}$，则 $f$ 在点 $x$ 处的一阶导数 $f\u0026rsquo;$ 和二阶导数 $f\u0026rsquo;\u0026rsquo;$ 的定义分别如下：\n$$\nf\u0026rsquo; = \\frac{dy}{dx} = \\lim_{{\\Delta x} \\to 0} \\frac{f(x + {\\Delta x})}{\\Delta x}\n$$\n$$ f\u0026rsquo;\u0026rsquo; = (f\u0026rsquo;)\u0026rsquo; = \\frac{d^2y}{dx^2} $$\n注意：可导等于可微，可导一定连续；\n说明：一阶导表示函数在该点处的瞬时变化率；\n用途：一阶导用于判断单调性；二阶导用于判断凹凸性，大于零则凸（U 型）。\n偏导数 给定函数 $f: \\mathbb{R}^n \\to \\mathbb{R}$，则 $f$ 对自变量 $x_j$ 的偏导数（partial derivative），指将其他自变量视作常量时，对 $x_j$ 的导数，即：\n$$\n\\frac{\\partial f}{\\partial x_j} = \\lim_{{\\Delta x_j} \\to 0} \\frac{f(x_j + {\\Delta x_j}, \u0026hellip;) - f(x_j, \u0026hellip;)}{\\Delta x_j}\n$$\n注意：可微一定可导，可微一定连续。\n梯度 梯度是一个向量，沿着梯度方向函数值上升最快，逆着梯度方向函数值下降最快。 给定可微函数 $f: \\mathbb{R}^n \\to \\mathbb{R}$，则 $f$ 的偏导数构成的向量，称为梯度，记作 $grad f$ 或 $\\nabla f$，即：\n$$\ngrad f = \\nabla f =\n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\\n\\frac{\\partial f}{\\partial x_2} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{bmatrix} \\in \\mathbb{R}^n\n$$\n用途：梯度下降算法\n凸函数 如果一个函数满足任意两点连成的线段都位于函数图形的上方，则称这个函数为凸函数（Convex function）。\n凸函数的局部最小值等于极小值，可作为选择损失函数的重要参考。\n向量 点积是标量，叉积是向量，外积是矩阵。 n 维向量 $x$ 记作：\n$$\nx = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\in \\mathbb{R}^n\n$$\n说明：本文一律默认列向量，在 Python 中对应一维数组。$x$ 也可视作一个 $n \\times 1$ 矩阵。\n数乘 几何意义是向量的伸缩 (stretch)。\n加法 几何意义是向量的旋转 (rotate)。\n点积 点积（Dot product），也称作点乘、内积、数量积。对于 $x,y \\in \\mathbb{R}^n$：\n$$\nx \\cdot y = x^Ty = \\sum_{j=1}^{n} x_jy_j \\in \\mathbb{R}\n$$\n注意：相同维数才能进行点积乘法；\n说明：几何意义是向量围成的平面的面积或空间的体积（有正负号），大小等于 $\\lVert x \\rVert \\lVert y \\rVert\\cos(\\theta)$，其中 $\\theta$ 为两向量之间的夹角；\n用途：余弦相似度\n叉积 叉积（Cross product），也称作叉乘、向量积。对于 $x,y \\in \\mathbb{R}^3$：\n$$\n\\begin{split}\nx \\times y \u0026amp;=\n\\left|\n\\begin{matrix}\n\\vec{i} \u0026amp; \\vec{j} \u0026amp; \\vec{k} \\\\\nx_1 \u0026amp; x_2 \u0026amp; x_3 \\\\\ny_1 \u0026amp; y_2 \u0026amp; y_3\n\\end{matrix}\n\\right| \\\\\n\\\\\u0026amp;= (x_2y_3-x_3y_2)\\vec{i} - (x_1y_3-x_3y_1)\\vec{j} + (x_1y_2-x_2y_1)\\vec{k} \\\\\n\\\\\u0026amp;= \\begin{bmatrix}x_2y_3-x_3y_2 \\\\ -(x_1y_3-x_3y_1) \\\\ x_1y_2-x_2y_1 \\end{bmatrix} \\in \\mathbb{R}^3\n\\end{split}\n$$\n注意：叉积的概念仅用于三维空间。这里的公式表达使用了行列式和代数余子式；\n说明：几何意义是法向量，大小等于 $\\lVert x \\rVert \\lVert y \\rVert \\sin(\\theta)$，其中 $\\theta$ 为两向量之间的夹角。\n外积 外积（Outer product）。对于 $x \\in \\mathbb{R}^m, y \\in \\mathbb{R}^n$：\n$$\nx \\otimes y = xy^T =\n\\begin{bmatrix}\nx_1y_1 \u0026amp; x_1y_2 \u0026amp; \\dots \u0026amp; x_1y_n \\\\\nx_2y_1 \u0026amp; x_2y_2 \u0026amp; \\dots \u0026amp; x_2y_n \\\\\n\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\nx_my_1 \u0026amp; x_my_2 \u0026amp; \\dots \u0026amp; x_my_n\n\\end{bmatrix}\n\\in \\mathbb{R}^{m \\times n}\n$$\n说明：运算结果是个矩阵。\n矩阵 $m \\times n$ 矩阵可理解为 n 个列向量的集合（或 m 个行向量的集合）。\n线性组合 向量的线性组合，就是先各自数乘再相加，结果仍是同维向量。 设有 n 个 m 维向量 $x_1,x_2,\u0026hellip;,x_n$ 和 n 个标量 $w_1,w_2,\u0026hellip;,w_n$，则该 n 个向量的线性组合 $y$ 表示如下：\n$$ y = w_1x_1 + w_2x_2 + \\cdots + w_nx_n \\in \\mathbb{R}^m $$\n说明：线性空间内，数乘运算本质上是向量的伸缩，加法运算本质上是向量的旋转。线性运算并没有对向量进行扭曲和变形。\n线性相关 n 个线性无关的向量，可作为基向量，张成一个 n 维线性空间。 对于 n 个向量 $x_1,x_2,\u0026hellip;,x_n$，令其线性组合为零向量，即：\n$$ w_1x_1 + w_2x_2 + \\cdots + w_nx_n = \\vec{0} $$\n如果当且仅当 $w_1 = w_2 = \\cdots = w_n = 0$ 即全部系数为零时才成立，则称该 n 个向量线性无关，否则线性相关。\n说明：线性相关，则其中一个可以用其余的线性组合表示，此时可降维。\n线性无关，对于 n 取 2 就是两个向量不共线，对于 n 取 3 就是三个向量不共面。 秩 矩阵的秩等于线性无关的列向量的个数。满秩则线性无关，不满秩则线性相关。 矩阵的秩（Rank）记作 $rank$，且秩 = 列秩 = 行秩。\n对于 $X \\in \\mathbb{R}^{m \\times n}$，由于实际中 $m \\gg n$，因此其秩由 $n$ 决定。且：\n若 $rank(X) = n$，即列满秩，则 n 个特征线性无关； 若 $rank(X) \u0026lt; n$，即列不满秩，则 n 个特征线性相关，此时可降维。 行列式 行列式（Determinant）针对的是方阵。对于方阵 $X \\in \\mathbb{R}^{n \\times n}$，其行列式记作 $\\det(X)$，且：\n若满秩则 $det(X) \\neq 0$，称为非奇异矩阵；\n若不满秩则 $det(X) = 0$，称为奇异矩阵；\n说明：奇异矩阵无法求逆矩阵。\n线性变换 矩阵是一次线性变换。 回忆线性组合，可将其写为矩阵乘向量即 $Xw=y$ 的形式：\n$$\n\\begin{split}\n\\begin{bmatrix}x_{11} \u0026amp; x_{12} \u0026amp; \\cdots \u0026amp; x_{1n} \\\\ x_{21} \u0026amp; x_{22} \u0026amp; \\cdots \u0026amp; x_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp;\\vdots \\\\ x_{m1} \u0026amp; x_{m2} \u0026amp; \\cdots \u0026amp; x_{mn} \\end{bmatrix}\n\\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix}\n\u0026amp;= \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_m \\end{bmatrix}\n\\end{split}\n$$\n理解上述式子：\n代数角度：n 个列向量的线性组合； 几何角度：对 n 个列向量先各自缩放再旋转； 线性变换的几何角度：将向量 $w$ 线性变换至 $y$，具体指： 输入向量：$w$ 线性变换：$X$，其中 n 个列向量可视作伪基向量； 输出向量：$y$ 矩阵乘向量 矩阵乘向量的结果是向量，可理解为对向量进行一次线性变换。 例子：\n$$\n\\begin{bmatrix}a \u0026amp; b \u0026amp; c \\\\ d \u0026amp; e \u0026amp; f \\\\ g \u0026amp; h \u0026amp; i \\end{bmatrix}\n\\begin{bmatrix}x \\\\ y \\\\ z \\end{bmatrix} =\nx \\begin{bmatrix}a \\\\ d \\\\ g \\end{bmatrix} +\ny \\begin{bmatrix}b \\\\ e \\\\ h \\end{bmatrix} +\nz \\begin{bmatrix}c \\\\ f \\\\ i \\end{bmatrix} =\n\\begin{bmatrix}ax+by+cz \\\\ dx+ey+fz \\\\ gx+hy+iz \\end{bmatrix}\n$$\n特别的，当取正交单位矩阵时，该向量经过线性变化后，仍等于该向量。\n$$\n\\begin{bmatrix}1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\n\\begin{bmatrix}x \\\\ y \\\\ z \\end{bmatrix} =\nx \\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\end{bmatrix} +\ny \\begin{bmatrix}0 \\\\ 1 \\\\ 0 \\end{bmatrix} +\nz \\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\end{bmatrix} =\n\\begin{bmatrix}x \\\\ y \\\\ z \\end{bmatrix}\n$$\n矩阵乘矩阵 矩阵乘矩阵的结果是矩阵，可理解为两次线性变换的叠加（自右向左）。 例子：\n特征值与特征向量 给定方阵 $A \\in \\mathbb{R}^{n \\times n}$，若存在非零向量 $v \\in \\mathbb{R}^n$ 和非零标量 $\\lambda \\in \\mathbb{R}$，使得：\n$$\nAv = \\lambda v\n$$\n则称 $v$ 为方阵 $A$ 的特征向量，$\\lambda$ 为对应的特征值。\n理解：$v$ 在 $A$ 线性变换的作用下，仅发生了数乘 $\\lambda v$，几何意义上即仅发生了缩放。\n特征分解 特征分解的结果是三个矩阵相乘，即三次线性变换的叠加。自右向左，先旋转，再伸缩，最后再旋转。 特征分解是一种矩阵分解，且针对的是方阵。给定方阵 $A \\in \\mathbb{R}^{n \\times n}$，则可将其分解为三个矩阵相乘：\n$$\nA = V diag(\\lambda) V^{-1}\n$$\n其中：\n$V \\in \\mathbb{R}^{n \\times n}$：指 $A$ 的 n 个特征向量组成的正交矩阵； $diag(\\lambda) \\in \\mathbb{R}^{n \\times n}$：指对应 n 个特征值在对角线上的对角矩阵； $V^{-1}$：指 $V$ 的逆矩阵； 例子（以下四个矩阵依次对应 $A, V, diag(\\lambda), V^{-1}$）：\n$$\n\\begin{bmatrix}1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} =\n\\begin{bmatrix}0 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\n\\begin{bmatrix}1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix}\n\\begin{bmatrix}0 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\n$$\n理解：向量 $\\begin{bmatrix}1 \u0026amp; 1 \u0026amp; 0 \\end{bmatrix}^T$ 和 $\\begin{bmatrix}1 \u0026amp; 1 \\end{bmatrix}^T$ 本质上一个属于三维，一个属于二维。\n奇异值分解 奇异值分解（SVD）是特征分解推广到一般矩阵的情形，可用于升/降维。 给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$，则可将其分解为三个矩阵相乘：\n$$\nA = U \\Sigma V^T\n$$\n其中：\n$U \\in \\mathbb{R}^{m \\times m}$：指 $AA^T$ 的 m 个特征向量组成的左正交矩阵； $\\Sigma \\in \\mathbb{R}^{m \\times n}$：指对角阵，对角线上的 $\\sigma$ 称为奇异值，非负且降序排列，可理解为特征的权重； 形如 $\\begin{bmatrix}\\sigma_1 \u0026amp; 0 \\\\ 0 \u0026amp; \\sigma_2 \\\\ 0 \u0026amp; 0 \\end{bmatrix}$ 时，起到降维的作用； 形如 $\\begin{bmatrix}\\sigma_1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; \\sigma_2 \u0026amp; 0 \\end{bmatrix}$ 时，起到升维的作用； $V^T \\in \\mathbb{R}^{n \\times n}$：指 $A^TA$ 的 n 个特征向量组成的右正交矩阵； 降维的原理，即取前 k 个权重高的特征来近似表示整个矩阵：\n$$\nA_{m \\times n} =\nU_{m \\times m} \\Sigma_{m \\times n} V_{n \\times n}^T \\approx\nU_{m \\times k} \\Sigma_{k \\times k} V_{k \\times n}^T\n$$\n降维例子（以下四个矩阵依次对应 $A, U, \\Sigma, V^T$）：\n$$\n\\begin{split}\n\\begin{bmatrix}1 \u0026amp; 2 \\\\ 3 \u0026amp; 4 \\\\ 5 \u0026amp; 6 \\end{bmatrix} \u0026amp;=\n\\begin{bmatrix}-0.2298477 \u0026amp; 0.88346102 \u0026amp; 0.40824829 \\\\ -0.52474482 \u0026amp; 0.24078249 \u0026amp; -0.81649658 \\\\ -0.81964194 \u0026amp; -0.40189603 \u0026amp; 0.40824829 \\end{bmatrix}\n\\begin{bmatrix}9.52551809 \u0026amp; 0 \\\\ 0 \u0026amp; 0.51430058 \\\\ 0 \u0026amp; 0 \\end{bmatrix}\n\\begin{bmatrix}-0.61962948 \u0026amp; -0.78489445 \\\\ -0.78489445 \u0026amp; 0.61962948 \\end{bmatrix} \\\\\n\\\\ \u0026amp;\\approx\n\\begin{bmatrix}-0.2298477 \u0026amp; 0.88346102 \\\\ -0.52474482 \u0026amp; 0.24078249 \\\\ -0.81964194 \u0026amp; -0.40189603 \\end{bmatrix}\n\\begin{bmatrix}9.52551809 \u0026amp; 0 \\\\ 0 \u0026amp; 0.51430058 \\end{bmatrix}\n\\begin{bmatrix}-0.61962948 \u0026amp; -0.78489445 \\\\ -0.78489445 \u0026amp; 0.61962948 \\end{bmatrix}\n\\end{split}\n$$\n范数 范数是一个函数，用于量化向量或矩阵的大小，即将向量或矩阵映射为一个标量。 向量范数 n 维向量 $x$ 的 p 范数定义如下：\n$$\nL_p(x) = \\lVert x \\rVert_p = \\left(\\sum_{j=1}^{n} {\\lvert x_j \\rvert}^p\\right)^{1/p}\n$$\n则当 p 依次取 $-\\infty, 1, 2, +\\infty$ 时，分别对应如下范数：\n$$\n\\lVert x \\rVert_{-\\infty} = \\lim_{p \\to -\\infty} \\left(\\sum_{j=1}^{n} {\\lvert x_j \\rvert}^p\\right)^{1/p} =\n\\min_{j} {\\lvert x_j \\rvert} \\tag{$L_{-\\infty}$}\n$$\n$$\n\\lVert x \\rVert_1 = \\sum_{j=1}^{n} {\\lvert x_j \\rvert} \\tag{$L_1$}\n$$\n$$\n\\lVert x \\rVert_2 = \\left(\\sum_{j=1}^{n} {\\lvert x_j \\rvert}^2\\right)^{1/2} \\tag{$L_2$}\n$$\n$$\n\\lVert x \\rVert_{+\\infty} = \\lim_{p \\to +\\infty} \\left(\\sum_{j=1}^{n} {\\lvert x_j \\rvert}^p\\right)^{1/p} =\n\\max_{j} {\\lvert x_j \\rvert} \\tag{$L_{+\\infty}$}\n$$\n补充说明：\nL1 范数，也称作曼哈顿距离； L2 范数，也称作欧氏距离，可用于计算向量的模（本文默认省略下标 2）； L$+\\infty$ 范数，也称作切比雪夫距离或最大范数； 矩阵范数 极大似然估计 极大似然估计是一种已知样本数据估计（反推）概率分布参数的方法。 极大似然估计（Maximum Likelihood Estimation）的思想是，假设 m 个样本独立同分布于目标概率分布函数 $p(x;\\theta)$，然后构造一个似然函数 $L(\\theta)$ 来表示 m 个样本的联合概率，通过最大化这个联合概率来求解参数 $\\theta$，即：\n$$ L(\\theta) = p(x^{(1)}, x^{(2)}, \\cdots, x^{(m)}) = \\prod_{i=1}^{m} p(x^{(i)};\\theta) $$\n其中 $\\lbrace x^{(1)}, x^{(2)}, \\cdots, x^{(m)} \\rbrace$ 为已知样本数据。\n说明：由于假设样本独立同分布，则联合概率等于各自概率的乘积。\n贝叶斯定理 贝叶斯定理（Bayes\u0026rsquo;theorem）公式如下（其中 $P(B) \\neq 0$）：\n$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n说明：\n可由条件概率 $P(A,B) = P(A|B)P(B) = P(B|A)P(A)$ 推导得到； $P(A|B)$ 是 $A$ 的后验概率，$P(A)$ 是 $A$ 的先验概率，$\\frac{P(B|A)}{P(B)}$ 称作标准似然度，因此贝叶斯公式可表示为：$$ A 的后验概率 = A 的先验概率 * 标准似然度 $$ 基础知识背景见下方。\n联合概率 $A$ 和 $B$ 同时发生的概率，记作 $P(A,B)$ 或 $P(AB)$ 或 $P(A \\cap B)$.\n条件概率 $B$ 发生的条件下 $A$ 发生的概率，记作 $A$ 的条件概率 $P(A|B)$，其中 $P(B) \\neq 0$：$$ P(A|B) = \\frac{P(A,B)}{P(B)} $$\n先验概率 以经验进行判断，如 $P(A)$.\n后验概率 以结果进行判断。当条件概率 $P(A|B)$ 中隐含 $A$（因）会导致 $B$（果）发生时，则称此条件概率为 $A$ 的后验概率，可理解为 $P(因|果)$。\n相互独立 $A$ 与 $B$ 相互独立，当且仅当以下成立：\n$$P(A,B) = P(A)P(B)$$\n朴素贝叶斯朴素在假设特征之间相互独立。 概率分布函数 离散型随机变量对应概率质量函数（Probability Mass Function, PMF），连续型随机变量对应概率密度函数（Probability Density Function, PDF）。\n均匀分布 随机变量 $X = \\lbrace a_1,a_2,\\cdots,a_n \\rbrace$ 服从均匀分布，则：\n$$ p(X=x) = \\frac{1}{n} \\tag{PMF} $$\n随机变量 $X \\in [a,b]$ 服从均匀分布，则：\n$$\np(X=x) =\n\\begin{cases}\n\\frac{1}{b-a} \u0026amp; \\text{if $x \\in [a,b]$} \\\\\n\\\\0 \u0026amp; \\text{if $x \\notin [a,b]$}\n\\end{cases} \\tag{PDF}\n$$\n伯努利分布 一次伯努利试验对应伯努利分布。 指每次试验的结果只有两种可能，要么成功（1），要么失败（0）。设成功（1）的概率为 $p$，则成功（1）发生的次数 $X$ 服从伯努利分布，记作：\n$$\nX \\sim Bernoulli(p)\n$$\n其中 $x \\in \\lbrace 0, 1 \\rbrace$，有：\n$$\np(X=x;p) = p^x(1-p)^{1-x} \\tag{PMF}\n$$\n$$ \\mu = p $$\n$$ \\sigma^2 = p(1-p) $$\n说明：上述试验称为伯努利试验。\n二项分布 重复 n 次伯努利试验即得到二项分布。 指每次试验的结果只有两种可能，重复 n 次试验，设成功（1）的概率为 $p$，则成功（1）发生的次数 $X$ 服从二项分布，记作：\n$$\nX \\sim B(n, p)\n$$\n其中 $x \\in \\lbrace 0, 1, \u0026hellip;, n \\rbrace$，有：\n$$\np(X=x;n,p) = \\frac{n!}{x!(n-x)!} p^x (1-p)^{n-x} \\tag{PMF}\n$$\n$$ \\mu = np $$\n$$ \\sigma^2 = np(1-p) $$\n多项分布 多项分布是二项分布推广到每次试验的结果有 k 种可能的情形。 指每次试验的结果有 k 种可能，重复 n 次试验，设结果 $j$ 的概率为 $p_j$，则所有结果发生的次数 $X = (X_1, \\cdots, X_k)$ 服从多项分布，记作：\n$$\nX \\sim M(n, p_1, \\cdots, p_k)\n$$\n其中 $x_j \\in \\lbrace 0,\\cdots n \\rbrace, \\sum_{j=1}^k x_j = n$，有：\n$$\np(X_1=x_1,\\cdots,X_k=x_k;n,p_1,\\cdots,p_k) = \\frac{n!}{x_1! \\cdots x_k!} p_1^{x_1} \\cdots p_k^{x_k} \\tag{PMF}\n$$\n说明：\n当 $k=2,n=1$ 时对应伯努利分布； 当 $k=2,n\u0026gt;1$ 时对应二项分布； 当 $k\u0026gt;2,n\u0026gt;1$ 时对应多项分布。 泊松分布 泊松分布是二项分布中 p 很小 n 很大时的一种极限形式。 指单位时间内，若随机事件发生的次数的期望值为 $\\lambda$，则随机事件发生的次数 $X$ 服从泊松分布，记作：\n$$\nX \\sim Poisson(\\lambda)\n$$\n其中 $x \\in \\lbrace 0, 1, \\cdots \\rbrace$，有：\n$$\np(X=x;\\lambda) = \\frac{\\lambda^x}{x!} e^{- \\lambda} \\tag{PMF}\n$$\n$$ \\mu = \\lambda $$\n$$ \\sigma^2 = \\lambda $$\n高斯分布 随机变量 $X$ 服从均值 $\\mu$，方差 $\\sigma^2$ 的高斯（正态）分布，记作：\n$$\nX \\sim N(\\mu, \\sigma^2)\n$$\n其中 $x \\in [-\\infty, +\\infty]$，有：\n$$\np(X=x;\\mu,\\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{(x-\\mu)^2} {2 \\sigma^2}\\right) \\tag{PDF}\n$$\n说明：方差越大，分布越分散（混乱），越扁，熵越大（平均信息量越大）。\n指数分布 指单位时间内，若随机事件发生的次数的期望值为 $\\lambda$，则随机事件发生的时间间隔 $X$ 服从指数分布，记作：\n$$\nX \\sim \\exp(\\lambda)\n$$\n其中 $x \\in [0, +\\infty]$，有：\n$$\np(X=x;\\lambda) = \\lambda e^{-\\lambda x} \\tag{PDF}\n$$\n$$ \\mu = \\frac{1}{\\lambda} $$\n$$ \\sigma^2 = \\frac{1}{\\lambda^2} $$\n熵 信息量是信息的大小，熵是信息量的期望值，相对熵用于衡量两个概率分布之间的差异，交叉熵是相对熵的简化版。 信息量 给定随机变量 $X$ 的概率分布 $p(x) \\in [0,1]$，则当 $X=x$ 发生时，$x$ 的信息量定义如下：\n$$ I(x) = \\ln \\frac{1}{p(x)} = - \\ln p(x) $$\n其中 $\\displaystyle \\sum_x p(x) = 1$.\n说明：\n信息量针对的是单一事件，大小仅受概率影响。概率越小，信息量越大； 对数底数仅影响量化的单位，以 2 为底对应比特，以 e 为底对应纳特（默认）。 熵 熵（Entropy）等于随机变量 $X$ 所有可能取值的 信息量的期望值，用于衡量混乱程度或不确定性，定义如下：\n$$\nH(X) = E(I(x)) = \\sum_x p(x) I(x) = - \\sum_x p(x) \\ln p(x)\n$$\n说明：\n熵针对的是整个概率分布，也记作 $H(p)$。熵越大（平均信息量越大），分布越混乱； 离散型随机变量对应求和，连续型随机变量对应求积分（已省略）； 相对熵 相对熵（Relative Entropy），又称为 KL 散度（Kullback-Leibler divergence），用于衡量两个概率分布之间的差异程度。对于随机变量 $X$ 的两个概率分布 $p(x)$ 和 $q(x)$，其相对熵定义如下：\n$$ D_{KL}(p||q) = \\sum_x p(x) \\ln \\frac{p(x)}{q(x)} $$\n说明：非负，且越小，则 $p(x)$ 和 $q(x)$ 分布越接近；\n证明：相对熵非负 由于 $\\ln(x) \\leq x - 1$，则：\n$$\n\\begin{split}\n- D_{KL}(p||q) \u0026amp;= \\sum_x p(x) \\ln \\frac{q(x)}{p(x)} \\\\\n\u0026amp;\\leq \\sum_x p(x) (\\frac{q(x)}{p(x)} - 1) \u0026amp;= \\sum_x (q(x) - p(x)) = 0\n\\end{split}\n$$\n因此 $D_{KL}(p||q) \\geq 0$，当且仅当 $p(x) = q(x)$ 时为零。\n交叉熵 将上述相对熵公式展开：\n$$\n\\begin{split}\nD_{KL}(p||q) \u0026amp;= \\sum_x p(x) \\ln \\frac{p(x)}{q(x)} \\\\\n\\\\\u0026amp;= \\sum_x p(x) \\ln p(x) - \\sum_x p(x) \\ln q(x) \\\\\n\\\\\u0026amp;= -H(p) + H(p,q)\n\\end{split}\n$$\n其中，前半部分就是负的 $p(x)$ 的熵，后半部分则就是交叉熵（Cross Entropy）：$$ H(p,q) = - \\sum_x p(x) \\ln q(x) $$\n实际应用中，如果将 $p(x)$ 和 $q(x)$ 分别作为真实值和预测值的概率分布，则由于前者的熵 $H(p)$ 是一个常数，因此：\n$$ D_{KL}(p||q) \\simeq H(p,q)$$\n条件熵 给定随机变量 $X$ 和 $Y$ 及对应的概率分布 $p(x)$ 和 $p(y)$，则顾名思义条件熵定义如下：\n$$\nH(Y|X) = \\sum_{x} p(x) H(Y|x) = \\sum_{x} p(x) \\sum_{y} p(y|x) \\ln(p(y|x))\n$$\n说明：可理解为原数据集是 $Y$，条件（特征）$X$ 将原数据集分组后，新的一组数据集 $Y|X$ 的熵。从全概率公式角度理解，$\\displaystyle\\sum_{condition} p(condition) H(goal|condition)$.\n用途：决策树\n信息增益 分组使得熵减（数据纯度提升），熵减的大小就是信息增益。\n$$\nGain(Y, X) = H(Y) - H(Y|X)\n$$\n用途：决策树 ID3 算法\n信息增益率 分组后信息增益与条件的熵的比值。\n$$\nr(Y, X) = \\frac{Gain(Y, X)}{H(X)}\n$$\n用途：决策树 C4.5 算法\n","description":"监督学习包括线性回归，逻辑回归，SVM，朴素贝叶斯，决策树，随机森林，XGBoost；无监督学习包括 K-means，PCA 等。附带复习相关数学基础。","id":16,"section":"posts","tags":["sklearn"],"title":"学习笔记：吴恩达机器学习","uri":"https://mollywangup.com/posts/notes-machine-learning/"},{"content":"本笔记基于以下学习资料（侧重实际应用）：\n入门机器学习：(强推|双字)2022吴恩达机器学习Deeplearning.ai课程\nPython 代码库：scikit-learn 官网\n复习线性代数：3Blue1Brown 的 线性代数的本质 - 系列合集\n统一口径 术语 特征（feature）：指输入变量； 标签（label）：指输出变量，真实值（target 或 ground truth），预测值（prediction）； 训练集（training set）：用于训练模型； 验证集（validation set）：用于防止模型过拟合； 测试集（test set）：用于评估模型效果； 训练示例（training example）：指训练集中的一组数据； 模型（model）：指拟合函数或概率模型； 模型参数（parameter）：调整模型的本质是调整模型参数； 损失函数（Loss function）：衡量预测值与真实值之间的差异程度，\u0026ldquo;单个损失\u0026rdquo;； 成本函数（Cost function）：用于评估模型性能，\u0026ldquo;总损失\u0026rdquo;； 特征工程（feature engineering）：对特征进行选择、提取和转换等操作，用于提高模型性能； 符号 约定如下：\nm 个训练示例，n 个特征； $\\mathbb{R}$ 表示标量，$\\mathbb{R}^n$ 表示向量，$\\mathbb{R}^{m \\times n}$ 表示矩阵，$\\mathbb{R}^{m \\times n \\times p \\times \\cdots}$ 表示张量（Tensor）； 具体符号：\n$x \\in \\mathbb{R}^n$ 表示输入变量，$w \\in \\mathbb{R}^n$ 表示回归系数； $X \\in \\mathbb{R}^{m \\times n}$ 表示训练集，$y,\\hat{y} \\in \\mathbb{R}^m$ 分别表示真实值和预测值。 $x^{(i)} \\in \\mathbb{R}^n$ 表示第 $i$ 个训练示例；（第 $i$ 行） $x_j \\in \\mathbb{R}^m$ 表示第 $j$ 个特征；（第 $j$ 列） $x_j^{(i)} \\in \\mathbb{R}$ 表示第 $i$ 个训练示例的第 $j$ 个特征； $y^{(i)},\\hat{y}^{(i)} \\in \\mathbb{R}$ 分别表示第 $i$ 个训练示例的真实值和预测值； $$\nx = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}\n\\space\nw = \\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix}\n\\space\ny = \\begin{bmatrix}y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\end{bmatrix}\n\\space\n\\hat{y} = \\begin{bmatrix}\\hat{y}^{(1)} \\\\ \\hat{y}^{(2)} \\\\ \\vdots \\\\ \\hat{y}^{(m)} \\end{bmatrix}\n\\space\n$$\n$$\nX =\n\\begin{bmatrix}\nx_1^{(1)} \u0026amp; x_2^{(1)} \u0026amp; \\dots \u0026amp; x_n^{(1)} \\\\\nx_1^{(2)} \u0026amp; x_2^{(2)} \u0026amp; \\dots \u0026amp; x_n^{(2)} \\\\\n\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\nx_1^{(m)} \u0026amp; x_2^{(m)} \u0026amp; \\dots \u0026amp; x_n^{(m)}\n\\end{bmatrix}\n\\space\nx^{(i)} = \\begin{bmatrix}x_1^{(i)} \\\\ x_2^{(i)} \\\\ \\vdots \\\\ x_n^{(i)} \\end{bmatrix}\n\\space\nx_j = \\begin{bmatrix}x_j^{(1)} \\\\ x_j^{(2)} \\\\ \\vdots \\\\ x_j^{(m)} \\end{bmatrix}\n$$\n监督学习 有标签的是监督学习。预测连续值的是回归任务，预测离散值的是分类任务。 给定包含标签的训练集 $(X,y)$，通过算法构建一个模型，学习如何从 $x$ 预测 $\\hat{y}$，即：$$ (X,y) \\to f(x) \\to \\hat{y} $$\n线性回归 线性回归（Linear Regression），解决线性的回归问题。\n原理 模型 $n$ 元线性回归的模型 $f: \\mathbb{R}^n \\to \\mathbb{R}$ 如下：\n$$\nf_{w,b}(x) = w \\cdot x + b =\n\\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix}\n\\cdot\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} + b =\n\\sum_{j=1}^{n}w_jx_j + b\n$$\n其中，模型参数：\n$w \\in \\mathbb{R}^n$：回归系数，分别对应 n 个特征的权重（weights）或系数（coefficients）；\n$b \\in \\mathbb{R}$：偏差（bias）或截距（intercept）；\n成本函数 使用最小二乘损失：\n$$\n\\begin{split}\nL(w,b) \u0026amp;= \\frac{1}{2} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \\\\\n\\\\\u0026amp;= \\frac{1}{2} (w \\cdot x^{(i)} + b - y^{(i)})^2\n\\end{split}\n$$\n基于最小二乘损失，常见的三种成本函数：\n$$ J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \\tag{OLS} $$\n$$ J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\lvert w_j \\rvert \\tag{Lasso} $$\n$$ J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2 + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2 \\tag{Ridge} $$\n说明：\n使用 $\\frac{1}{2m}$ 取均值，仅是为了在求偏导时消去常数 2，不影响结果； OLS：普通最小二乘回归； Lasso：Lasso 回归，用于特征选择。在 OLS 的基础上添加了 $w$ 的 L1 范数 作为正则化项； Ridge：岭回归，用于防止过拟合。是在 OLS 的基础上，添加了 $w$ 的 L2 范数 的平方作为正则化项； $\\lambda$：超参数，非负标量，为了控制惩罚项的大小。 矩阵乘向量写法 $$\nJ(w,b) = \\frac{1}{2m} \\lVert X_{new} \\cdot w_{new} - y \\rVert_2^2\n$$\n其中：\n$$\n(X_{new}|y) = \\left [\n\\begin{array}{ccccc|c}\n1 \u0026amp; x_1^{(1)} \u0026amp; x_2^{(1)} \u0026amp; \\dots \u0026amp; x_n^{(1)} \u0026amp; y^{(1)} \\\\\n1 \u0026amp; x_1^{(2)} \u0026amp; x_2^{(2)} \u0026amp; \\dots \u0026amp; x_n^{(2)} \u0026amp; y^{(2)} \\\\\n\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \\\\\n1 \u0026amp; x_1^{(m)} \u0026amp; x_2^{(m)} \u0026amp; \\dots \u0026amp; x_n^{(m)} \u0026amp; y^{(m)}\n\\end{array}\n\\right ]\n\\space\nw_{new} = \\begin{bmatrix}b \\\\ w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix}\n$$\n求解模型参数 求解一组模型参数 $(w,b)$ 使得成本函数 $J$ 最小化。方法见梯度下降算法\n$$ \\arg \\min_{w,b} J(w,b) $$\n多项式回归 通过添加特征的多项式可提高模型复杂度，将其视作新特征则归来仍是线性回归问题。 例子：以下式 $(1)(2)(3)$ 依次对应一元二次多项式、一元三次多项式、二元二次多项式模型：\n$$ f_{w,b}(x) = w_1x + w_2x^2 + b \\tag{1} $$\n$$ f_{w,b}(x) = w_1x + w_2x^2 + w_3x^3 + b \\tag{2} $$\n$$ f_{w,b}(x) = w_1x_1 + w_2x_2 + w_3x_1x_2 + w_4x_1^2 + w_5x_2^2 + b \\tag{3} $$\n以式 $(1)$ 的模型为例，将将非一次项的 $x^2$ 视作新特征，即可按照线性回归模型训练。\n逻辑回归 逻辑回归（Logistic Regression）是 Softmax 回归的特殊情况，都属于线性分类器。\n问题背景 二分类（逻辑回归） 即二选一问题。将 $y|x \\in \\lbrace C_1,C_2 \\rbrace$ 视为 $y$ 的条件概率下的伯努利分布，即：\n$p(y=1|x)$ 表示是 $C_1$ 的概率； $1 - p(y=1|x)$ 表示不是 $C_1$ 即是 $C_2$ 的概率； 因此仅需要找到一个概率分布函数：\n$$ p(y=1|x) $$\n然后取 $\\displaystyle \\max \\lbrace p,1-p \\rbrace$ 即以 $0.5$ 为分界，若 $p \\geq 0.5$ 则分类为 $C_1$，否则分类为 $C_2$.\n多分类（Softmax 回归） 即多选一问题。为 $y|x \\in \\lbrace C_1,C_2,\\cdots,C_k \\rbrace$ 找到 k 个 概率分布函数：\n$$\n\\begin{cases}\np(y=1|x) \\\\\n\\\\p(y=2|x) \\\\\n\\\\ \\cdots \\\\\n\\\\p(y=k|x)\n\\end{cases}\n$$\n其中 $\\displaystyle\\sum_{i=1}^{k} p(y=i|x) = 1$，然后取 $\\displaystyle \\max_{i} p(y=i|x)$ 为最终分类类别。\n逻辑回归 模型 逻辑回归假设 $y|x \\sim Bernoulli(p)$，即 $y$ 的条件概率服从伯努利分布（0-1分布）。\nSigmoid 函数：\n$$ g(z) = \\frac{1}{1+e^{-z}} \\in (0,1) $$\n令\n$$ z = w \\cdot x + b $$ 则 $y=1$（也称作正例）的概率模型：\n$$\np(y=1|x;w,b) = g(z) = \\frac{1}{1 + e^{-(w \\cdot x + b)}}\n$$\n说明：\n模型直接输出 $y=1$ 即正例的概率，即属于 $\\mathbb{R}^n \\to \\mathbb{R}$ 单值函数； 如 $y^{(i)}$ 形如 $[0]$，$\\hat{y}^{(i)}$ 形如 $[0.4]$. 以 0.5 为分界，若 $p \\geq 0.5$ 则分类为 $1$，否则分类为 $0$. 因此别名对数逻辑回归； 模型参数同线性回归。本质上是构造了一个线性决策边界 $z = w \\cdot x + b = 0$； 成本函数 以下两种角度殊途同归。\n极大似然估计角度 极大似然估计假设样本独立同分布，由模型 $p(y=1|x;w,b)$ 构造似然函数 $L(w,b)$：\n$$\n\\begin{split}\nL(w,b) \u0026amp;= \\prod_{i:y^{(i)}=1} p(x^{(i)};w,b) \\prod_{i:y^{(i)}=0} \\left(1 - p(x^{(i)};w,b)\\right) \\\\\n\\\\\u0026amp;= \\prod_{i=1}^{m} \\left(p(x^{(i)};w,b)\\right)^{y^{(i)}} \\left(1 - p(x^{(i)};w,b)\\right)^{1 - y^{(i)}}\n\\end{split}\n$$\n将目标由 $\\displaystyle\\arg \\max_{w,b} L(w,b)$ 转化为取对数再取负号后求极小值问题，取均值后成本函数：\n$$\nJ(w,b) = \\frac{1}{m} \\sum_{i=1}^{m} - y^{(i)} \\ln p(x^{(i)};w,b) - (1 - y^{(i)}) \\ln\\left(1 - p(x^{(i)};w,b)\\right)\n$$\n交叉熵损失角度 将真实类别 $y$ 和预测类别 $p(x;w,b)$ 看作分类类别的两个概率分布，则可使用交叉熵来衡量差异程度，即：\n$$\n\\begin{split}\nJ(w,b) \u0026amp;= \\frac{1}{m} \\sum_{i=1}^{m} L(\\hat{y}^{(i)}, y^{(i)}) = \\frac{1}{m} \\sum_{i=1}^{m} H(y^{(i)}, \\hat{y}^{(i)}) \\\\\n\u0026amp;= \\frac{1}{m} \\sum_{i=1}^{m} - y^{(i)} \\ln p(x^{(i)};w,b) - (1 - y^{(i)}) \\ln\\left(1 - p(x^{(i)};w,b)\\right)\n\\end{split}\n$$\n求解模型参数 求解一组模型参数 $(w,b)$ 使得成本函数 $J$ 最小化。方法见梯度下降算法\n$$ \\arg \\min_{w,b} J(w,b) $$\nSoftmax 回归 模型 Softmax 解决多分类问题，设共 $k$ 个类别，对于每个类别，都对应一个线性映射：\n$$ z_i = w_i \\cdot x + b_i $$\n则第 $i$ 个类别的概率模型：\n$$\np(y=i|x;w_i,b_i) = g(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{k} e^{z_j}}\n$$\n其中 $w_i \\in \\mathbb{R}^n, \\space i \\in \\lbrace 1, 2, \u0026hellip;, k \\rbrace$，显然 $\\displaystyle\\sum_{i=1}^{k} p(y=i|x;w_i,b_i) = 1$.\n说明：\n模型直接输出 $k$ 个类别的概率，即属于 $\\mathbb{R}^n \\to \\mathbb{R}^k$ 多值函数； 如 $k$ 取 3，则 $y^{(i)}$ 形如 $[0, 0, 1]$，$\\hat{y}^{(i)}$ 形如 $[0.1, 0.4, 0.5]$. 最终分类类别取 $\\displaystyle \\max_i p(y=i|x)$ 对应的即可； 成本函数 使用交叉熵损失：\n$$\n\\begin{split}\nJ \u0026amp;= \\frac{1}{m} \\sum_{i=1}^{m} L(\\hat{y}^{(i)}, y^{(i)})\n= \\frac{1}{m} \\sum_{i=1}^{m} H(y^{(i)}, \\hat{y}^{(i)}) \\\\\n\\\\\u0026amp;= \\frac{1}{m} \\sum_{i=1}^{m} \\sum_{j=1}^{k} -y^{(i,j)} \\ln p(x^{(i)};w_j,b_j)\n\\end{split}\n$$\n其中，$y^{(i,j)}$ 表示第 $i$ 个训练示例的第 $j$ 个分类的概率。\nSVM 支持向量机，解决分类问题。\n属于线性分类器。非线性问题，可通过 kernal SVM 解决（映射到高维）；\n超平面：\n决策分界面（decision boundary） 边界分界面（margin boundary） Hard-margin SVM\nSoft-margin SVM：加入了容错率\n核函数需满足：\n$$ k(x,z) = g(x) g(z) $$\n朴素贝叶斯 朴素贝叶斯（Naive Bayes），解决分类问题。\n原理 朴素贝叶斯基于贝叶斯定理，并假设每个样本点的特征相互独立。\n设 $x \\in \\mathbb{R}^n$，$y|x \\in \\lbrace C_1,C_2,\\cdots,C_k \\rbrace$，则给定待分类的 $x$，其属于 $C_i$ 类别的概率是：\n$$\np(y=C_i|x) = \\frac{p(y=C_i) p(x|y=C_i)}{p(x)} =\n\\frac{p(y=C_i) \\prod_{j=1}^{n} p(x_j|y=C_i)}{\\prod_{j=1}^{n} p(x_j)}\n$$\n然后取 $k$ 个类别中概率最大的作为预测类别，即：\n$$\n\\arg \\max_{C_i} p(y=C_i|x)\n$$\n说明：由于是比大小，因此可省去计算常量分母 $p(x)$，即：\n$$\np(y=C_i|x)\n\\propto\tp(y=C_i) \\prod_{j=1}^{n} p(x_j|y=C_i)\n$$\n拉普拉斯平滑 拉普拉斯平滑（Laplace smoothing）用于修正当 $p(x_j|y=C_i) = 0$ 时导致的连乘结果为零的零概率问题。方法是计算概率时分子+1\n决策树 决策树（Decision tree）可解决分类和回归问题。核心思想是使用信息纯度的提升程度来衡量分类效率。\n问题背景 特征：包含离散值和连续值；\n标签：\n离散值：决策树，使用熵或基尼系数衡量信息不纯度； 连续值：回归树，使用方差衡量信息不纯度； 决策树 设训练集有 $n$ 个类别特征，$k$ 个分类标签，则ID3算法的决策树基本原理如下：\n步骤零 设置一个阈值 $\\varepsilon$，当熵小于该值，则停止分类，因为此时信息纯度已足够高；\n步骤一 计算分类前 $y$ 的熵：\n$$ H(y) = - \\sum_{i=1}^{k} p(y=i) \\ln p(y=i) $$\n说明：当 $H(y) \u0026lt; \\varepsilon$ 时，没有分类的必要了。\n步骤二 对于每个类别特征 $x_j$，计算其将 $y$ 分类后的熵：\n$$ H(y|x_j), \\space j \\in \\lbrace1,2,\\cdots,n \\rbrace$$\n再计算分类前后的熵减即信息增益，选信息增益最大的那个特征作为分类特征：\n$$ Gain(y,x_j) = H(y) - H(y|x_j) $$\n说明：ID3算法使用信息增益，C4.5算法使用信息增益率。\n步骤三 对于每个子类别节点，重复步骤一和步骤二（记得剔除已分类特征），直至所有的子类别节点都停止分类。\n可选：连续特征离散化 回归树 对于回归树，使用方差衡量信息不纯度。其他类比决策树。\n随机森林 随机森林（Random forest）是一种基于树模型的集成学习（Ensemble learning）方法。\n思想：通过重复多次有放回抽样，且每次随机选择 $k\u0026lt;n$ 个特征，训练若干个权重相等的决策树（弱学习器），然后投票机制，分类问题则求众数，回归问题则求均值。\nBagging\nXGBoost 也是一种集成学习方法，Boosting.\nKNN KNN (K-Nearest Neighbors)，解决分类+回归问题。K 个邻居的意思。\n原理 给定训练集 $X \\in \\mathbb{R}^{m \\times n}, y \\in \\mathbb{R}^m$，则给定待分类的点（特征） $x$，其所属类别由距离其最近的 k 个点（邻居）决定。\n其中，距离计算方式有多种，较常使用的欧氏距离如下：\n$$\nd(x, x^{(i)}) = \\lVert x - x^{(i)} \\rVert\n= \\sqrt{\\sum_{j=1}^{n} (x_j - x_j^{(i)})^2}\n$$\n说明：非参数，投票制。回归问题，可取均值。\n无监督学习 无标签的是无监督学习。 给定不包含标签的训练集 $X$，通过算法构建一个模型，揭示数据的内在分布特性及规律，即：$$ X \\to f(x) \\to \\hat{y} $$\n无监督学习任务分为聚类（Clustering）和降维（Dimensionality reduction）。\nK-means 解决聚类问题。K 个类别的意思。\n原理 给定训练集 $X \\in \\mathbb{R}^{m \\times n}$，K-means 要实现的是将 $m$ 个点（训练示例）聚类为 $k$ 个簇（Cluster），步骤如下：\n步骤一：随机初始化 $k$ 个簇中心，记作 $\\mu_j \\in \\mathbb{R}^n$；\n步骤二：为每个点 $x^{(i)}$ 分配距离最近的簇，记作 $c^{(i)}$：$$ c^{(i)} = \\displaystyle\\min_{j} \\lVert x^{(i)} - \\mu_j\\rVert_2^2 $$\n步骤三：为每个簇重新计算簇中心 $\\mu_{j}$，方法是该簇中所有点的均值；\n重复以上步骤二和步骤三，直至 $k$ 个簇中心不再发生变化（即收敛）。\n成本函数可以表示为：\n$$\nJ(c^{(1)}, \\cdots, c^{(m)}, \\mu_1, \\cdots, \\mu_k) = \\frac{1}{m} \\sum_{i=1}^{m} \\lVert x^{(i)} - \\mu_{c^{(i)}}\\rVert_2^2\n$$\n其中：$\\mu_{c^{(i)}}$ 表示 $x^{(i)}$ 所属的簇中心；\nPCA 主成分分析（Principal Component Analysis, PCA），解决降维问题。\n用最少的特征尽可能解释所有的方差（越离散方差越大）。\n用途：特征工程，可视化。\n机器学习基础 距离和相似度 距离和相似度常用于分/聚类，距离越近或相似度越高，则被认为可以分/聚为一类。 对于向量 $x,y \\in \\mathbb{R}^n$，或空间中两个点，计算距离可使用差向量的大小的衡量如范数，计算相似度可通过两向量夹角等来衡量。\n闵可夫斯基距离 是含参数 p 的距离函数。当 p 依次取 1, 2, $\\infty$ 时，分别对应曼哈顿距离、欧氏距离、切比雪夫距离；\n$$ \\left(\\sum_{j=1}^{n} {\\lvert x_j - y_j \\rvert}^p\\right)^{1/p} \\tag{$L_p$} $$\n曼哈顿距离 $$ \\sum_{j=1}^{n} \\lvert x_j - y_j \\rvert \\tag{$L_1$} $$\n欧氏距离 $$ \\sqrt{\\sum_{j=1}^{n} (x_j - y_j)^2} \\tag{$L_2$} $$\n切比雪夫距离 $$ \\max_{j} {\\lvert x_j - y_j \\rvert} \\tag{$L_{+\\infty}$} $$\n余弦相似度 使用两个向量夹角的余弦值来衡量相似度，公式如下：\n$$ Cosine \\space Similarity = \\cos(\\theta) = \\frac{x \\cdot y}{\\lVert x \\rVert \\lVert y \\rVert} $$\n说明：由向量点积计算公式推导而来。越接近于 1，夹角越接近于 0，越相似。\n皮尔逊相关系数 使用标准化后的协方差来衡量两个随机变量的线性相关性。\n$$\n\\rho = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y} \\in [-1, 1]\n$$\n说明：越接近于 1 越正线性相关，越接近于 -1 越负线性相关，等于 0 不线性相关。\nKL 散度 给定两个概率分布 $p(x)$ 和 $q(x)$，使用 KL 散度来衡量两者之间的差异程度，公式如下：\n$$ D_{KL}(p||q) = \\sum_x p(x) \\ln \\frac{p(x)}{q(x)} \\in [0, \\infty] $$\n说明：也称作相对熵。非负，越小越相似。\n特征工程 EDA 探索阶段，包括：\n缺失值； 异常值；（PCA 后可视化） 线性相关性； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import pandas as pd import seaborn as sns df = pd.read_csv(\u0026#39;/path/to/xxx.csv\u0026#39;) # 查看前 5 行 df.head() # 查看每列的数据类型 df.info() # 描述性统计: 个数、均值、标准差、最大/小值、四分位数、中位数 df.describe() # 探索特征两两相关性矩阵 (超好用) sns.pairplot(data=df, hue=\u0026#39;your_label\u0026#39;) # 探索单个特征和标签 (小提琴图) sns.catplot(x=\u0026#39;your_feature\u0026#39;, y=\u0026#39;your_label\u0026#39;, hue=\u0026#39;your_label\u0026#39;, kind=\u0026#39;violin\u0026#39;, data=df) 缺失值处理 离散值 删除：缺失比例严重时； 取众数； 逻辑回归：使用完整数据预测缺失数据； 不处理：算法不敏感时，如 XGBoost; 连续值 删除：缺失比例严重时； 取中位数：（相对均值更能兼容偏态分布） 线性回归：使用完整数据预测缺失数据； 不处理：算法不敏感时，如 XGBoost; 异常值处理 如何发现：\nLabelEncoder 主要用于将离散特征的多个（有序）类别，映射为有序数字。例子：\n原特征 新特征 $C_1$ 0 $C_2$ 1 $C_3$ 2 One-Hot 编码 主要用于将离散特征的多个（无序）类别，转为稀疏矩阵。例子：\n原特征 新特征1 新特征2 新特征3 $C_1$ 1 0 0 $C_2$ 0 1 0 $C_3$ 0 0 1 分箱 主要用于连续特征的离散化。例子：\n原特征 新特征 $[0, 60)$ 0 $[60,80)$ 1 $[80,100]$ 2 特征缩放 特征缩放（Feature scaling）主要通过归一化（Normalization）和标准化（Standardization）实现。主要目的是：\n剔除量纲，解决数据可比性问题； 提高求解速度，如运行梯度下降时更快收敛。 最大最小归一化 Min-max normalization (Rescaling)：\n$$\nx^{\\prime} = \\frac{x - min(x)}{max(x) - min(x)}\n$$\n说明：归一化后取值范围为 $[0,1]$，适用于最大最小值较稳定的情况；\n均值归一化 Mean normalization：\n$$\nx^{\\prime} = \\frac{x - \\bar{x}}{max(x) - min(x)}\n$$\n说明：归一化后取值范围为 $[-1,1]$；\nZ 分数归一化 Z-score normalization，也称作标准化(Standardization)：\n$$\nx^{\\prime} = \\frac{x - \\mu}{\\sigma}\n$$\n说明：归一化后取值范围为 $[-\\infty,+\\infty]$，且均值为 $0$，标准差为 $1$；\n特征提取 如从文本、图像中提取机器学习可支持的特征。\n1 from sklearn.feature_extraction.text import CountVectorizer 特征选择 去除变化小（方差小）的特征：\n去除共线（线性相关）的特征：\n损失函数 损失函数用于衡量单个预测值与真实值之间的差异程度。 损失函数通常表示为 $L(\\hat{y}, y)$，成本函数通常表示为 $J = \\frac{1}{m} \\displaystyle \\sum_{i=1}^{m} L\\left(\\hat{y}^{(i)}, y^{(i)}\\right)$.\n最小二乘 适用于回归模型。给定 $\\hat{y},y \\in \\mathbb{R}$，分别表示预测值和真实值，则：\n$$ L(\\hat{y}, y) = \\frac{1}{2} (\\hat{y} - y)^2 $$\n交叉熵 适用于分类模型。将 $\\hat{y},y$ 分别看作 预测类别的分布和真实类别的分布，则：\n$$ L(\\hat{y}, y) = H(y,\\hat{y}) = - \\sum_k y \\ln \\hat{y} $$\n其中 $k$ 为分类的数量，$\\displaystyle\\sum_{k} y = \\sum_{k} \\hat{y} = 1$. 推导详见交叉熵。\n特别的，对于二分类问题：\n$$ L(\\hat{y}, y) = -y\\ln\\hat{y} - (1-y)\\ln(1-\\hat{y}) $$\n举例说明：\n对于二分类，$\\hat{y},y$ 的一组取值形如 $[0.6]$ 和 $[1]$，本质上是 $[0.6, 0.4]$ 和 $[1, 0]$；\n对于三分类问题，$\\hat{y},y$ 的一组取值形如 $[0.1, 0.3, 0.6]$ 和 $[0, 0, 1]$；\n优化算法 梯度下降算法 核心原理是可微函数 在某点沿着梯度反方向，函数值下降最快。 梯度下降（Gradient Descent, GD）是一种迭代优化算法，用于求解任意一个可微函数的局部最小值。在机器学习中，常用于最小化成本函数，即：\n给定成本函数 $J(w,b)$，求解一组 $(w,b)$，使得\n$$ arg\\min_{w,b} J(w,b) $$\n实现方法 步骤一：选定初始点 $(w_{init},b_{init})$；\n步骤二：为了使函数值下降，需要沿着梯度反方向迭代，即重复以下步骤，直至收敛，即可得到局部最小值的解：\n$$\nw \\leftarrow w - \\alpha \\frac{\\partial J}{\\partial w}\n$$\n$$\nb \\leftarrow b - \\alpha \\frac{\\partial J}{\\partial b}\n$$\n即：\n$$\n\\begin{equation}\n\\begin{pmatrix}\nw_1 \\\\\nw_2 \\\\\n\\vdots \\\\\nw_n \\\\\nb\n\\end{pmatrix}\n\\leftarrow\n\\begin{pmatrix}\nw_1 \\\\\nw_2 \\\\\n\\vdots \\\\\nw_n \\\\\nb\n\\end{pmatrix}\n- \\alpha\n\\begin{pmatrix}\n\\frac{\\partial J}{\\partial w_1} \\\\\n\\frac{\\partial J}{\\partial w_2} \\\\\n\\vdots \\\\\n\\frac{\\partial J}{\\partial w_n} \\\\\n\\frac{\\partial J}{\\partial b}\n\\end{pmatrix}\n\\end{equation}\n$$\n其中：$\\alpha \\geq 0$ 指学习率（Learning rate），也称作步长，决定了迭代的次数。\n批量梯度下降 （Batch Gradient Descent, BGD）：使用训练集中的所有数据\n随机梯度下降 （stotastic gradient descent, SGD）：？？根据每个训练样本进行参数更新\n模型评估 过拟合问题 定义过拟合：训练方差小，测试方差大。\n解决过拟合的方法：\n收集更多的训练示例； 特征选择； 正则化； 评估方法 留出法（Hold-out）：拆分训练集和测试集，如经验上 8/2 或 7/3；\n交叉验证法（Cross Validation）：将数据集分成 N 块，使用 N-1 块进行训练，再用最后一块进行测试；\n自助法（Bootstrap）：有放回随机抽样；\n回归指标 MAE MAE（Mean Absolute Error），平均绝对误差。\n$$ MAE = \\frac{1}{m} \\sum_{i=1}^{m} \\lvert \\hat{y}^{(i)} - y^{(i)} \\rvert $$\nMAPE MAPE（Mean Absolute Percentage Error），平均绝对百分误差。\n$$ MAPE = \\frac{100}{m} \\sum_{i=1}^{m} \\lvert \\frac{y^{(i)} - \\hat{y}^{(i)}}{y^{(i)}} \\rvert $$\nMSE MSE（Mean Squared Error），均方误差。最小二乘的均值版，常用于回归模型。\n$$ MSE = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 $$\nRMSE RMSE（Root Mean Square Error），均方根误差。\n$$ RMSE = \\sqrt{MSE} $$\nR2 R2 (coefficient of determination)，决定系数。衡量总误差（客观存在且无关回归模型）中可以被回归模型解释的比例，即拟合程度。\n$$ R^2 = \\frac{SSR}{SST} = 1- \\frac{SSE}{SST} $$\n说明：\n当 $R^2 \\to 1$ 时，表明拟合程度越好，因为此时 SSR 趋向于 SST（或 SSE 趋向于 0）；\n当 $R^2 \\to 0$ 时，表明拟合程度越差，因为此时 SSR 趋向于 0（或 SSE 趋向于 SST）；\n关于 SST/SSR/SSE 助记小技巧：T is short for total, R is short for regression, E is short for error. SST (sum of squares total)，总平方和，用于衡量真实值相对均值的离散程度。SST 客观存在且与回归模型无关；\n$$ SST = \\sum_{i=1}^{m} (y^{(i)} - \\bar{y})^2 $$\nSSR (sum of squares due to regression)，回归平方和，用于衡量预测值相对均值的离散程度。当 SSR = SST 时，回归模型完美；\n$$ SSR = \\sum_{i=1}^{m} (\\hat{y}^{(i)} - \\bar{y})^2 $$\nSSE (sum of squares error)，误差平方和，用于衡量预测值相对真实值的离散程度；\n$$ SSE = \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2 $$\n且三者之间的关系是 $SST = SSR + SSE$.\n分类指标 二分类问题的混淆矩阵（Confusion Matrix）如下：\nactual/predicted Positive Negative Positive TP（真阳） FN（假阴） Negative FP（假阳） TN（真阴） 其中：T/F 表示预测是否正确，P/N 表示预测结果（P=1, N=0）。\n准确率 指预测正确的比例，即：\n$$ accuracy = \\frac{TP+TN}{TP+TN+FP+FN} $$\n精确率 也称作查准率，指预测为正的样本中，实际也为正的比例，即：\n$$ precision = \\frac{True \\space P}{predicted \\space P} = \\frac{TP}{TP+FP} $$\n召回率 也称作查全率，指实际为正的样本中，判定也为正的比例，即：\n$$ recall = \\frac{True \\space P}{actual \\space P} = \\frac{TP}{TP+FN} $$\nF1 $$ F1 = \\frac{2 \\times precision \\times recall}{precision + recall} $$\nROC 曲线 指以 FPR 为横轴, TPR 为纵轴绘制成的曲线。其中：\nFPR 指假阳率，也称作误诊率，指实际为阴，但判定为阳的比例，即：\n$$ FPR = \\frac{FP}{FP+TN} $$\nTPR 指真阳率，就是召回率，指实际为阳，判断也为阳的比例，即：\n$$ TPR = \\frac{TP}{TP+FN} $$\n说明：FPR 越低，TPR 越高，也就是越靠近 (0, 1)，说明模型分类能力越好。\nAUC AUC (Area Under ROC Curve)指的是 ROC 曲线下方的面积，相较于 ROC，是一个直观的标量来衡量模型分类能力。\n$AUC=1$: 即左上角，完美分类； $AUC=0.5$: 即分类能力与随机的抛硬币毫无差异，比较差； $AUC\u0026lt;0.5$: 分类能力很差，反着来； 实际中，一般在 $0.5 \\to 1$ 之间。\nPR 曲线 指以 Recall 为横轴, precision 为纵轴绘制成的曲线。\n数学基础 矩 一阶原点矩是期望值，二阶中心矩是方差，三阶标准矩是偏度，四阶标准矩减常数3是峰度，二阶混合中心矩是协方差。 设随机变量 $X$ 和 $Y$，正整数 $k$ 和 $l$.\n原点矩 原点指坐标原点。$X$ 的 $k$ 阶原点矩：\n$$ E(X^k) $$\n中心矩 中心指期望值。$X$ 的 $k$ 阶中心矩记作 $\\mu_k$：\n$$ \\mu_k = E\\lbrack X - E(X)\\rbrack^k $$\n标准矩 标准化指除以标准差以剔除量纲，标准矩是标准化的中心矩。$X$ 的 $k$ 阶标准矩：\n$$\n\\frac{\\mu_k}{\\sigma^k} = \\frac{\\mu_k}{\\mu_2^{\\frac{k}{2}}} = \\frac{E\\lbrack X - E(X)\\rbrack^k}{\\left(E\\lbrack X - E(X)\\rbrack^2\\right)^{\\frac{k}{2}}}\n$$\n混合矩 $X$ 和 $Y$ 的 $k+l$ 阶混合矩：\n$$ E(X^kY^l) $$\n混合中心矩 $X$ 和 $Y$ 的 $k+l$ 阶混合中心矩：\n$$ E\\lbrace\\lbrack X - E(X)\\rbrack^k \\lbrack Y - E(Y)\\rbrack^l \\rbrace $$\n统计指标 注意这里不严格区分总体和样本，并使用样本估计整体。\n极差 $$ \\max(x) - \\min(x) $$\n期望值 这里使用样本均值估计总体期望值。\n$$\n\\begin{split}\n\\mu \u0026amp;= E(X) = \\sum_{j=1}^{N} p(x_j) x_j \\\\\n\u0026amp;\\approx \\bar{x} = \\frac{1}{n} \\sum_{j=1}^{n} x_j\n\\end{split}\n$$\n说明：根据强大数定律，当 n 趋向于无穷时，样本均值依概率 1 收敛于期望值。 期望值与均值 总体期望值是常数标量，样本均值依赖于具体的随机抽样。\n如抛硬币（伯努利试验），总体期望值是 $0.5 * 1 + 0.5 * 0 = 0.5$，但样本均值比如抛 3 次 $(1+1+0)/3 \\neq 0.5$.\n方差 方差（Variance）用于衡量相对均值的离散程度。\n$$\n\\begin{split}\n\\sigma^2 \u0026amp;= Var(X) = E\\lbrack X - E(X)\\rbrack^2 = \\sum_{j=1}^{N} p(x_j)(x_j - \\mu)^2 \\\\\n\u0026amp;\\approx \\frac{1}{n} \\sum_{j=1}^{n} (x_j - \\bar{x})^2\n\\end{split}\n$$\n说明：越大，越扁，越离散，熵越大。\n标准差 标准差（Standard deviation）是方差的正平方根。\n$$ \\sigma = \\sqrt{\\sigma^2} $$\n协方差 协方差（Covariance）用于衡量两个变量的线性相关性。\n$$\nCov(X,Y) = E\\lbrace\\lbrack X - E(X)\\rbrack \\lbrack Y - E(Y)\\rbrack \\rbrace\n$$\n说明：$Cov(X,X) = Var(X)$，即方差是协方差的特殊情形。\n相关系数 标准化的协方差。\n$$\n\\rho = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}\n$$\n偏度 偏度（Skewness）用于衡量分布的对称性。\n$$\nSkewness = \\frac{\\mu_3}{\\sigma^3} = \\frac{\\mu_3}{\\mu_2^{\\frac{3}{2}}}\n$$\n说明：尾巴在哪边就偏哪边。\n峰度 峰度（Kurtosis）用于衡量相对高斯分布的陡峭程度。\n$$\nKurtosis = \\frac{\\mu_4}{\\sigma^4} - 3 = \\frac{\\mu_4}{\\mu_2^2} - 3\n$$\n说明：减常数 3 是为了使高斯分布的峰度为零。\n导数 一阶导用于单调性判断，二阶导用于凹凸性判断。 给定函数 $f: \\mathbb{R} \\to \\mathbb{R}$，则 $f$ 在点 $x$ 处的一阶导数 $f\u0026rsquo;$ 和二阶导数 $f\u0026rsquo;\u0026rsquo;$ 的定义分别如下：\n$$\nf\u0026rsquo; = \\frac{dy}{dx} = \\lim_{{\\Delta x} \\to 0} \\frac{f(x + {\\Delta x})}{\\Delta x}\n$$\n$$ f\u0026rsquo;\u0026rsquo; = (f\u0026rsquo;)\u0026rsquo; = \\frac{d^2y}{dx^2} $$\n注意：可导等于可微，可导一定连续；\n说明：一阶导表示函数在该点处的瞬时变化率；\n用途：一阶导用于判断单调性；二阶导用于判断凹凸性，大于零则凸（U 型）。\n偏导数 给定函数 $f: \\mathbb{R}^n \\to \\mathbb{R}$，则 $f$ 对自变量 $x_j$ 的偏导数（partial derivative），指将其他自变量视作常量时，对 $x_j$ 的导数，即：\n$$\n\\frac{\\partial f}{\\partial x_j} = \\lim_{{\\Delta x_j} \\to 0} \\frac{f(x_j + {\\Delta x_j}, \u0026hellip;) - f(x_j, \u0026hellip;)}{\\Delta x_j}\n$$\n注意：可微一定可导，可微一定连续。\n梯度 梯度是一个向量，沿着梯度方向函数值上升最快，逆着梯度方向函数值下降最快。 给定可微函数 $f: \\mathbb{R}^n \\to \\mathbb{R}$，则 $f$ 的偏导数构成的向量，称为梯度，记作 $grad f$ 或 $\\nabla f$，即：\n$$\ngrad f = \\nabla f =\n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\\n\\frac{\\partial f}{\\partial x_2} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{bmatrix} \\in \\mathbb{R}^n\n$$\n用途：梯度下降算法\n凸函数 如果一个函数满足任意两点连成的线段都位于函数图形的上方，则称这个函数为凸函数（Convex function）。\n凸函数的局部最小值等于极小值，可作为选择损失函数的重要参考。\n向量 点积是标量，叉积是向量，外积是矩阵。 n 维向量 $x$ 记作：\n$$\nx = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\in \\mathbb{R}^n\n$$\n说明：本文一律默认列向量，在 Python 中对应一维数组。$x$ 也可视作一个 $n \\times 1$ 矩阵。\n数乘 几何意义是向量的伸缩 (stretch)。\n加法 几何意义是向量的旋转 (rotate)。\n点积 点积（Dot product），也称作点乘、内积、数量积。对于 $x,y \\in \\mathbb{R}^n$：\n$$\nx \\cdot y = x^Ty = \\sum_{j=1}^{n} x_jy_j \\in \\mathbb{R}\n$$\n注意：相同维数才能进行点积乘法；\n说明：几何意义是向量围成的平面的面积或空间的体积（有正负号），大小等于 $\\lVert x \\rVert \\lVert y \\rVert\\cos(\\theta)$，其中 $\\theta$ 为两向量之间的夹角；\n用途：余弦相似度\n叉积 叉积（Cross product），也称作叉乘、向量积。对于 $x,y \\in \\mathbb{R}^3$：\n$$\n\\begin{split}\nx \\times y \u0026amp;=\n\\left|\n\\begin{matrix}\n\\vec{i} \u0026amp; \\vec{j} \u0026amp; \\vec{k} \\\\\nx_1 \u0026amp; x_2 \u0026amp; x_3 \\\\\ny_1 \u0026amp; y_2 \u0026amp; y_3\n\\end{matrix}\n\\right| \\\\\n\\\\\u0026amp;= (x_2y_3-x_3y_2)\\vec{i} - (x_1y_3-x_3y_1)\\vec{j} + (x_1y_2-x_2y_1)\\vec{k} \\\\\n\\\\\u0026amp;= \\begin{bmatrix}x_2y_3-x_3y_2 \\\\ -(x_1y_3-x_3y_1) \\\\ x_1y_2-x_2y_1 \\end{bmatrix} \\in \\mathbb{R}^3\n\\end{split}\n$$\n注意：叉积的概念仅用于三维空间。这里的公式表达使用了行列式和代数余子式；\n说明：几何意义是法向量，大小等于 $\\lVert x \\rVert \\lVert y \\rVert \\sin(\\theta)$，其中 $\\theta$ 为两向量之间的夹角。\n外积 外积（Outer product）。对于 $x \\in \\mathbb{R}^m, y \\in \\mathbb{R}^n$：\n$$\nx \\otimes y = xy^T =\n\\begin{bmatrix}\nx_1y_1 \u0026amp; x_1y_2 \u0026amp; \\dots \u0026amp; x_1y_n \\\\\nx_2y_1 \u0026amp; x_2y_2 \u0026amp; \\dots \u0026amp; x_2y_n \\\\\n\\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\\nx_my_1 \u0026amp; x_my_2 \u0026amp; \\dots \u0026amp; x_my_n\n\\end{bmatrix}\n\\in \\mathbb{R}^{m \\times n}\n$$\n说明：运算结果是个矩阵。\n矩阵 $m \\times n$ 矩阵可理解为 n 个列向量的集合（或 m 个行向量的集合）。\n线性组合 向量的线性组合，就是先各自数乘再相加，结果仍是同维向量。 设有 n 个 m 维向量 $x_1,x_2,\u0026hellip;,x_n$ 和 n 个标量 $w_1,w_2,\u0026hellip;,w_n$，则该 n 个向量的线性组合 $y$ 表示如下：\n$$ y = w_1x_1 + w_2x_2 + \\cdots + w_nx_n \\in \\mathbb{R}^m $$\n说明：线性空间内，数乘运算本质上是向量的伸缩，加法运算本质上是向量的旋转。线性运算并没有对向量进行扭曲和变形。\n线性相关 n 个线性无关的向量，可作为基向量，张成一个 n 维线性空间。 对于 n 个向量 $x_1,x_2,\u0026hellip;,x_n$，令其线性组合为零向量，即：\n$$ w_1x_1 + w_2x_2 + \\cdots + w_nx_n = \\vec{0} $$\n如果当且仅当 $w_1 = w_2 = \\cdots = w_n = 0$ 即全部系数为零时才成立，则称该 n 个向量线性无关，否则线性相关。\n说明：线性相关，则其中一个可以用其余的线性组合表示，此时可降维。\n线性无关，对于 n 取 2 就是两个向量不共线，对于 n 取 3 就是三个向量不共面。 秩 矩阵的秩等于线性无关的列向量的个数。满秩则线性无关，不满秩则线性相关。 矩阵的秩（Rank）记作 $rank$，且秩 = 列秩 = 行秩。\n对于 $X \\in \\mathbb{R}^{m \\times n}$，由于实际中 $m \\gg n$，因此其秩由 $n$ 决定。且：\n若 $rank(X) = n$，即列满秩，则 n 个特征线性无关； 若 $rank(X) \u0026lt; n$，即列不满秩，则 n 个特征线性相关，此时可降维。 行列式 行列式（Determinant）针对的是方阵。对于方阵 $X \\in \\mathbb{R}^{n \\times n}$，其行列式记作 $\\det(X)$，且：\n若满秩则 $det(X) \\neq 0$，称为非奇异矩阵；\n若不满秩则 $det(X) = 0$，称为奇异矩阵；\n说明：奇异矩阵无法求逆矩阵。\n线性变换 矩阵是一次线性变换。 回忆线性组合，可将其写为矩阵乘向量即 $Xw=y$ 的形式：\n$$\n\\begin{split}\n\\begin{bmatrix}x_{11} \u0026amp; x_{12} \u0026amp; \\cdots \u0026amp; x_{1n} \\\\ x_{21} \u0026amp; x_{22} \u0026amp; \\cdots \u0026amp; x_{2n} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp;\\vdots \\\\ x_{m1} \u0026amp; x_{m2} \u0026amp; \\cdots \u0026amp; x_{mn} \\end{bmatrix}\n\\begin{bmatrix}w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n \\end{bmatrix}\n\u0026amp;= \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_m \\end{bmatrix}\n\\end{split}\n$$\n理解上述式子：\n代数角度：n 个列向量的线性组合； 几何角度：对 n 个列向量先各自缩放再旋转； 线性变换的几何角度：将向量 $w$ 线性变换至 $y$，具体指： 输入向量：$w$ 线性变换：$X$，其中 n 个列向量可视作伪基向量； 输出向量：$y$ 矩阵乘向量 矩阵乘向量的结果是向量，可理解为对向量进行一次线性变换。 例子：\n$$\n\\begin{bmatrix}a \u0026amp; b \u0026amp; c \\\\ d \u0026amp; e \u0026amp; f \\\\ g \u0026amp; h \u0026amp; i \\end{bmatrix}\n\\begin{bmatrix}x \\\\ y \\\\ z \\end{bmatrix} =\nx \\begin{bmatrix}a \\\\ d \\\\ g \\end{bmatrix} +\ny \\begin{bmatrix}b \\\\ e \\\\ h \\end{bmatrix} +\nz \\begin{bmatrix}c \\\\ f \\\\ i \\end{bmatrix} =\n\\begin{bmatrix}ax+by+cz \\\\ dx+ey+fz \\\\ gx+hy+iz \\end{bmatrix}\n$$\n特别的，当取正交单位矩阵时，该向量经过线性变化后，仍等于该向量。\n$$\n\\begin{bmatrix}1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\n\\begin{bmatrix}x \\\\ y \\\\ z \\end{bmatrix} =\nx \\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\end{bmatrix} +\ny \\begin{bmatrix}0 \\\\ 1 \\\\ 0 \\end{bmatrix} +\nz \\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\end{bmatrix} =\n\\begin{bmatrix}x \\\\ y \\\\ z \\end{bmatrix}\n$$\n矩阵乘矩阵 矩阵乘矩阵的结果是矩阵，可理解为两次线性变换的叠加（自右向左）。 例子：\n特征值与特征向量 给定方阵 $A \\in \\mathbb{R}^{n \\times n}$，若存在非零向量 $v \\in \\mathbb{R}^n$ 和非零标量 $\\lambda \\in \\mathbb{R}$，使得：\n$$\nAv = \\lambda v\n$$\n则称 $v$ 为方阵 $A$ 的特征向量，$\\lambda$ 为对应的特征值。\n理解：$v$ 在 $A$ 线性变换的作用下，仅发生了数乘 $\\lambda v$，几何意义上即仅发生了缩放。\n特征分解 特征分解的结果是三个矩阵相乘，即三次线性变换的叠加。自右向左，先旋转，再伸缩，最后再旋转。 特征分解是一种矩阵分解，且针对的是方阵。给定方阵 $A \\in \\mathbb{R}^{n \\times n}$，则可将其分解为三个矩阵相乘：\n$$\nA = V diag(\\lambda) V^{-1}\n$$\n其中：\n$V \\in \\mathbb{R}^{n \\times n}$：指 $A$ 的 n 个特征向量组成的正交矩阵； $diag(\\lambda) \\in \\mathbb{R}^{n \\times n}$：指对应 n 个特征值在对角线上的对角矩阵； $V^{-1}$：指 $V$ 的逆矩阵； 例子（以下四个矩阵依次对应 $A, V, diag(\\lambda), V^{-1}$）：\n$$\n\\begin{bmatrix}1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix} =\n\\begin{bmatrix}0 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\n\\begin{bmatrix}1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix}\n\\begin{bmatrix}0 \u0026amp; 1 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\n$$\n理解：向量 $\\begin{bmatrix}1 \u0026amp; 1 \u0026amp; 0 \\end{bmatrix}^T$ 和 $\\begin{bmatrix}1 \u0026amp; 1 \\end{bmatrix}^T$ 本质上一个属于三维，一个属于二维。\n奇异值分解 奇异值分解（SVD）是特征分解推广到一般矩阵的情形，可用于升/降维。 给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$，则可将其分解为三个矩阵相乘：\n$$\nA = U \\Sigma V^T\n$$\n其中：\n$U \\in \\mathbb{R}^{m \\times m}$：指 $AA^T$ 的 m 个特征向量组成的左正交矩阵； $\\Sigma \\in \\mathbb{R}^{m \\times n}$：指对角阵，对角线上的 $\\sigma$ 称为奇异值，非负且降序排列，可理解为特征的权重； 形如 $\\begin{bmatrix}\\sigma_1 \u0026amp; 0 \\\\ 0 \u0026amp; \\sigma_2 \\\\ 0 \u0026amp; 0 \\end{bmatrix}$ 时，起到降维的作用； 形如 $\\begin{bmatrix}\\sigma_1 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; \\sigma_2 \u0026amp; 0 \\end{bmatrix}$ 时，起到升维的作用； $V^T \\in \\mathbb{R}^{n \\times n}$：指 $A^TA$ 的 n 个特征向量组成的右正交矩阵； 降维的原理，即取前 k 个权重高的特征来近似表示整个矩阵：\n$$\nA_{m \\times n} =\nU_{m \\times m} \\Sigma_{m \\times n} V_{n \\times n}^T \\approx\nU_{m \\times k} \\Sigma_{k \\times k} V_{k \\times n}^T\n$$\n降维例子（以下四个矩阵依次对应 $A, U, \\Sigma, V^T$）：\n$$\n\\begin{split}\n\\begin{bmatrix}1 \u0026amp; 2 \\\\ 3 \u0026amp; 4 \\\\ 5 \u0026amp; 6 \\end{bmatrix} \u0026amp;=\n\\begin{bmatrix}-0.2298477 \u0026amp; 0.88346102 \u0026amp; 0.40824829 \\\\ -0.52474482 \u0026amp; 0.24078249 \u0026amp; -0.81649658 \\\\ -0.81964194 \u0026amp; -0.40189603 \u0026amp; 0.40824829 \\end{bmatrix}\n\\begin{bmatrix}9.52551809 \u0026amp; 0 \\\\ 0 \u0026amp; 0.51430058 \\\\ 0 \u0026amp; 0 \\end{bmatrix}\n\\begin{bmatrix}-0.61962948 \u0026amp; -0.78489445 \\\\ -0.78489445 \u0026amp; 0.61962948 \\end{bmatrix} \\\\\n\\\\ \u0026amp;\\approx\n\\begin{bmatrix}-0.2298477 \u0026amp; 0.88346102 \\\\ -0.52474482 \u0026amp; 0.24078249 \\\\ -0.81964194 \u0026amp; -0.40189603 \\end{bmatrix}\n\\begin{bmatrix}9.52551809 \u0026amp; 0 \\\\ 0 \u0026amp; 0.51430058 \\end{bmatrix}\n\\begin{bmatrix}-0.61962948 \u0026amp; -0.78489445 \\\\ -0.78489445 \u0026amp; 0.61962948 \\end{bmatrix}\n\\end{split}\n$$\n范数 范数是一个函数，用于量化向量或矩阵的大小，即将向量或矩阵映射为一个标量。 向量范数 n 维向量 $x$ 的 p 范数定义如下：\n$$\nL_p(x) = \\lVert x \\rVert_p = \\left(\\sum_{j=1}^{n} {\\lvert x_j \\rvert}^p\\right)^{1/p}\n$$\n则当 p 依次取 $-\\infty, 1, 2, +\\infty$ 时，分别对应如下范数：\n$$\n\\lVert x \\rVert_{-\\infty} = \\lim_{p \\to -\\infty} \\left(\\sum_{j=1}^{n} {\\lvert x_j \\rvert}^p\\right)^{1/p} =\n\\min_{j} {\\lvert x_j \\rvert} \\tag{$L_{-\\infty}$}\n$$\n$$\n\\lVert x \\rVert_1 = \\sum_{j=1}^{n} {\\lvert x_j \\rvert} \\tag{$L_1$}\n$$\n$$\n\\lVert x \\rVert_2 = \\left(\\sum_{j=1}^{n} {\\lvert x_j \\rvert}^2\\right)^{1/2} \\tag{$L_2$}\n$$\n$$\n\\lVert x \\rVert_{+\\infty} = \\lim_{p \\to +\\infty} \\left(\\sum_{j=1}^{n} {\\lvert x_j \\rvert}^p\\right)^{1/p} =\n\\max_{j} {\\lvert x_j \\rvert} \\tag{$L_{+\\infty}$}\n$$\n补充说明：\nL1 范数，也称作曼哈顿距离； L2 范数，也称作欧氏距离，可用于计算向量的模（本文默认省略下标 2）； L$+\\infty$ 范数，也称作切比雪夫距离或最大范数； 矩阵范数 极大似然估计 极大似然估计是一种已知样本数据估计（反推）概率分布参数的方法。 极大似然估计（Maximum Likelihood Estimation）的思想是，假设 m 个样本独立同分布于目标概率分布函数 $p(x;\\theta)$，然后构造一个似然函数 $L(\\theta)$ 来表示 m 个样本的联合概率，通过最大化这个联合概率来求解参数 $\\theta$，即：\n$$ L(\\theta) = p(x^{(1)}, x^{(2)}, \\cdots, x^{(m)}) = \\prod_{i=1}^{m} p(x^{(i)};\\theta) $$\n其中 $\\lbrace x^{(1)}, x^{(2)}, \\cdots, x^{(m)} \\rbrace$ 为已知样本数据。\n说明：由于假设样本独立同分布，则联合概率等于各自概率的乘积。\n贝叶斯定理 贝叶斯定理（Bayes\u0026rsquo;theorem）公式如下（其中 $P(B) \\neq 0$）：\n$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n说明：\n可由条件概率 $P(A,B) = P(A|B)P(B) = P(B|A)P(A)$ 推导得到； $P(A|B)$ 是 $A$ 的后验概率，$P(A)$ 是 $A$ 的先验概率，$\\frac{P(B|A)}{P(B)}$ 称作标准似然度，因此贝叶斯公式可表示为：$$ A 的后验概率 = A 的先验概率 * 标准似然度 $$ 基础知识背景见下方。\n联合概率 $A$ 和 $B$ 同时发生的概率，记作 $P(A,B)$ 或 $P(AB)$ 或 $P(A \\cap B)$.\n条件概率 $B$ 发生的条件下 $A$ 发生的概率，记作 $A$ 的条件概率 $P(A|B)$，其中 $P(B) \\neq 0$：$$ P(A|B) = \\frac{P(A,B)}{P(B)} $$\n先验概率 以经验进行判断，如 $P(A)$.\n后验概率 以结果进行判断。当条件概率 $P(A|B)$ 中隐含 $A$（因）会导致 $B$（果）发生时，则称此条件概率为 $A$ 的后验概率，可理解为 $P(因|果)$。\n相互独立 $A$ 与 $B$ 相互独立，当且仅当以下成立：\n$$P(A,B) = P(A)P(B)$$\n朴素贝叶斯朴素在假设特征之间相互独立。 概率分布函数 离散型随机变量对应概率质量函数（Probability Mass Function, PMF），连续型随机变量对应概率密度函数（Probability Density Function, PDF）。\n均匀分布 随机变量 $X = \\lbrace a_1,a_2,\\cdots,a_n \\rbrace$ 服从均匀分布，则：\n$$ p(X=x) = \\frac{1}{n} \\tag{PMF} $$\n随机变量 $X \\in [a,b]$ 服从均匀分布，则：\n$$\np(X=x) =\n\\begin{cases}\n\\frac{1}{b-a} \u0026amp; \\text{if $x \\in [a,b]$} \\\\\n\\\\0 \u0026amp; \\text{if $x \\notin [a,b]$}\n\\end{cases} \\tag{PDF}\n$$\n伯努利分布 一次伯努利试验对应伯努利分布。 指每次试验的结果只有两种可能，要么成功（1），要么失败（0）。设成功（1）的概率为 $p$，则成功（1）发生的次数 $X$ 服从伯努利分布，记作：\n$$\nX \\sim Bernoulli(p)\n$$\n其中 $x \\in \\lbrace 0, 1 \\rbrace$，有：\n$$\np(X=x;p) = p^x(1-p)^{1-x} \\tag{PMF}\n$$\n$$ \\mu = p $$\n$$ \\sigma^2 = p(1-p) $$\n说明：上述试验称为伯努利试验。\n二项分布 重复 n 次伯努利试验即得到二项分布。 指每次试验的结果只有两种可能，重复 n 次试验，设成功（1）的概率为 $p$，则成功（1）发生的次数 $X$ 服从二项分布，记作：\n$$\nX \\sim B(n, p)\n$$\n其中 $x \\in \\lbrace 0, 1, \u0026hellip;, n \\rbrace$，有：\n$$\np(X=x;n,p) = \\frac{n!}{x!(n-x)!} p^x (1-p)^{n-x} \\tag{PMF}\n$$\n$$ \\mu = np $$\n$$ \\sigma^2 = np(1-p) $$\n多项分布 多项分布是二项分布推广到每次试验的结果有 k 种可能的情形。 指每次试验的结果有 k 种可能，重复 n 次试验，设结果 $j$ 的概率为 $p_j$，则所有结果发生的次数 $X = (X_1, \\cdots, X_k)$ 服从多项分布，记作：\n$$\nX \\sim M(n, p_1, \\cdots, p_k)\n$$\n其中 $x_j \\in \\lbrace 0,\\cdots n \\rbrace, \\sum_{j=1}^k x_j = n$，有：\n$$\np(X_1=x_1,\\cdots,X_k=x_k;n,p_1,\\cdots,p_k) = \\frac{n!}{x_1! \\cdots x_k!} p_1^{x_1} \\cdots p_k^{x_k} \\tag{PMF}\n$$\n说明：\n当 $k=2,n=1$ 时对应伯努利分布； 当 $k=2,n\u0026gt;1$ 时对应二项分布； 当 $k\u0026gt;2,n\u0026gt;1$ 时对应多项分布。 泊松分布 泊松分布是二项分布中 p 很小 n 很大时的一种极限形式。 指单位时间内，若随机事件发生的次数的期望值为 $\\lambda$，则随机事件发生的次数 $X$ 服从泊松分布，记作：\n$$\nX \\sim Poisson(\\lambda)\n$$\n其中 $x \\in \\lbrace 0, 1, \\cdots \\rbrace$，有：\n$$\np(X=x;\\lambda) = \\frac{\\lambda^x}{x!} e^{- \\lambda} \\tag{PMF}\n$$\n$$ \\mu = \\lambda $$\n$$ \\sigma^2 = \\lambda $$\n高斯分布 随机变量 $X$ 服从均值 $\\mu$，方差 $\\sigma^2$ 的高斯（正态）分布，记作：\n$$\nX \\sim N(\\mu, \\sigma^2)\n$$\n其中 $x \\in [-\\infty, +\\infty]$，有：\n$$\np(X=x;\\mu,\\sigma) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left(-\\frac{(x-\\mu)^2} {2 \\sigma^2}\\right) \\tag{PDF}\n$$\n说明：方差越大，分布越分散（混乱），越扁，熵越大（平均信息量越大）。\n指数分布 指单位时间内，若随机事件发生的次数的期望值为 $\\lambda$，则随机事件发生的时间间隔 $X$ 服从指数分布，记作：\n$$\nX \\sim \\exp(\\lambda)\n$$\n其中 $x \\in [0, +\\infty]$，有：\n$$\np(X=x;\\lambda) = \\lambda e^{-\\lambda x} \\tag{PDF}\n$$\n$$ \\mu = \\frac{1}{\\lambda} $$\n$$ \\sigma^2 = \\frac{1}{\\lambda^2} $$\n熵 信息量是信息的大小，熵是信息量的期望值，相对熵用于衡量两个概率分布之间的差异，交叉熵是相对熵的简化版。 信息量 给定随机变量 $X$ 的概率分布 $p(x) \\in [0,1]$，则当 $X=x$ 发生时，$x$ 的信息量定义如下：\n$$ I(x) = \\ln \\frac{1}{p(x)} = - \\ln p(x) $$\n其中 $\\displaystyle \\sum_x p(x) = 1$.\n说明：\n信息量针对的是单一事件，大小仅受概率影响。概率越小，信息量越大； 对数底数仅影响量化的单位，以 2 为底对应比特，以 e 为底对应纳特（默认）。 熵 熵（Entropy）等于随机变量 $X$ 所有可能取值的 信息量的期望值，用于衡量混乱程度或不确定性，定义如下：\n$$\nH(X) = E(I(x)) = \\sum_x p(x) I(x) = - \\sum_x p(x) \\ln p(x)\n$$\n说明：\n熵针对的是整个概率分布，也记作 $H(p)$。熵越大（平均信息量越大），分布越混乱； 离散型随机变量对应求和，连续型随机变量对应求积分（已省略）； 相对熵 相对熵（Relative Entropy），又称为 KL 散度（Kullback-Leibler divergence），用于衡量两个概率分布之间的差异程度。对于随机变量 $X$ 的两个概率分布 $p(x)$ 和 $q(x)$，其相对熵定义如下：\n$$ D_{KL}(p||q) = \\sum_x p(x) \\ln \\frac{p(x)}{q(x)} $$\n说明：非负，且越小，则 $p(x)$ 和 $q(x)$ 分布越接近；\n证明：相对熵非负 由于 $\\ln(x) \\leq x - 1$，则：\n$$\n\\begin{split}\n- D_{KL}(p||q) \u0026amp;= \\sum_x p(x) \\ln \\frac{q(x)}{p(x)} \\\\\n\u0026amp;\\leq \\sum_x p(x) (\\frac{q(x)}{p(x)} - 1) \u0026amp;= \\sum_x (q(x) - p(x)) = 0\n\\end{split}\n$$\n因此 $D_{KL}(p||q) \\geq 0$，当且仅当 $p(x) = q(x)$ 时为零。\n交叉熵 将上述相对熵公式展开：\n$$\n\\begin{split}\nD_{KL}(p||q) \u0026amp;= \\sum_x p(x) \\ln \\frac{p(x)}{q(x)} \\\\\n\\\\\u0026amp;= \\sum_x p(x) \\ln p(x) - \\sum_x p(x) \\ln q(x) \\\\\n\\\\\u0026amp;= -H(p) + H(p,q)\n\\end{split}\n$$\n其中，前半部分就是负的 $p(x)$ 的熵，后半部分则就是交叉熵（Cross Entropy）：$$ H(p,q) = - \\sum_x p(x) \\ln q(x) $$\n实际应用中，如果将 $p(x)$ 和 $q(x)$ 分别作为真实值和预测值的概率分布，则由于前者的熵 $H(p)$ 是一个常数，因此：\n$$ D_{KL}(p||q) \\simeq H(p,q)$$\n条件熵 给定随机变量 $X$ 和 $Y$ 及对应的概率分布 $p(x)$ 和 $p(y)$，则顾名思义条件熵定义如下：\n$$\nH(Y|X) = \\sum_{x} p(x) H(Y|x) = \\sum_{x} p(x) \\sum_{y} p(y|x) \\ln(p(y|x))\n$$\n说明：可理解为原数据集是 $Y$，条件（特征）$X$ 将原数据集分组后，新的一组数据集 $Y|X$ 的熵。从全概率公式角度理解，$\\displaystyle\\sum_{condition} p(condition) H(goal|condition)$.\n用途：决策树\n信息增益 分组使得熵减（数据纯度提升），熵减的大小就是信息增益。\n$$\nGain(Y, X) = H(Y) - H(Y|X)\n$$\n用途：决策树 ID3 算法\n信息增益率 分组后信息增益与条件的熵的比值。\n$$\nr(Y, X) = \\frac{Gain(Y, X)}{H(X)}\n$$\n用途：决策树 C4.5 算法\n","description":"监督学习包括线性回归，逻辑回归，SVM，朴素贝叶斯，决策树，随机森林，XGBoost；无监督学习包括 K-means，PCA 等。附带复习相关数学基础。","id":17,"section":"zh","tags":["sklearn"],"title":"学习笔记：吴恩达机器学习","uri":"https://mollywangup.com/zh/posts/notes-machine-learning/"},{"content":"背景信息 Apache Druid: 26.0.0 Batch ingestion task informations: SQL-based ingestion S3 input source Duplicate column entries found 详细报错 1 2 3 4 { \u0026#34;errorCode\u0026#34;: \u0026#34;CannotParseExternalData\u0026#34;, \u0026#34;errorMessage\u0026#34;: \u0026#34;Duplicate column entries found : [0, Facebook]\u0026#34; } 解决方案 Druid 属于列式存储，出现此问题的根本原因是，存在名称相同的两列。因此需要定位到名称相同的两列，并进行手动调整。\n我遇到这个问题，是因为 MMP 方写入到 S3 的一手原始数据本身就是有问题的，具体表现为原始数据表头丢失，导致 Druid 自动识别到存在三列名称都为空的列。详见下方：\n踩坑举例：发生在 S3 的 .csv.gz 原始数据 以下是正常的表头：\n以下是有问题的表头：\nInsertTimeOutOfBounds 详细报错 1 2 3 4 5 { \u0026#34;errorCode\u0026#34;: \u0026#34;InsertTimeOutOfBoundsFault\u0026#34;, \u0026#34;interval\u0026#34;: \u0026#34;2023-06-09T00:00:00.000Z/2023-06-10T00:00:00.000Z\u0026#34;, \u0026#34;errorMessage\u0026#34;: \u0026#34;Query generated time chunk [2023-06-09T00:00:00.000Z/2023-06-10T00:00:00.000Z] out of bounds specified by replaceExistingTimeChunks\u0026#34; } 解决方案 此问题一般发生在 REPLACE specific time ranges，即类似下列的任务中：\n1 2 3 4 5 REPLACE INTO \u0026lt;target table\u0026gt; OVERWRITE WHERE __time \u0026gt;= TIMESTAMP \u0026#39;\u0026lt;lower bound\u0026gt;\u0026#39; AND __time \u0026lt; TIMESTAMP \u0026#39;\u0026lt;upper bound\u0026gt;\u0026#39; \u0026lt; SELECT query \u0026gt; PARTITIONED BY \u0026lt;time granularity\u0026gt; [ CLUSTERED BY \u0026lt;column list\u0026gt; ] 出现此问题的原因是，查询生成的时间段超出了由 replaceExistingTimeChunks 指定的边界，因此需要检查并修改日期字段。\n我遇到这个问题，是因为在上述任务中的 WHERE 语句中，MILLIS_TO_TIMESTAMP(\u0026quot;{created_at}\u0026quot; * 1000) 的格式转换有问题（具体是没有*1000就直接转时间戳），导致最终的时间戳对应的是-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z\nWorker did not start in timeout 详细报错 以下已省略其他敏感信息：\n1 2 3 4 { \u0026#34;type\u0026#34;: \u0026#34;query_controller\u0026#34;, \u0026#34;errorMsg\u0026#34;: \u0026#34;The worker that this task is assigned did not start it in timeout[PT5M]. See overlord and middleMana...\u0026#34; } 解决方案 我遇到这个问题，是直接在 Druid 控制后台运行批量摄取任务时发生的。一般情况下是因为服务器存储空间不足。（🙊 来自小公司的小声bb）\n以下清理内存的一些常用方法。\n👉 定期清除日志文件，指路我的另一篇文章 使用 Crontab 添加定时任务\nLinux 1 2 3 4 5 6 7 # 查看日志内存占用大小 df -h du -sh /var/log/* | sort -hr | head -n 10 du -sh /opt/druid/apache-druid-26.0.0/log/* | sort -hr | head -n 10 # 移除所有的 Druid 的日志文件 sudo rm /opt/druid/apache-druid-26.0.0/log/*.log 未完待续 \u0026hellip;\n","description":"Duplicate column entries found, InsertTimeOutOfBounds, The worker that this task is assigned did not start it in timeout.","id":18,"section":"posts","tags":["Apache Druid","S3"],"title":"踩坑：Druid + S3 批量摄取任务中的各种报错","uri":"https://mollywangup.com/posts/troubleshooting-druid-batch-ingestion-task/"},{"content":"背景信息 Apache Druid: 26.0.0 Batch ingestion task informations: SQL-based ingestion S3 input source Duplicate column entries found 详细报错 1 2 3 4 { \u0026#34;errorCode\u0026#34;: \u0026#34;CannotParseExternalData\u0026#34;, \u0026#34;errorMessage\u0026#34;: \u0026#34;Duplicate column entries found : [0, Facebook]\u0026#34; } 解决方案 Druid 属于列式存储，出现此问题的根本原因是，存在名称相同的两列。因此需要定位到名称相同的两列，并进行手动调整。\n我遇到这个问题，是因为 MMP 方写入到 S3 的一手原始数据本身就是有问题的，具体表现为原始数据表头丢失，导致 Druid 自动识别到存在三列名称都为空的列。详见下方：\n踩坑举例：发生在 S3 的 .csv.gz 原始数据 以下是正常的表头：\n以下是有问题的表头：\nInsertTimeOutOfBounds 详细报错 1 2 3 4 5 { \u0026#34;errorCode\u0026#34;: \u0026#34;InsertTimeOutOfBoundsFault\u0026#34;, \u0026#34;interval\u0026#34;: \u0026#34;2023-06-09T00:00:00.000Z/2023-06-10T00:00:00.000Z\u0026#34;, \u0026#34;errorMessage\u0026#34;: \u0026#34;Query generated time chunk [2023-06-09T00:00:00.000Z/2023-06-10T00:00:00.000Z] out of bounds specified by replaceExistingTimeChunks\u0026#34; } 解决方案 此问题一般发生在 REPLACE specific time ranges，即类似下列的任务中：\n1 2 3 4 5 REPLACE INTO \u0026lt;target table\u0026gt; OVERWRITE WHERE __time \u0026gt;= TIMESTAMP \u0026#39;\u0026lt;lower bound\u0026gt;\u0026#39; AND __time \u0026lt; TIMESTAMP \u0026#39;\u0026lt;upper bound\u0026gt;\u0026#39; \u0026lt; SELECT query \u0026gt; PARTITIONED BY \u0026lt;time granularity\u0026gt; [ CLUSTERED BY \u0026lt;column list\u0026gt; ] 出现此问题的原因是，查询生成的时间段超出了由 replaceExistingTimeChunks 指定的边界，因此需要检查并修改日期字段。\n我遇到这个问题，是因为在上述任务中的 WHERE 语句中，MILLIS_TO_TIMESTAMP(\u0026quot;{created_at}\u0026quot; * 1000) 的格式转换有问题（具体是没有*1000就直接转时间戳），导致最终的时间戳对应的是-146136543-09-08T08:23:32.096Z/146140482-04-24T15:36:27.903Z\nWorker did not start in timeout 详细报错 以下已省略其他敏感信息：\n1 2 3 4 { \u0026#34;type\u0026#34;: \u0026#34;query_controller\u0026#34;, \u0026#34;errorMsg\u0026#34;: \u0026#34;The worker that this task is assigned did not start it in timeout[PT5M]. See overlord and middleMana...\u0026#34; } 解决方案 我遇到这个问题，是直接在 Druid 控制后台运行批量摄取任务时发生的。一般情况下是因为服务器存储空间不足。（🙊 来自小公司的小声bb）\n以下清理内存的一些常用方法。\n👉 定期清除日志文件，指路我的另一篇文章 使用 Crontab 添加定时任务\nLinux 1 2 3 4 5 6 7 # 查看日志内存占用大小 df -h du -sh /var/log/* | sort -hr | head -n 10 du -sh /opt/druid/apache-druid-26.0.0/log/* | sort -hr | head -n 10 # 移除所有的 Druid 的日志文件 sudo rm /opt/druid/apache-druid-26.0.0/log/*.log 未完待续 \u0026hellip;\n","description":"Duplicate column entries found, InsertTimeOutOfBounds, The worker that this task is assigned did not start it in timeout.","id":19,"section":"zh","tags":["Apache Druid","S3"],"title":"踩坑：Druid + S3 批量摄取任务中的各种报错","uri":"https://mollywangup.com/zh/posts/troubleshooting-druid-batch-ingestion-task/"},{"content":"🙇‍♀️ 本文是个文章地图索引。\n本文旨在将来自 Adjust 的原始数据可视化在 Superset. 其中，不同的工具分工如下：\nAdjust： MMP； 用于收集原始数据； S3： 云存储，分布式文件系统； 用于存储原始数据； Apache Druid： 开源的 OLAP 数据库，列式存储，时间序列分析； 可用于批量摄取来自 S3 的原始数据； 可用于将 segments 数据持久化到 S3（建议新建一个专门的存储捅）； Apache Superset： 开源的可视化工具； 可直接连接 Apache Druid 数据库； Step1. 收集原始数据 本文使用的是 Adjust.\n👇 指路我的另外两篇文章：\n使用 Adjust 追踪事件和收入数据 使用 Adjust + FCM 追踪卸载和重装 Step2. 存储原始数据 本文使用的是 S3.\n👉 指路我的另外一篇文章 将 Adjust 原始数据导出的两种方法\nStep3. 转存至数仓 本文使用的是 Apache Druid.\n👉 指路我的另外一篇文章 使用 Druid SQL-based ingestion 批量摄取 S3 数据\nStep4. 可视化 本文使用的是 Apache Superset.\nDocker 部署：apache/superset 支持的数据库：Supported Databases 附：原始数据清洗 SQL 👉 指路我的另外一篇文章 基于 Adjust 原始数据的指标体系\n","description":"将 Adjust 原始数据可视化至 Apache Superset.","id":20,"section":"posts","tags":["Adjust","S3","Apache Druid","Apache Superset"],"title":"BI 方案：Adjust + S3 + Druid + Superset","uri":"https://mollywangup.com/posts/bi-solution-adjust-s3-druid-superset/"},{"content":"🙇‍♀️ 本文是个文章地图索引。\n本文旨在将来自 Adjust 的原始数据可视化在 Superset. 其中，不同的工具分工如下：\nAdjust： MMP； 用于收集原始数据； S3： 云存储，分布式文件系统； 用于存储原始数据； Apache Druid： 开源的 OLAP 数据库，列式存储，时间序列分析； 可用于批量摄取来自 S3 的原始数据； 可用于将 segments 数据持久化到 S3（建议新建一个专门的存储捅）； Apache Superset： 开源的可视化工具； 可直接连接 Apache Druid 数据库； Step1. 收集原始数据 本文使用的是 Adjust.\n👇 指路我的另外两篇文章：\n使用 Adjust 追踪事件和收入数据 使用 Adjust + FCM 追踪卸载和重装 Step2. 存储原始数据 本文使用的是 S3.\n👉 指路我的另外一篇文章 将 Adjust 原始数据导出的两种方法\nStep3. 转存至数仓 本文使用的是 Apache Druid.\n👉 指路我的另外一篇文章 使用 Druid SQL-based ingestion 批量摄取 S3 数据\nStep4. 可视化 本文使用的是 Apache Superset.\nDocker 部署：apache/superset 支持的数据库：Supported Databases 附：原始数据清洗 SQL 👉 指路我的另外一篇文章 基于 Adjust 原始数据的指标体系\n","description":"将 Adjust 原始数据可视化至 Apache Superset.","id":21,"section":"zh","tags":["Adjust","S3","Apache Druid","Apache Superset"],"title":"BI 方案：Adjust + S3 + Druid + Superset","uri":"https://mollywangup.com/zh/posts/bi-solution-adjust-s3-druid-superset/"},{"content":"本文基于 Adjust（原始数据） -\u0026gt; S3（云存储）-\u0026gt; Druid（数仓）-\u0026gt; Superset（可视化）。\n几点说明：\n共两个阶段会对已有字段（以下称为列）进行加工： 写入数仓时：在 Adjust/S3 原有列的基础上； 写入数仓后：在 Druid 原有列的基础上，也就是可视化查询时； 示例的 SQL 语句省略了除0的情况； Druid 不支持窗口函数； 统计原则 一个 ID，两个时间戳 adid：用户唯一标识； installed_at：首次打开的时间戳； created_at：事件发生的时间戳，在数仓中为__time；（Druid 需要） 时区说明：时间戳类型全部为 UTC 时区； 统计次数 没有使用 COUNT(*)，是为了事件去重。\n1 COUNT(DISTINCT __time) 统计人数 使用的是 Adjust 的设备标识 adid.\n1 COUNT(DISTINCT adid) 统计频次 次数 / 人数。\n1 COUNT(DISTINCT __time) / COUNT(DISTINCT adid) 新增计算列 ⚠️ 注意：写入数仓前的批量任务中新增，因此是基于 Adjust/S3 的原始列。 days_x ✍ 同期群分析，本质上是围绕 created_at 和 installed_at 之间相差的天数展开的。\n1 2 3 4 5 6 7 8 -- days_x TIMESTAMPDIFF(DAY, MILLIS_TO_TIMESTAMP(\u0026#34;{installed_at}\u0026#34; * 1000), MILLIS_TO_TIMESTAMP(\u0026#34;{created_at}\u0026#34; * 1000)) AS \u0026#34;days_x\u0026#34; -- hours_x TIMESTAMPDIFF(HOUR, MILLIS_TO_TIMESTAMP(\u0026#34;{installed_at}\u0026#34; * 1000), MILLIS_TO_TIMESTAMP(\u0026#34;{created_at}\u0026#34; * 1000)) AS \u0026#34;hours_x\u0026#34; -- minutes_x TIMESTAMPDIFF(MINUTE, MILLIS_TO_TIMESTAMP(\u0026#34;{installed_at}\u0026#34; * 1000), MILLIS_TO_TIMESTAMP(\u0026#34;{created_at}\u0026#34; * 1000)) AS \u0026#34;minutes_x\u0026#34; 关于次日，有两种可能的定义：\n1.严格间隔 24h 为次日；\n2.过了零点就是次日了;\n⚠️ Adjust 和这里计算 days_x 的方式，都属于第一种。 event_name 取齐，便于分析。\n1 2 3 4 CASE WHEN \u0026#34;{activity_kind}\u0026#34; \u0026lt;\u0026gt; \u0026#39;event\u0026#39; THEN \u0026#34;{activity_kind}\u0026#34; ELSE \u0026#34;{event_name}\u0026#34; END AS \u0026#34;event_name\u0026#34; media_source 用于区分流量来源（归因）。\n⚠️ 需要按需修改：实际接入的流量源。\n1 2 3 4 CASE WHEN \u0026#34;{fb_install_referrer_campaign_group_id}\u0026#34; IS NOT NULL THEN \u0026#39;Facebook Ads\u0026#39; ELSE \u0026#39;Organic\u0026#39; END AS \u0026#34;media_source\u0026#34; revenue_kind 用于区分收入类型。\n⚠️ 需要按需修改：收入事件名称。\n1 2 3 4 5 6 CASE WHEN \u0026#34;{activity_kind}\u0026#34; = \u0026#39;ad_revenue\u0026#39; THEN \u0026#39;Ad\u0026#39; WHEN \u0026#34;{event_name}\u0026#34; = \u0026#39;purchase\u0026#39; THEN \u0026#39;IAP\u0026#39; WHEN \u0026#34;{event_name}\u0026#34; = \u0026#39;subscription\u0026#39; THEN \u0026#39;Subscription\u0026#39; ELSE \u0026#39;Unknown\u0026#39; END AS \u0026#34;revenue_kind\u0026#34; revenue 用于统一计算所有类型的收入：广告、内购（一次性）、订阅。\n⚠️ 需要按需修改：实际接入的聚合平台、收入事件名称。\n1 2 3 4 5 CASE WHEN \u0026#34;{event_name}\u0026#34; IN (\u0026#39;purchase\u0026#39;, \u0026#39;subscription\u0026#39;) THEN \u0026#34;[price]\u0026#34; WHEN \u0026#34;{activity_kind}\u0026#34; = \u0026#39;ad_revenue\u0026#39; AND \u0026#34;{ad_mediation_platform}\u0026#34; = \u0026#39;applovin_max_sdk\u0026#39; THEN \u0026#34;{reporting_revenue}\u0026#34; ELSE 0 END AS \u0026#34;revenue\u0026#34; is_test_device 未严格在 sandbox 环境测试时，手动维护的内部测试设置列表，用于剥离出生成环境的数据。\n1 2 3 4 5 CASE WHEN \u0026#34;{gps_adid}\u0026#34; IN (\u0026#39;83640d56-411c-46b2-9e2b-10ca1ad1abe1\u0026#39;, \u0026#39;af7f3092-445d-4db0-b682-297b5bb5fdc4\u0026#39;) THEN \u0026#39;t\u0026#39; WHEN REGEXP_LIKE(\u0026#34;{device_name}\u0026#34;, \u0026#39;XXXMobi\u0026#39;) THEN \u0026#39;t\u0026#39; ELSE \u0026#39;f\u0026#39; END AS \u0026#34;is_test_device\u0026#34; 基础指标 ⚠️ 注意：写入数仓后计算的，因此是基于 Druid 的原始列。 newUser 新增。\n1 COUNT(DISTINCT CASE WHEN activity_kind = \u0026#39;install\u0026#39; THEN adid END) DAU 关于活跃的定义：\nAdjust：与应用发生互动，见 What is an active user? Firebase：user_engagement 事件，见 User activity over time BigQuery：至少发生了一个事件，且该事件的参数 engagement_time_msec \u0026gt; 0，见 N-day active users 自行定义：至少发生了一次自定义的 login 事件； 1 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; THEN adid END) ARPDAU 活跃用户的 ARPU，其中活跃使用上述自定义的。\n1 SUM(revenue) / DAU ARPU (New) 新用户的 ARPU.\n1 SUM(revenue) / newUser 同期群指标 RR 留存率。与上述活跃定义取齐，留存率计算公式：Rx = Dx活跃 / D0活跃。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- 0D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; AND days_x = 0 THEN adid END) -- 1D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; AND days_x = 1 THEN adid END) -- 7D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; AND days_x = 7 THEN adid END) -- R1 1D / 0D -- R7 7D / 0D LTV 给定周期内的总收入。\n1 2 3 4 5 -- LT7 SUM(CASE WHEN days_x \u0026lt;= 6 THEN revenue END) -- LT14 SUM(CASE WHEN days_x \u0026lt;= 13 THEN revenue END) 广告变现指标 Imps 广告展示次数。\n1 COUNT(DISTINCT CASE WHEN activity_kind = \u0026#39;ad_revenue\u0026#39; THEN __time END) DAV 广告展示人数。\n1 COUNT(DISTINCT CASE WHEN activity_kind = \u0026#39;ad_revenue\u0026#39; THEN adid END) eCPM 1 SUM(CASE WHEN revenue_kind = \u0026#39;Ad\u0026#39; THEN revenue END) / Imps * 1000 Imps per DAU 活跃用户，平均广告展示次数。\n1 Imps / DAU Imps per DAV 看到广告的用户，平均广告展示次数。\n1 Imps / DAV 未完待续 \u0026hellip;\n附：原始数据结构 原始数据示例，有助于理解数据结构。\nAdjust/S3 原始数据举例（已脱敏） 1 2 {environment}\t{activity_kind}\t{created_at}\t{installed_at}\t{timezone}\t{app_name}\t{app_version_short}\t{country}\t{city}\t{os_name}\t{os_version}\t{device_type}\t{device_manufacturer}\t{device_name}\t{gps_adid}\t{adid}\t{android_id}\t{language}\t{tracker}\t{tracker_name}\t{is_organic}\t{is_reattributed}\t{reporting_currency}\t{reporting_cost}\t{reporting_revenue}\t{event}\t{event_name}\t[level]\t[id]\t[price]\t[subscription_type]\t[transaction_id]\t[error_code]\t{ad_mediation_platform}\t{ad_revenue_network}\t[ad_format]\t[ad_space]\t[ad_network_name]\t[ad_revenue]\t[ad_error_code]\t[is_vip]\t[trial_state]\t{fb_install_referrer_publisher_platform}\t{fb_install_referrer_campaign_group_name}\t{fb_install_referrer_campaign_group_id}\t{fb_install_referrer_campaign_name}\t{fb_install_referrer_campaign_id}\t{fb_install_referrer_adgroup_name}\t{fb_install_referrer_adgroup_id}\tproduction\tevent\t1687957195\t1687956440\tUTC-0600\tPACKAGE_NAME\t1.1.1\tus\tNampa\tandroid\t13\tphone\tSamsung\tGalaxyA715G\t21d01e91-1338-44ba-94c1-9a392d832d5b\tdf50cd2988ddf1f78b6116c22389c557\ten\tunattr\tUnattributed\t0\t0\t71cxx6\tclaim_rewarded_ad\tRewarded\t1110004\tf\tnever\tunknown\tCAMPAIGN_NAME\t23855267775170400\tADSET_NAME\t23855267775220400\tAD_NAME\t23855268033500400\tDruid 原始数据举例（已脱敏） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \u0026#34;__time\u0026#34;:\u0026#34;2023-07-14T07:28:54.000Z\u0026#34;, \u0026#34;environment\u0026#34;:\u0026#34;production\u0026#34;, \u0026#34;activity_kind\u0026#34;:\u0026#34;event\u0026#34;, \u0026#34;installed_at\u0026#34;:1689319730000, \u0026#34;timezone\u0026#34;:\u0026#34;UTC-0700\u0026#34;, \u0026#34;app_name\u0026#34;:\u0026#34;PACKAGE_NAME\u0026#34;, \u0026#34;app_version_short\u0026#34;:\u0026#34;1.1.2\u0026#34;, \u0026#34;country\u0026#34;:\u0026#34;us\u0026#34;, \u0026#34;city\u0026#34;:\u0026#34;Los Angeles\u0026#34;, \u0026#34;os_name\u0026#34;:\u0026#34;android\u0026#34;, \u0026#34;os_version\u0026#34;:\u0026#34;12\u0026#34;, \u0026#34;device_type\u0026#34;:\u0026#34;phone\u0026#34;, \u0026#34;device_manufacturer\u0026#34;:\u0026#34;Motorola\u0026#34;, \u0026#34;device_name\u0026#34;:\u0026#34;motogstylus5G(2022)\u0026#34;, \u0026#34;gps_adid\u0026#34;:\u0026#34;1af0adeb-5f20-4b13-a7c7-ae11cbf55947\u0026#34;, \u0026#34;adid\u0026#34;:\u0026#34;b82355d7d28c623bf918156c8f7486b1\u0026#34;, \u0026#34;android_id\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;language\u0026#34;:\u0026#34;en\u0026#34;, \u0026#34;tracker\u0026#34;:\u0026#34;11n573m9\u0026#34;, \u0026#34;tracker_name\u0026#34;:\u0026#34;Organic\u0026#34;, \u0026#34;is_organic\u0026#34;:1, \u0026#34;is_reattributed\u0026#34;:0, \u0026#34;reporting_currency\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;reporting_cost\u0026#34;:0, \u0026#34;reporting_revenue\u0026#34;:0, \u0026#34;event\u0026#34;:\u0026#34;mbvbnw\u0026#34;, \u0026#34;event_name2\u0026#34;:\u0026#34;login\u0026#34;, \u0026#34;level\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;id\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;price\u0026#34;:0, \u0026#34;subscription_type\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;transaction_id\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;error_code\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;ad_mediation_platform\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;ad_revenue_network\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;ad_format\u0026#34;:\u0026#34;Unknown\u0026#34;, \u0026#34;ad_space\u0026#34;:\u0026#34;Unknown\u0026#34;, \u0026#34;ad_network_name\u0026#34;:\u0026#34;Unknown\u0026#34;, \u0026#34;ad_revenue\u0026#34;:0, \u0026#34;ad_error_code\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;is_vip\u0026#34;:\u0026#34;f\u0026#34;, \u0026#34;trial_state\u0026#34;:\u0026#34;never\u0026#34;, \u0026#34;fb_network_name\u0026#34;:\u0026#34;instagram\u0026#34;, \u0026#34;fb_campaign_name\u0026#34;:\u0026#34;CAMPAIGN_NAME\u0026#34;, \u0026#34;fb_campaign_id\u0026#34;:\u0026#34;23855267775170453\u0026#34;, \u0026#34;fb_adgroup_name\u0026#34;:\u0026#34;ADSET_NAME\u0026#34;, \u0026#34;fb_adgroup_id\u0026#34;:\u0026#34;23855267775220453\u0026#34;, \u0026#34;fb_creative_name\u0026#34;:\u0026#34;AD_NAME\u0026#34;, \u0026#34;fb_creative_id\u0026#34;:\u0026#34;23855268033500453\u0026#34;, \u0026#34;phase\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;update_at\u0026#34;:1689328800513, \u0026#34;days_x\u0026#34;:0, \u0026#34;hours_x\u0026#34;:0, \u0026#34;minutes_x\u0026#34;:0, \u0026#34;event_name\u0026#34;:\u0026#34;login\u0026#34;, \u0026#34;revenue_kind\u0026#34;:\u0026#34;Unknown\u0026#34;, \u0026#34;media_source\u0026#34;:\u0026#34;Facebook Ads\u0026#34;, \u0026#34;revenue\u0026#34;:0, \u0026#34;is_test_device\u0026#34;:\u0026#34;f\u0026#34; } ","description":"newUser, DAU, ARPDAU, ARPU (New), DAV, eCPM, RR, LTV 等。","id":22,"section":"posts","tags":["Adjust","Apache Druid"],"title":"基于 Adjust 原始数据的指标体系","uri":"https://mollywangup.com/posts/common-dimensions-and-metrics-based-on-adjust-raw-data/"},{"content":"本文基于 Adjust（原始数据） -\u0026gt; S3（云存储）-\u0026gt; Druid（数仓）-\u0026gt; Superset（可视化）。\n几点说明：\n共两个阶段会对已有字段（以下称为列）进行加工： 写入数仓时：在 Adjust/S3 原有列的基础上； 写入数仓后：在 Druid 原有列的基础上，也就是可视化查询时； 示例的 SQL 语句省略了除0的情况； Druid 不支持窗口函数； 统计原则 一个 ID，两个时间戳 adid：用户唯一标识； installed_at：首次打开的时间戳； created_at：事件发生的时间戳，在数仓中为__time；（Druid 需要） 时区说明：时间戳类型全部为 UTC 时区； 统计次数 没有使用 COUNT(*)，是为了事件去重。\n1 COUNT(DISTINCT __time) 统计人数 使用的是 Adjust 的设备标识 adid.\n1 COUNT(DISTINCT adid) 统计频次 次数 / 人数。\n1 COUNT(DISTINCT __time) / COUNT(DISTINCT adid) 新增计算列 ⚠️ 注意：写入数仓前的批量任务中新增，因此是基于 Adjust/S3 的原始列。 days_x ✍ 同期群分析，本质上是围绕 created_at 和 installed_at 之间相差的天数展开的。\n1 2 3 4 5 6 7 8 -- days_x TIMESTAMPDIFF(DAY, MILLIS_TO_TIMESTAMP(\u0026#34;{installed_at}\u0026#34; * 1000), MILLIS_TO_TIMESTAMP(\u0026#34;{created_at}\u0026#34; * 1000)) AS \u0026#34;days_x\u0026#34; -- hours_x TIMESTAMPDIFF(HOUR, MILLIS_TO_TIMESTAMP(\u0026#34;{installed_at}\u0026#34; * 1000), MILLIS_TO_TIMESTAMP(\u0026#34;{created_at}\u0026#34; * 1000)) AS \u0026#34;hours_x\u0026#34; -- minutes_x TIMESTAMPDIFF(MINUTE, MILLIS_TO_TIMESTAMP(\u0026#34;{installed_at}\u0026#34; * 1000), MILLIS_TO_TIMESTAMP(\u0026#34;{created_at}\u0026#34; * 1000)) AS \u0026#34;minutes_x\u0026#34; 关于次日，有两种可能的定义：\n1.严格间隔 24h 为次日；\n2.过了零点就是次日了;\n⚠️ Adjust 和这里计算 days_x 的方式，都属于第一种。 event_name 取齐，便于分析。\n1 2 3 4 CASE WHEN \u0026#34;{activity_kind}\u0026#34; \u0026lt;\u0026gt; \u0026#39;event\u0026#39; THEN \u0026#34;{activity_kind}\u0026#34; ELSE \u0026#34;{event_name}\u0026#34; END AS \u0026#34;event_name\u0026#34; media_source 用于区分流量来源（归因）。\n⚠️ 需要按需修改：实际接入的流量源。\n1 2 3 4 CASE WHEN \u0026#34;{fb_install_referrer_campaign_group_id}\u0026#34; IS NOT NULL THEN \u0026#39;Facebook Ads\u0026#39; ELSE \u0026#39;Organic\u0026#39; END AS \u0026#34;media_source\u0026#34; revenue_kind 用于区分收入类型。\n⚠️ 需要按需修改：收入事件名称。\n1 2 3 4 5 6 CASE WHEN \u0026#34;{activity_kind}\u0026#34; = \u0026#39;ad_revenue\u0026#39; THEN \u0026#39;Ad\u0026#39; WHEN \u0026#34;{event_name}\u0026#34; = \u0026#39;purchase\u0026#39; THEN \u0026#39;IAP\u0026#39; WHEN \u0026#34;{event_name}\u0026#34; = \u0026#39;subscription\u0026#39; THEN \u0026#39;Subscription\u0026#39; ELSE \u0026#39;Unknown\u0026#39; END AS \u0026#34;revenue_kind\u0026#34; revenue 用于统一计算所有类型的收入：广告、内购（一次性）、订阅。\n⚠️ 需要按需修改：实际接入的聚合平台、收入事件名称。\n1 2 3 4 5 CASE WHEN \u0026#34;{event_name}\u0026#34; IN (\u0026#39;purchase\u0026#39;, \u0026#39;subscription\u0026#39;) THEN \u0026#34;[price]\u0026#34; WHEN \u0026#34;{activity_kind}\u0026#34; = \u0026#39;ad_revenue\u0026#39; AND \u0026#34;{ad_mediation_platform}\u0026#34; = \u0026#39;applovin_max_sdk\u0026#39; THEN \u0026#34;{reporting_revenue}\u0026#34; ELSE 0 END AS \u0026#34;revenue\u0026#34; is_test_device 未严格在 sandbox 环境测试时，手动维护的内部测试设置列表，用于剥离出生成环境的数据。\n1 2 3 4 5 CASE WHEN \u0026#34;{gps_adid}\u0026#34; IN (\u0026#39;83640d56-411c-46b2-9e2b-10ca1ad1abe1\u0026#39;, \u0026#39;af7f3092-445d-4db0-b682-297b5bb5fdc4\u0026#39;) THEN \u0026#39;t\u0026#39; WHEN REGEXP_LIKE(\u0026#34;{device_name}\u0026#34;, \u0026#39;XXXMobi\u0026#39;) THEN \u0026#39;t\u0026#39; ELSE \u0026#39;f\u0026#39; END AS \u0026#34;is_test_device\u0026#34; 基础指标 ⚠️ 注意：写入数仓后计算的，因此是基于 Druid 的原始列。 newUser 新增。\n1 COUNT(DISTINCT CASE WHEN activity_kind = \u0026#39;install\u0026#39; THEN adid END) DAU 关于活跃的定义：\nAdjust：与应用发生互动，见 What is an active user? Firebase：user_engagement 事件，见 User activity over time BigQuery：至少发生了一个事件，且该事件的参数 engagement_time_msec \u0026gt; 0，见 N-day active users 自行定义：至少发生了一次自定义的 login 事件； 1 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; THEN adid END) ARPDAU 活跃用户的 ARPU，其中活跃使用上述自定义的。\n1 SUM(revenue) / DAU ARPU (New) 新用户的 ARPU.\n1 SUM(revenue) / newUser 同期群指标 RR 留存率。与上述活跃定义取齐，留存率计算公式：Rx = Dx活跃 / D0活跃。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- 0D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; AND days_x = 0 THEN adid END) -- 1D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; AND days_x = 1 THEN adid END) -- 7D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; AND days_x = 7 THEN adid END) -- R1 1D / 0D -- R7 7D / 0D LTV 给定周期内的总收入。\n1 2 3 4 5 -- LT7 SUM(CASE WHEN days_x \u0026lt;= 6 THEN revenue END) -- LT14 SUM(CASE WHEN days_x \u0026lt;= 13 THEN revenue END) 广告变现指标 Imps 广告展示次数。\n1 COUNT(DISTINCT CASE WHEN activity_kind = \u0026#39;ad_revenue\u0026#39; THEN __time END) DAV 广告展示人数。\n1 COUNT(DISTINCT CASE WHEN activity_kind = \u0026#39;ad_revenue\u0026#39; THEN adid END) eCPM 1 SUM(CASE WHEN revenue_kind = \u0026#39;Ad\u0026#39; THEN revenue END) / Imps * 1000 Imps per DAU 活跃用户，平均广告展示次数。\n1 Imps / DAU Imps per DAV 看到广告的用户，平均广告展示次数。\n1 Imps / DAV 未完待续 \u0026hellip;\n附：原始数据结构 原始数据示例，有助于理解数据结构。\nAdjust/S3 原始数据举例（已脱敏） 1 2 {environment}\t{activity_kind}\t{created_at}\t{installed_at}\t{timezone}\t{app_name}\t{app_version_short}\t{country}\t{city}\t{os_name}\t{os_version}\t{device_type}\t{device_manufacturer}\t{device_name}\t{gps_adid}\t{adid}\t{android_id}\t{language}\t{tracker}\t{tracker_name}\t{is_organic}\t{is_reattributed}\t{reporting_currency}\t{reporting_cost}\t{reporting_revenue}\t{event}\t{event_name}\t[level]\t[id]\t[price]\t[subscription_type]\t[transaction_id]\t[error_code]\t{ad_mediation_platform}\t{ad_revenue_network}\t[ad_format]\t[ad_space]\t[ad_network_name]\t[ad_revenue]\t[ad_error_code]\t[is_vip]\t[trial_state]\t{fb_install_referrer_publisher_platform}\t{fb_install_referrer_campaign_group_name}\t{fb_install_referrer_campaign_group_id}\t{fb_install_referrer_campaign_name}\t{fb_install_referrer_campaign_id}\t{fb_install_referrer_adgroup_name}\t{fb_install_referrer_adgroup_id}\tproduction\tevent\t1687957195\t1687956440\tUTC-0600\tPACKAGE_NAME\t1.1.1\tus\tNampa\tandroid\t13\tphone\tSamsung\tGalaxyA715G\t21d01e91-1338-44ba-94c1-9a392d832d5b\tdf50cd2988ddf1f78b6116c22389c557\ten\tunattr\tUnattributed\t0\t0\t71cxx6\tclaim_rewarded_ad\tRewarded\t1110004\tf\tnever\tunknown\tCAMPAIGN_NAME\t23855267775170400\tADSET_NAME\t23855267775220400\tAD_NAME\t23855268033500400\tDruid 原始数据举例（已脱敏） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \u0026#34;__time\u0026#34;:\u0026#34;2023-07-14T07:28:54.000Z\u0026#34;, \u0026#34;environment\u0026#34;:\u0026#34;production\u0026#34;, \u0026#34;activity_kind\u0026#34;:\u0026#34;event\u0026#34;, \u0026#34;installed_at\u0026#34;:1689319730000, \u0026#34;timezone\u0026#34;:\u0026#34;UTC-0700\u0026#34;, \u0026#34;app_name\u0026#34;:\u0026#34;PACKAGE_NAME\u0026#34;, \u0026#34;app_version_short\u0026#34;:\u0026#34;1.1.2\u0026#34;, \u0026#34;country\u0026#34;:\u0026#34;us\u0026#34;, \u0026#34;city\u0026#34;:\u0026#34;Los Angeles\u0026#34;, \u0026#34;os_name\u0026#34;:\u0026#34;android\u0026#34;, \u0026#34;os_version\u0026#34;:\u0026#34;12\u0026#34;, \u0026#34;device_type\u0026#34;:\u0026#34;phone\u0026#34;, \u0026#34;device_manufacturer\u0026#34;:\u0026#34;Motorola\u0026#34;, \u0026#34;device_name\u0026#34;:\u0026#34;motogstylus5G(2022)\u0026#34;, \u0026#34;gps_adid\u0026#34;:\u0026#34;1af0adeb-5f20-4b13-a7c7-ae11cbf55947\u0026#34;, \u0026#34;adid\u0026#34;:\u0026#34;b82355d7d28c623bf918156c8f7486b1\u0026#34;, \u0026#34;android_id\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;language\u0026#34;:\u0026#34;en\u0026#34;, \u0026#34;tracker\u0026#34;:\u0026#34;11n573m9\u0026#34;, \u0026#34;tracker_name\u0026#34;:\u0026#34;Organic\u0026#34;, \u0026#34;is_organic\u0026#34;:1, \u0026#34;is_reattributed\u0026#34;:0, \u0026#34;reporting_currency\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;reporting_cost\u0026#34;:0, \u0026#34;reporting_revenue\u0026#34;:0, \u0026#34;event\u0026#34;:\u0026#34;mbvbnw\u0026#34;, \u0026#34;event_name2\u0026#34;:\u0026#34;login\u0026#34;, \u0026#34;level\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;id\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;price\u0026#34;:0, \u0026#34;subscription_type\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;transaction_id\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;error_code\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;ad_mediation_platform\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;ad_revenue_network\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;ad_format\u0026#34;:\u0026#34;Unknown\u0026#34;, \u0026#34;ad_space\u0026#34;:\u0026#34;Unknown\u0026#34;, \u0026#34;ad_network_name\u0026#34;:\u0026#34;Unknown\u0026#34;, \u0026#34;ad_revenue\u0026#34;:0, \u0026#34;ad_error_code\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;is_vip\u0026#34;:\u0026#34;f\u0026#34;, \u0026#34;trial_state\u0026#34;:\u0026#34;never\u0026#34;, \u0026#34;fb_network_name\u0026#34;:\u0026#34;instagram\u0026#34;, \u0026#34;fb_campaign_name\u0026#34;:\u0026#34;CAMPAIGN_NAME\u0026#34;, \u0026#34;fb_campaign_id\u0026#34;:\u0026#34;23855267775170453\u0026#34;, \u0026#34;fb_adgroup_name\u0026#34;:\u0026#34;ADSET_NAME\u0026#34;, \u0026#34;fb_adgroup_id\u0026#34;:\u0026#34;23855267775220453\u0026#34;, \u0026#34;fb_creative_name\u0026#34;:\u0026#34;AD_NAME\u0026#34;, \u0026#34;fb_creative_id\u0026#34;:\u0026#34;23855268033500453\u0026#34;, \u0026#34;phase\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;update_at\u0026#34;:1689328800513, \u0026#34;days_x\u0026#34;:0, \u0026#34;hours_x\u0026#34;:0, \u0026#34;minutes_x\u0026#34;:0, \u0026#34;event_name\u0026#34;:\u0026#34;login\u0026#34;, \u0026#34;revenue_kind\u0026#34;:\u0026#34;Unknown\u0026#34;, \u0026#34;media_source\u0026#34;:\u0026#34;Facebook Ads\u0026#34;, \u0026#34;revenue\u0026#34;:0, \u0026#34;is_test_device\u0026#34;:\u0026#34;f\u0026#34; } ","description":"newUser, DAU, ARPDAU, ARPU (New), DAV, eCPM, RR, LTV 等。","id":23,"section":"zh","tags":["Adjust","Apache Druid"],"title":"基于 Adjust 原始数据的指标体系","uri":"https://mollywangup.com/zh/posts/common-dimensions-and-metrics-based-on-adjust-raw-data/"},{"content":"本文旨在将来自 S3 的 .csv.gz 数据，批量摄取至 Druid. 其中：\nApache Druid: 26.0.0 参考文档： SQL-based ingestion S3 input source REPLACE all data 1 2 3 4 5 REPLACE INTO \u0026lt;target table\u0026gt; OVERWRITE ALL \u0026lt; SELECT query \u0026gt; PARTITIONED BY \u0026lt;time granularity\u0026gt; [ CLUSTERED BY \u0026lt;column list\u0026gt; ] REPLACE specific time ranges 1 2 3 4 5 REPLACE INTO \u0026lt;target table\u0026gt; OVERWRITE WHERE __time \u0026gt;= TIMESTAMP \u0026#39;\u0026lt;lower bound\u0026gt;\u0026#39; AND __time \u0026lt; TIMESTAMP \u0026#39;\u0026lt;upper bound\u0026gt;\u0026#39; \u0026lt; SELECT query \u0026gt; PARTITIONED BY \u0026lt;time granularity\u0026gt; [ CLUSTERED BY \u0026lt;column list\u0026gt; ] ","description":"S3 是 .csv.gz 格式，Druid 是 segments 格式。","id":24,"section":"posts","tags":["Apache Druid","S3"],"title":"使用 Druid SQL-based ingestion 批量摄取 S3 数据","uri":"https://mollywangup.com/posts/ingest-s3-data-with-druid-sql-based-ingestion-task/"},{"content":"本文旨在将来自 S3 的 .csv.gz 数据，批量摄取至 Druid. 其中：\nApache Druid: 26.0.0 参考文档： SQL-based ingestion S3 input source REPLACE all data 1 2 3 4 5 REPLACE INTO \u0026lt;target table\u0026gt; OVERWRITE ALL \u0026lt; SELECT query \u0026gt; PARTITIONED BY \u0026lt;time granularity\u0026gt; [ CLUSTERED BY \u0026lt;column list\u0026gt; ] REPLACE specific time ranges 1 2 3 4 5 REPLACE INTO \u0026lt;target table\u0026gt; OVERWRITE WHERE __time \u0026gt;= TIMESTAMP \u0026#39;\u0026lt;lower bound\u0026gt;\u0026#39; AND __time \u0026lt; TIMESTAMP \u0026#39;\u0026lt;upper bound\u0026gt;\u0026#39; \u0026lt; SELECT query \u0026gt; PARTITIONED BY \u0026lt;time granularity\u0026gt; [ CLUSTERED BY \u0026lt;column list\u0026gt; ] ","description":"S3 是 .csv.gz 格式，Druid 是 segments 格式。","id":25,"section":"zh","tags":["Apache Druid","S3"],"title":"使用 Druid SQL-based ingestion 批量摄取 S3 数据","uri":"https://mollywangup.com/zh/posts/ingest-s3-data-with-druid-sql-based-ingestion-task/"},{"content":"🙇‍♀️ 本文是个文章地图索引。\n本文旨在将来自 Firebase/BigQuery 的原始数据可视化在 Looker Studio. 其中，不同的工具分工如下：\nFirebase： BAAS； 用于收集原始数据； GCS： 云存储，Google 生态； 用于存储原始数据； BigQuery： OLAP 数据库，列式存储，Google 生态； Looker Studio： Google 生态的可视化工具； 可直接连接 BigQuery，Google 生态； Step1. 收集原始数据 本文使用的是 Firebase.\n👇 指路我的另外一篇文章 使用 Firebase 统计事件\u0026amp;设置用户属性\nStep2. 原始数据至数仓 本文使用的是 GCS + BigQuery.\n仅需在 GA 后台设置导出至 BigQuery，即可实现自动将原始数据存储在 GCS 并存储至 BigQuery.\nStep3. 可视化 本文使用的是 Looker Studio.\n傻瓜式操作，见 Connect to Data\n附：原始数据清洗 SQL 👉 指路我的另外一篇文章 基于 BigQuery 原始数据的指标体系\n","description":"【太贵弃之】将 Firebase 原始数据可视化至 Looker Studio.","id":26,"section":"posts","tags":["Firebase","GCS","BigQuery","Looker Studio"],"title":"BI 方案：Firebase + GCS + BigQuery + Looker Studio","uri":"https://mollywangup.com/posts/bi-solution-firebase-gcs-bigquery-looker/"},{"content":"🙇‍♀️ 本文是个文章地图索引。\n本文旨在将来自 Firebase/BigQuery 的原始数据可视化在 Looker Studio. 其中，不同的工具分工如下：\nFirebase： BAAS； 用于收集原始数据； GCS： 云存储，Google 生态； 用于存储原始数据； BigQuery： OLAP 数据库，列式存储，Google 生态； Looker Studio： Google 生态的可视化工具； 可直接连接 BigQuery，Google 生态； Step1. 收集原始数据 本文使用的是 Firebase.\n👇 指路我的另外一篇文章 使用 Firebase 统计事件\u0026amp;设置用户属性\nStep2. 原始数据至数仓 本文使用的是 GCS + BigQuery.\n仅需在 GA 后台设置导出至 BigQuery，即可实现自动将原始数据存储在 GCS 并存储至 BigQuery.\nStep3. 可视化 本文使用的是 Looker Studio.\n傻瓜式操作，见 Connect to Data\n附：原始数据清洗 SQL 👉 指路我的另外一篇文章 基于 BigQuery 原始数据的指标体系\n","description":"【太贵弃之】将 Firebase 原始数据可视化至 Looker Studio.","id":27,"section":"zh","tags":["Firebase","GCS","BigQuery","Looker Studio"],"title":"BI 方案：Firebase + GCS + BigQuery + Looker Studio","uri":"https://mollywangup.com/zh/posts/bi-solution-firebase-gcs-bigquery-looker/"},{"content":"本文基于 Firebase（原始数据）-\u0026gt; GCS（云存储）-\u0026gt; BigQuery（数仓）-\u0026gt; Looker Studio（可视化）。\n几点说明：\n共两个阶段会对已有字段（以下称为列）进行加工： 在 Looker Studio 连接 BigQuery 数据源时：加在原有列的基础上； 在 Looker Studio 可视化查询时：加在已导入列的基础上，即实时可视化查询时； 示例的 SQL 语句省略了除0的情况； BigQuery 支持窗口函数； 统计原则 一个 ID，两个时间戳 user_pseudo_id：用户唯一标识； user_first_touch_timestamp：首次打开的时间戳； event_timestamp：事件发生的时间戳； 时区说明：\nevent_date：导出至 BigQuery 设置中的时区；\nevent_timestamp/user_first_touch_timestamp：时间戳类型全部为 UTC 时区； 统计次数 没有使用 COUNT(*)，是为了事件去重。\n1 COUNT(DISTINCT event_timestamp) 统计人数 使用的是 Firebase/BigQuery 的匿名用户标识 user_pseudo_id.\n1 COUNT(DISTINCT user_pseudo_id) 统计频次 次数 / 人数。\n1 COUNT(DISTINCT event_timestamp) / COUNT(DISTINCT user_pseudo_id) 新增计算列 ⚠️ 注意：在 Looker Studio 连接 BigQuery 数据源时新增，因此是基于 Firebase/BigQuery 的原始列。 days_x ✍ 同期群分析，本质上是围绕 event_timestamp 和 user_first_touch_timestamp 之间相差的天数展开的。\n1 2 3 4 5 6 7 8 -- days_x CAST(TIMESTAMP_DIFF(TIMESTAMP_MICROS(event_timestamp), TIMESTAMP_MICROS(user_first_touch_timestamp), DAY) AS INT64) AS days_x -- hours_x CAST(TIMESTAMP_DIFF(TIMESTAMP_MICROS(event_timestamp), TIMESTAMP_MICROS(user_first_touch_timestamp), HOUR) AS INT64) AS hours_x -- minutes_x CAST(TIMESTAMP_DIFF(TIMESTAMP_MICROS(event_timestamp), TIMESTAMP_MICROS(user_first_touch_timestamp), MINUTE) AS INT64) AS minutes_x media_source 用于区分流量来源（归因）。\n⚠️ 需要按需修改：实际接入的流量源。\n👉 指路我的另外一篇文章 使用 Play Install Referrer API 解密 Facebook Campaign\n1 2 3 4 CASE traffic_source.source WHEN \u0026#39;apps.facebook.com\u0026#39; THEN \u0026#39;Facebook Ads\u0026#39; ELSE \u0026#39;Organic\u0026#39; END AS media_source revenue_kind 用于区分收入类型。\n⚠️ 需要按需修改：收入事件名称。\n1 2 3 4 5 6 CASE event_name WHEN \u0026#39;ad_revenue\u0026#39; THEN \u0026#39;Ad\u0026#39; WHEN \u0026#39;purchase\u0026#39; THEN \u0026#39;IAP\u0026#39; WHEN \u0026#39;subscription\u0026#39; THEN \u0026#39;Subscription\u0026#39; ELSE \u0026#39;unknown\u0026#39; END AS revenue_kind revenue 用于统一计算所有类型的收入：广告、内购（一次性）、订阅。\n⚠️ 需要按需修改：实际接入的聚合平台、收入事件名称。\n1 2 3 4 5 CASE WHEN event_name = \u0026#39;ad_revenue\u0026#39; AND event_params.key = \u0026#39;ad_revenue\u0026#39; THEN event_params.value.double_value WHEN event_name IN (\u0026#39;purchase\u0026#39;, \u0026#39;subscription\u0026#39;) AND event_params.key = \u0026#39;price\u0026#39; THEN event_params.value.float_value ELSE 0 END AS revenue 基础指标 ⚠️ 注意：在 Looker Studio 的可视化查询时实时计算的。 newUser 新增。\n1 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;first_open\u0026#39; THEN user_pseudo_id END) DAU 关于活跃的定义：\nAdjust：与应用发生互动，见 What is an active user? Firebase：user_engagement 事件，见 User activity over time BigQuery：至少发生了一个事件，且该事件的参数 engagement_time_msec \u0026gt; 0，见 N-day active users 自行定义：至少发生了一次自定义的 login 事件； 1 2 3 4 5 -- Firebase 定义的活跃 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;user_engagement\u0026#39; THEN user_pseudo_id END) -- 自定义的活跃 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; THEN user_pseudo_id END) ARPDAU 活跃用户的 ARPU，其中活跃使用上述自定义的。\n1 SUM(revenue) / DAU ARPU (New) 新用户的 ARPU.\n1 SUM(revenue) / newUser 同期群指标 RR 留存率。与上述活跃定义取齐，留存率计算公式：Rx = Dx活跃 / D0活跃。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- 0D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;user_engagement\u0026#39; AND days_x = 0 THEN user_pseudo_id END) -- 1D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;user_engagement\u0026#39; AND days_x = 1 THEN user_pseudo_id END) -- 7D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;user_engagement\u0026#39; AND days_x = 7 THEN user_pseudo_id END) -- R1 1D / 0D -- R7 7D / 0D LTV 给定周期内的总收入。\n1 2 3 4 5 -- LT7 SUM(CASE WHEN days_x \u0026lt;= 6 THEN revenue END) -- LT14 SUM(CASE WHEN days_x \u0026lt;= 13 THEN revenue END) 广告变现指标 Imps 广告展示次数。\n1 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;ad_play_ok\u0026#39; THEN event_timestamp END) DAV 广告展示人数。\n1 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;ad_play_ok\u0026#39; THEN user_pseudo_id END) eCPM 1 SUM(CASE WHEN revenue_kind = \u0026#39;Ad\u0026#39; THEN revenue END) / Imps * 1000 Imps per DAU 活跃用户，平均广告展示次数。\n1 Imps / DAU Imps per DAV 看到广告的用户，平均广告展示次数。\n1 Imps / DAV 附：原始数据结构 以下为自定义事件 sign_up 的原始数据，有助于理解数据结构。\nFirebase/BigQuery 原始数据举例（已脱敏） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 [{ \u0026#34;event_date\u0026#34;: \u0026#34;20230116\u0026#34;, \u0026#34;event_timestamp\u0026#34;: \u0026#34;1673858401132002\u0026#34;, \u0026#34;event_name\u0026#34;: \u0026#34;sign_up\u0026#34;, \u0026#34;event_params\u0026#34;: [{ \u0026#34;key\u0026#34;: \u0026#34;firebase_screen_class\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: \u0026#34;UnityPlayerActivity\u0026#34;, \u0026#34;int_value\u0026#34;: null, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;method\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;int_value\u0026#34;: null, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;ga_session_id\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;1673858394\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;ga_session_number\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;firebase_screen_id\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;-5164663614086310235\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;firebase_event_origin\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: \u0026#34;app\u0026#34;, \u0026#34;int_value\u0026#34;: null, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;engaged_session_event\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }], \u0026#34;event_previous_timestamp\u0026#34;: \u0026#34;1673780157003002\u0026#34;, \u0026#34;event_value_in_usd\u0026#34;: null, \u0026#34;event_bundle_sequence_id\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;event_server_timestamp_offset\u0026#34;: \u0026#34;2492698\u0026#34;, \u0026#34;user_id\u0026#34;: null, \u0026#34;user_pseudo_id\u0026#34;: \u0026#34;8d59ce7133e03f6170eadbce40174c91\u0026#34;, \u0026#34;privacy_info\u0026#34;: { \u0026#34;analytics_storage\u0026#34;: \u0026#34;Yes\u0026#34;, \u0026#34;ads_storage\u0026#34;: \u0026#34;Yes\u0026#34;, \u0026#34;uses_transient_token\u0026#34;: \u0026#34;No\u0026#34; }, \u0026#34;user_properties\u0026#34;: [{ \u0026#34;key\u0026#34;: \u0026#34;ga_session_id\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;1673858394\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null, \u0026#34;set_timestamp_micros\u0026#34;: \u0026#34;1673858394853000\u0026#34; } }, { \u0026#34;key\u0026#34;: \u0026#34;first_open_time\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;1673780400000\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null, \u0026#34;set_timestamp_micros\u0026#34;: \u0026#34;1673777018672000\u0026#34; } }, { \u0026#34;key\u0026#34;: \u0026#34;ga_session_number\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null, \u0026#34;set_timestamp_micros\u0026#34;: \u0026#34;1673858394853000\u0026#34; } }, { \u0026#34;key\u0026#34;: \u0026#34;player_match_level\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: \u0026#34;8\u0026#34;, \u0026#34;int_value\u0026#34;: null, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null, \u0026#34;set_timestamp_micros\u0026#34;: \u0026#34;1673780429774000\u0026#34; } }], \u0026#34;user_first_touch_timestamp\u0026#34;: \u0026#34;1673777018672000\u0026#34;, \u0026#34;user_ltv\u0026#34;: null, \u0026#34;device\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;mobile_brand_name\u0026#34;: \u0026#34;Xiaomi\u0026#34;, \u0026#34;mobile_model_name\u0026#34;: \u0026#34;M2104K10AC\u0026#34;, \u0026#34;mobile_marketing_name\u0026#34;: \u0026#34;Redmi K40 Gaming Edition\u0026#34;, \u0026#34;mobile_os_hardware_model\u0026#34;: \u0026#34;M2104K10AC\u0026#34;, \u0026#34;operating_system\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;operating_system_version\u0026#34;: \u0026#34;Android 11\u0026#34;, \u0026#34;vendor_id\u0026#34;: null, \u0026#34;advertising_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;language\u0026#34;: \u0026#34;zh-cn\u0026#34;, \u0026#34;is_limited_ad_tracking\u0026#34;: \u0026#34;No\u0026#34;, \u0026#34;time_zone_offset_seconds\u0026#34;: \u0026#34;28800\u0026#34;, \u0026#34;browser\u0026#34;: null, \u0026#34;browser_version\u0026#34;: null, \u0026#34;web_info\u0026#34;: null }, \u0026#34;geo\u0026#34;: { \u0026#34;continent\u0026#34;: \u0026#34;Asia\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;China\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;sub_continent\u0026#34;: \u0026#34;Eastern Asia\u0026#34;, \u0026#34;metro\u0026#34;: \u0026#34;(not set)\u0026#34; }, \u0026#34;app_info\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;PACKAGE_NAME\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.2.8\u0026#34;, \u0026#34;install_store\u0026#34;: null, \u0026#34;firebase_app_id\u0026#34;: \u0026#34;1:65595447720:android:aa82859441a614a0aba59d\u0026#34;, \u0026#34;install_source\u0026#34;: \u0026#34;com.miui.packageinstaller\u0026#34; }, \u0026#34;traffic_source\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;(direct)\u0026#34;, \u0026#34;medium\u0026#34;: \u0026#34;(none)\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;(direct)\u0026#34; }, \u0026#34;stream_id\u0026#34;: \u0026#34;3607414280\u0026#34;, \u0026#34;platform\u0026#34;: \u0026#34;ANDROID\u0026#34;, \u0026#34;event_dimensions\u0026#34;: null, \u0026#34;ecommerce\u0026#34;: null, \u0026#34;items\u0026#34;: [] }] ","description":"newUser, DAU, ARPDAU, ARPU (New), DAV, eCPM, RR, LTV 等。","id":28,"section":"posts","tags":["BigQuery"],"title":"基于 BigQuery 原始数据的指标体系","uri":"https://mollywangup.com/posts/common-dimensions-and-metrics-based-on-bigquery-raw-data/"},{"content":"本文基于 Firebase（原始数据）-\u0026gt; GCS（云存储）-\u0026gt; BigQuery（数仓）-\u0026gt; Looker Studio（可视化）。\n几点说明：\n共两个阶段会对已有字段（以下称为列）进行加工： 在 Looker Studio 连接 BigQuery 数据源时：加在原有列的基础上； 在 Looker Studio 可视化查询时：加在已导入列的基础上，即实时可视化查询时； 示例的 SQL 语句省略了除0的情况； BigQuery 支持窗口函数； 统计原则 一个 ID，两个时间戳 user_pseudo_id：用户唯一标识； user_first_touch_timestamp：首次打开的时间戳； event_timestamp：事件发生的时间戳； 时区说明：\nevent_date：导出至 BigQuery 设置中的时区；\nevent_timestamp/user_first_touch_timestamp：时间戳类型全部为 UTC 时区； 统计次数 没有使用 COUNT(*)，是为了事件去重。\n1 COUNT(DISTINCT event_timestamp) 统计人数 使用的是 Firebase/BigQuery 的匿名用户标识 user_pseudo_id.\n1 COUNT(DISTINCT user_pseudo_id) 统计频次 次数 / 人数。\n1 COUNT(DISTINCT event_timestamp) / COUNT(DISTINCT user_pseudo_id) 新增计算列 ⚠️ 注意：在 Looker Studio 连接 BigQuery 数据源时新增，因此是基于 Firebase/BigQuery 的原始列。 days_x ✍ 同期群分析，本质上是围绕 event_timestamp 和 user_first_touch_timestamp 之间相差的天数展开的。\n1 2 3 4 5 6 7 8 -- days_x CAST(TIMESTAMP_DIFF(TIMESTAMP_MICROS(event_timestamp), TIMESTAMP_MICROS(user_first_touch_timestamp), DAY) AS INT64) AS days_x -- hours_x CAST(TIMESTAMP_DIFF(TIMESTAMP_MICROS(event_timestamp), TIMESTAMP_MICROS(user_first_touch_timestamp), HOUR) AS INT64) AS hours_x -- minutes_x CAST(TIMESTAMP_DIFF(TIMESTAMP_MICROS(event_timestamp), TIMESTAMP_MICROS(user_first_touch_timestamp), MINUTE) AS INT64) AS minutes_x media_source 用于区分流量来源（归因）。\n⚠️ 需要按需修改：实际接入的流量源。\n👉 指路我的另外一篇文章 使用 Play Install Referrer API 解密 Facebook Campaign\n1 2 3 4 CASE traffic_source.source WHEN \u0026#39;apps.facebook.com\u0026#39; THEN \u0026#39;Facebook Ads\u0026#39; ELSE \u0026#39;Organic\u0026#39; END AS media_source revenue_kind 用于区分收入类型。\n⚠️ 需要按需修改：收入事件名称。\n1 2 3 4 5 6 CASE event_name WHEN \u0026#39;ad_revenue\u0026#39; THEN \u0026#39;Ad\u0026#39; WHEN \u0026#39;purchase\u0026#39; THEN \u0026#39;IAP\u0026#39; WHEN \u0026#39;subscription\u0026#39; THEN \u0026#39;Subscription\u0026#39; ELSE \u0026#39;unknown\u0026#39; END AS revenue_kind revenue 用于统一计算所有类型的收入：广告、内购（一次性）、订阅。\n⚠️ 需要按需修改：实际接入的聚合平台、收入事件名称。\n1 2 3 4 5 CASE WHEN event_name = \u0026#39;ad_revenue\u0026#39; AND event_params.key = \u0026#39;ad_revenue\u0026#39; THEN event_params.value.double_value WHEN event_name IN (\u0026#39;purchase\u0026#39;, \u0026#39;subscription\u0026#39;) AND event_params.key = \u0026#39;price\u0026#39; THEN event_params.value.float_value ELSE 0 END AS revenue 基础指标 ⚠️ 注意：在 Looker Studio 的可视化查询时实时计算的。 newUser 新增。\n1 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;first_open\u0026#39; THEN user_pseudo_id END) DAU 关于活跃的定义：\nAdjust：与应用发生互动，见 What is an active user? Firebase：user_engagement 事件，见 User activity over time BigQuery：至少发生了一个事件，且该事件的参数 engagement_time_msec \u0026gt; 0，见 N-day active users 自行定义：至少发生了一次自定义的 login 事件； 1 2 3 4 5 -- Firebase 定义的活跃 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;user_engagement\u0026#39; THEN user_pseudo_id END) -- 自定义的活跃 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;login\u0026#39; THEN user_pseudo_id END) ARPDAU 活跃用户的 ARPU，其中活跃使用上述自定义的。\n1 SUM(revenue) / DAU ARPU (New) 新用户的 ARPU.\n1 SUM(revenue) / newUser 同期群指标 RR 留存率。与上述活跃定义取齐，留存率计算公式：Rx = Dx活跃 / D0活跃。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- 0D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;user_engagement\u0026#39; AND days_x = 0 THEN user_pseudo_id END) -- 1D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;user_engagement\u0026#39; AND days_x = 1 THEN user_pseudo_id END) -- 7D COUNT(DISTINCT CASE WHEN event_name = \u0026#39;user_engagement\u0026#39; AND days_x = 7 THEN user_pseudo_id END) -- R1 1D / 0D -- R7 7D / 0D LTV 给定周期内的总收入。\n1 2 3 4 5 -- LT7 SUM(CASE WHEN days_x \u0026lt;= 6 THEN revenue END) -- LT14 SUM(CASE WHEN days_x \u0026lt;= 13 THEN revenue END) 广告变现指标 Imps 广告展示次数。\n1 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;ad_play_ok\u0026#39; THEN event_timestamp END) DAV 广告展示人数。\n1 COUNT(DISTINCT CASE WHEN event_name = \u0026#39;ad_play_ok\u0026#39; THEN user_pseudo_id END) eCPM 1 SUM(CASE WHEN revenue_kind = \u0026#39;Ad\u0026#39; THEN revenue END) / Imps * 1000 Imps per DAU 活跃用户，平均广告展示次数。\n1 Imps / DAU Imps per DAV 看到广告的用户，平均广告展示次数。\n1 Imps / DAV 附：原始数据结构 以下为自定义事件 sign_up 的原始数据，有助于理解数据结构。\nFirebase/BigQuery 原始数据举例（已脱敏） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 [{ \u0026#34;event_date\u0026#34;: \u0026#34;20230116\u0026#34;, \u0026#34;event_timestamp\u0026#34;: \u0026#34;1673858401132002\u0026#34;, \u0026#34;event_name\u0026#34;: \u0026#34;sign_up\u0026#34;, \u0026#34;event_params\u0026#34;: [{ \u0026#34;key\u0026#34;: \u0026#34;firebase_screen_class\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: \u0026#34;UnityPlayerActivity\u0026#34;, \u0026#34;int_value\u0026#34;: null, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;method\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;int_value\u0026#34;: null, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;ga_session_id\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;1673858394\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;ga_session_number\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;firebase_screen_id\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;-5164663614086310235\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;firebase_event_origin\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: \u0026#34;app\u0026#34;, \u0026#34;int_value\u0026#34;: null, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }, { \u0026#34;key\u0026#34;: \u0026#34;engaged_session_event\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null } }], \u0026#34;event_previous_timestamp\u0026#34;: \u0026#34;1673780157003002\u0026#34;, \u0026#34;event_value_in_usd\u0026#34;: null, \u0026#34;event_bundle_sequence_id\u0026#34;: \u0026#34;22\u0026#34;, \u0026#34;event_server_timestamp_offset\u0026#34;: \u0026#34;2492698\u0026#34;, \u0026#34;user_id\u0026#34;: null, \u0026#34;user_pseudo_id\u0026#34;: \u0026#34;8d59ce7133e03f6170eadbce40174c91\u0026#34;, \u0026#34;privacy_info\u0026#34;: { \u0026#34;analytics_storage\u0026#34;: \u0026#34;Yes\u0026#34;, \u0026#34;ads_storage\u0026#34;: \u0026#34;Yes\u0026#34;, \u0026#34;uses_transient_token\u0026#34;: \u0026#34;No\u0026#34; }, \u0026#34;user_properties\u0026#34;: [{ \u0026#34;key\u0026#34;: \u0026#34;ga_session_id\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;1673858394\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null, \u0026#34;set_timestamp_micros\u0026#34;: \u0026#34;1673858394853000\u0026#34; } }, { \u0026#34;key\u0026#34;: \u0026#34;first_open_time\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;1673780400000\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null, \u0026#34;set_timestamp_micros\u0026#34;: \u0026#34;1673777018672000\u0026#34; } }, { \u0026#34;key\u0026#34;: \u0026#34;ga_session_number\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: null, \u0026#34;int_value\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null, \u0026#34;set_timestamp_micros\u0026#34;: \u0026#34;1673858394853000\u0026#34; } }, { \u0026#34;key\u0026#34;: \u0026#34;player_match_level\u0026#34;, \u0026#34;value\u0026#34;: { \u0026#34;string_value\u0026#34;: \u0026#34;8\u0026#34;, \u0026#34;int_value\u0026#34;: null, \u0026#34;float_value\u0026#34;: null, \u0026#34;double_value\u0026#34;: null, \u0026#34;set_timestamp_micros\u0026#34;: \u0026#34;1673780429774000\u0026#34; } }], \u0026#34;user_first_touch_timestamp\u0026#34;: \u0026#34;1673777018672000\u0026#34;, \u0026#34;user_ltv\u0026#34;: null, \u0026#34;device\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;mobile\u0026#34;, \u0026#34;mobile_brand_name\u0026#34;: \u0026#34;Xiaomi\u0026#34;, \u0026#34;mobile_model_name\u0026#34;: \u0026#34;M2104K10AC\u0026#34;, \u0026#34;mobile_marketing_name\u0026#34;: \u0026#34;Redmi K40 Gaming Edition\u0026#34;, \u0026#34;mobile_os_hardware_model\u0026#34;: \u0026#34;M2104K10AC\u0026#34;, \u0026#34;operating_system\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;operating_system_version\u0026#34;: \u0026#34;Android 11\u0026#34;, \u0026#34;vendor_id\u0026#34;: null, \u0026#34;advertising_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;language\u0026#34;: \u0026#34;zh-cn\u0026#34;, \u0026#34;is_limited_ad_tracking\u0026#34;: \u0026#34;No\u0026#34;, \u0026#34;time_zone_offset_seconds\u0026#34;: \u0026#34;28800\u0026#34;, \u0026#34;browser\u0026#34;: null, \u0026#34;browser_version\u0026#34;: null, \u0026#34;web_info\u0026#34;: null }, \u0026#34;geo\u0026#34;: { \u0026#34;continent\u0026#34;: \u0026#34;Asia\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;China\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;sub_continent\u0026#34;: \u0026#34;Eastern Asia\u0026#34;, \u0026#34;metro\u0026#34;: \u0026#34;(not set)\u0026#34; }, \u0026#34;app_info\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;PACKAGE_NAME\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.2.8\u0026#34;, \u0026#34;install_store\u0026#34;: null, \u0026#34;firebase_app_id\u0026#34;: \u0026#34;1:65595447720:android:aa82859441a614a0aba59d\u0026#34;, \u0026#34;install_source\u0026#34;: \u0026#34;com.miui.packageinstaller\u0026#34; }, \u0026#34;traffic_source\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;(direct)\u0026#34;, \u0026#34;medium\u0026#34;: \u0026#34;(none)\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;(direct)\u0026#34; }, \u0026#34;stream_id\u0026#34;: \u0026#34;3607414280\u0026#34;, \u0026#34;platform\u0026#34;: \u0026#34;ANDROID\u0026#34;, \u0026#34;event_dimensions\u0026#34;: null, \u0026#34;ecommerce\u0026#34;: null, \u0026#34;items\u0026#34;: [] }] ","description":"newUser, DAU, ARPDAU, ARPU (New), DAV, eCPM, RR, LTV 等。","id":29,"section":"zh","tags":["BigQuery"],"title":"基于 BigQuery 原始数据的指标体系","uri":"https://mollywangup.com/zh/posts/common-dimensions-and-metrics-based-on-bigquery-raw-data/"},{"content":"由于 Adjust 看板数据具有较大的分析局限性，因此有必要使用原始数据导出功能，用以更细颗粒度、更自由的多维度交叉分析。\n共两种方法，一种是导出至云存储，一种是实时回传给自己的服务器。\n导出机制 基于事件（广义）及对应的事件参数导出。\n支持的事件（广义） Adjust 称为 activity_kind，但本质上属于事件。对应的是触发机制。常见需要导出的事件如下：\nClick Installs Events：需要手动创建event_token； Ad revenue：需要依赖聚合 SDK 获取，且额外收费； Subscriptions：需要手动添加额外的代码，且额外收费； Uninstall：需要依赖 FCM SDK 每天发送静默推送消息来监测是否已卸载； 支持的事件参数 对应的是数据颗粒度。按照是否需要手动设置，共分为以下两类：\n内置参数：对应 Placeholder，支持的列表见 Adjust Placeholders for Partners\n自定义参数：对应 CallbackParameter，支持的上报方式见： SDK 方式：Callback parameters S2S 方式：Share custom data 方法一：CSV 至云储存 设置每小时自动导出一次：CSV uploads to cloud storage\n需要提前设置接收的云服务器（二选一）：\nAWS S3：Set up your project in the AWS Management Console Google Cloud Storage：Set up your project in the Google Cloud Console 需要提前设置导出的列格式：Format your CSV definition\n共以下3种类型的参数作为列： 常量：使用双引号，如\u0026quot;my constant\u0026quot; 内置参数：使用花括号，如{gps_adid} 自定义参数：使用中括号，如[user_id] 例子： 1 \u0026#34;my constant\u0026#34;,{gps_adid},[user_id],{installed_at},{event_name},[item_number],{reporting_revenue} 方法二：实时回传 设置实时回传：Set up callbacks\n需要提前在自有服务器配置回传 URL： Callback structure Recommended placeholders for callbacks ","description":"共两种方法，实时回传和每小时上传 CSV 至云储存。","id":30,"section":"posts","tags":["Adjust"],"title":"将 Adjust 原始数据导出的两种方法","uri":"https://mollywangup.com/posts/two-methods-for-exporting-adjust-raw-data/"},{"content":"由于 Adjust 看板数据具有较大的分析局限性，因此有必要使用原始数据导出功能，用以更细颗粒度、更自由的多维度交叉分析。\n共两种方法，一种是导出至云存储，一种是实时回传给自己的服务器。\n导出机制 基于事件（广义）及对应的事件参数导出。\n支持的事件（广义） Adjust 称为 activity_kind，但本质上属于事件。对应的是触发机制。常见需要导出的事件如下：\nClick Installs Events：需要手动创建event_token； Ad revenue：需要依赖聚合 SDK 获取，且额外收费； Subscriptions：需要手动添加额外的代码，且额外收费； Uninstall：需要依赖 FCM SDK 每天发送静默推送消息来监测是否已卸载； 支持的事件参数 对应的是数据颗粒度。按照是否需要手动设置，共分为以下两类：\n内置参数：对应 Placeholder，支持的列表见 Adjust Placeholders for Partners\n自定义参数：对应 CallbackParameter，支持的上报方式见： SDK 方式：Callback parameters S2S 方式：Share custom data 方法一：CSV 至云储存 设置每小时自动导出一次：CSV uploads to cloud storage\n需要提前设置接收的云服务器（二选一）：\nAWS S3：Set up your project in the AWS Management Console Google Cloud Storage：Set up your project in the Google Cloud Console 需要提前设置导出的列格式：Format your CSV definition\n共以下3种类型的参数作为列： 常量：使用双引号，如\u0026quot;my constant\u0026quot; 内置参数：使用花括号，如{gps_adid} 自定义参数：使用中括号，如[user_id] 例子： 1 \u0026#34;my constant\u0026#34;,{gps_adid},[user_id],{installed_at},{event_name},[item_number],{reporting_revenue} 方法二：实时回传 设置实时回传：Set up callbacks\n需要提前在自有服务器配置回传 URL： Callback structure Recommended placeholders for callbacks ","description":"共两种方法，实时回传和每小时上传 CSV 至云储存。","id":31,"section":"zh","tags":["Adjust"],"title":"将 Adjust 原始数据导出的两种方法","uri":"https://mollywangup.com/zh/posts/two-methods-for-exporting-adjust-raw-data/"},{"content":"Adjust SDK 无法独自实现追踪卸载和重装，需要借助 FCM SDK 的消息推送功能。\n实现原理 官方文档：Uninstall and reinstall measurement\n概括起来如下：\nFCM 会在新用户首次启动时，为该设备生成一个设备标识符，即 registration token 以下称作 push token，在此应用场景中的作用是消息定位该设备；\nAdjust 获取上述 FCM 生成的 push token，并与自己的设备标识相关联；\nAdjust 通过 FCM 每天向设备发送一个静默的推送消息用于卸载监听，并根据监听结果来判断用户是否发生了卸载或者重装。\nAdjust 服务器发送监听消息给 FCM 其中 pushToken 用于定位设备：\n1 2 3 4 5 6 { \u0026#34;to\u0026#34;:\u0026#34;pushToken\u0026#34;, \u0026#34;data\u0026#34;:{ \u0026#34;adjust_purpose\u0026#34;:\u0026#34;uninstall detection\u0026#34; } } 具体步骤 准备 FCM server key，并配置到 Adjust 后台：\n接入 FCM SDK：Set up a Firebase Cloud Messaging client app on Android\nAdjust SDK 获取 Push tokens：\nPush tokens are used for Audience Builder and client callbacks. They are also required for uninstall and reinstall tracking.\nsetPushToken 1 2 // Send the token with context (recommended) Adjust.setPushToken(pushNotificationsToken, context); ","description":"Adjust SDK 无法独自实现，需要借助 FCM SDK 的消息推送功能来实现。","id":32,"section":"posts","tags":["Adjust","FCM"],"title":"使用 Adjust + FCM 追踪卸载和重装","uri":"https://mollywangup.com/posts/implement-uninstalls-and-reinstalls-with-adjust-and-fcm/"},{"content":"Adjust SDK 无法独自实现追踪卸载和重装，需要借助 FCM SDK 的消息推送功能。\n实现原理 官方文档：Uninstall and reinstall measurement\n概括起来如下：\nFCM 会在新用户首次启动时，为该设备生成一个设备标识符，即 registration token 以下称作 push token，在此应用场景中的作用是消息定位该设备；\nAdjust 获取上述 FCM 生成的 push token，并与自己的设备标识相关联；\nAdjust 通过 FCM 每天向设备发送一个静默的推送消息用于卸载监听，并根据监听结果来判断用户是否发生了卸载或者重装。\nAdjust 服务器发送监听消息给 FCM 其中 pushToken 用于定位设备：\n1 2 3 4 5 6 { \u0026#34;to\u0026#34;:\u0026#34;pushToken\u0026#34;, \u0026#34;data\u0026#34;:{ \u0026#34;adjust_purpose\u0026#34;:\u0026#34;uninstall detection\u0026#34; } } 具体步骤 准备 FCM server key，并配置到 Adjust 后台：\n接入 FCM SDK：Set up a Firebase Cloud Messaging client app on Android\nAdjust SDK 获取 Push tokens：\nPush tokens are used for Audience Builder and client callbacks. They are also required for uninstall and reinstall tracking.\nsetPushToken 1 2 // Send the token with context (recommended) Adjust.setPushToken(pushNotificationsToken, context); ","description":"Adjust SDK 无法独自实现，需要借助 FCM SDK 的消息推送功能来实现。","id":33,"section":"zh","tags":["Adjust","FCM"],"title":"使用 Adjust + FCM 追踪卸载和重装","uri":"https://mollywangup.com/zh/posts/implement-uninstalls-and-reinstalls-with-adjust-and-fcm/"},{"content":"本文旨在使用 Adjust SDK 追踪以下四类事件数据：\n普通事件（指非收入事件）； 广告收入； 内购收入（一次性）； 订阅收入（周期性）； 💡 理论上，收入事件 = 设置了金额和币种参数的普通事件，所以额外收费的广告收入和订阅收入服务，是可以作为一个普通的收入事件上报的（此方法本文已略）。 追踪普通事件 方法描述 在 Adjust 后台为每个事件创建一个 event token，然后直接上报即可。\n1 2 AdjustEvent adjustEvent = new AdjustEvent(\u0026#34;abc123\u0026#34;); Adjust.trackEvent(adjustEvent); 参考文档 [Adjust] Create an event token [GitHub] Track an event 追踪广告收入 共两种方式，推荐 SDK-to-SDK 方式。\n方式一（SDK-to-SDK方式）（推荐） 方法描述 MAX SDK 可获取 Impression-Level User Revenue，通过 SDK-to-SDK 的方式，将 MAX SDK 的 ad revenue 转发给 Adjust SDK.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // Adjust SDK initialization AdjustConfig adjustConfig = new AdjustConfig(\u0026#34;{YourAppToken}\u0026#34;, AdjustEnvironment.Sandbox); adjustConfig.setSendInBackground(true); Adjust.start(adjustConfig); // ... // pass MAX SDK ad revenue data to Adjust SDK public static void OnInterstitialAdRevenuePaidEvent(string adUnitId) { var info = MaxSdk.GetAdInfo(adUnitId); var adRevenue = new AdjustAdRevenue(AdjustConfig.AdjustAdRevenueSourceAppLovinMAX); adRevenue.setRevenue(info.Revenue, \u0026#34;USD\u0026#34;); adRevenue.setAdRevenueNetwork(info.NetworkName); adRevenue.setAdRevenueUnit(info.AdUnitIdentifier); adRevenue.setAdRevenuePlacement(info.Placement); Adjust.trackAdRevenue(adRevenue); } 参考文档 [Adjust] Get real-time data using SDK postbacks [GitHub] Track AppLovin MAX ad revenue with Adjust SDK 方式二（API Key） 方法描述 将 MAX 后台的report key填到 Ajust 后台，本质是通过 API 的形式每天从 MAX 下载一次数据，然后同步至 Adjust 面板；\n参考文档 [Adjust] Connect Adjust to your AppLovin MAX account\n追踪内购收入 方式一（SDK方式） 方法描述 创建一个普通事件如 purchase，在上报时，为其设置金额和币种参数，即可被 Adjust 识别为收入事件。\n1 2 3 4 AdjustEvent adjustEvent = new AdjustEvent(\u0026#34;abc123\u0026#34;); adjustEvent.setRevenue(0.01, \u0026#34;USD\u0026#34;); adjustEvent.setTransactionId(\u0026#34;transactionId\u0026#34;); Adjust.trackEvent(adjustEvent); 补充说明：\nsetRevenue：币种需要设置为USD，即默认币种；\nsetTransactionId：为了防止重复统计内购收入，可设置为订单唯一标识； 参考文档 [Adjust] Track revenue events (with the Adjust SDK) [GitHub] Ad revenue tracking 方式二（S2S方式） 方法描述 自备服务器，且需要设置跟 Adjust 沟通的参数（见 Required parameters ），当发生内购事件时，Adjust 服务器发给我们服务器；\n参考文档 [Adjust] Track revenue events (server-to-server) [Adjust] Server-to-server (S2S) events 追踪订阅收入 方法描述 构造 subscription 对象，直接上报即可。\n⚠️ 注意：price 为 long 类型，假定订阅价格是 $9.99，则需要上报为 9.99 * 1000000 = 9990000，详见 getPriceAmountMicros 1 2 3 4 5 6 7 8 9 10 AdjustPlayStoreSubscription subscription = new AdjustPlayStoreSubscription( price, currency, sku, orderId, signature, purchaseToken); subscription.setPurchaseTime(purchaseTime); Adjust.trackPlayStoreSubscription(subscription); 参考文档 [Adjust] Measure subscriptions [GitHub] Subscription tracking ","description":"广告收入通过聚合 SDK 转发而来（额外收费），内购收入通过设置带有金额和币种参数的普通事件而来，订阅收入有专门的 subscription API（额外收费）。","id":34,"section":"posts","tags":["Adjust"],"title":"使用 Adjust 追踪事件和收入数据","uri":"https://mollywangup.com/posts/tracking-event-and-revenue-with-adjust-sdk/"},{"content":"本文旨在使用 Adjust SDK 追踪以下四类事件数据：\n普通事件（指非收入事件）； 广告收入； 内购收入（一次性）； 订阅收入（周期性）； 💡 理论上，收入事件 = 设置了金额和币种参数的普通事件，所以额外收费的广告收入和订阅收入服务，是可以作为一个普通的收入事件上报的（此方法本文已略）。 追踪普通事件 方法描述 在 Adjust 后台为每个事件创建一个 event token，然后直接上报即可。\n1 2 AdjustEvent adjustEvent = new AdjustEvent(\u0026#34;abc123\u0026#34;); Adjust.trackEvent(adjustEvent); 参考文档 [Adjust] Create an event token [GitHub] Track an event 追踪广告收入 共两种方式，推荐 SDK-to-SDK 方式。\n方式一（SDK-to-SDK方式）（推荐） 方法描述 MAX SDK 可获取 Impression-Level User Revenue，通过 SDK-to-SDK 的方式，将 MAX SDK 的 ad revenue 转发给 Adjust SDK.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // Adjust SDK initialization AdjustConfig adjustConfig = new AdjustConfig(\u0026#34;{YourAppToken}\u0026#34;, AdjustEnvironment.Sandbox); adjustConfig.setSendInBackground(true); Adjust.start(adjustConfig); // ... // pass MAX SDK ad revenue data to Adjust SDK public static void OnInterstitialAdRevenuePaidEvent(string adUnitId) { var info = MaxSdk.GetAdInfo(adUnitId); var adRevenue = new AdjustAdRevenue(AdjustConfig.AdjustAdRevenueSourceAppLovinMAX); adRevenue.setRevenue(info.Revenue, \u0026#34;USD\u0026#34;); adRevenue.setAdRevenueNetwork(info.NetworkName); adRevenue.setAdRevenueUnit(info.AdUnitIdentifier); adRevenue.setAdRevenuePlacement(info.Placement); Adjust.trackAdRevenue(adRevenue); } 参考文档 [Adjust] Get real-time data using SDK postbacks [GitHub] Track AppLovin MAX ad revenue with Adjust SDK 方式二（API Key） 方法描述 将 MAX 后台的report key填到 Ajust 后台，本质是通过 API 的形式每天从 MAX 下载一次数据，然后同步至 Adjust 面板；\n参考文档 [Adjust] Connect Adjust to your AppLovin MAX account\n追踪内购收入 方式一（SDK方式） 方法描述 创建一个普通事件如 purchase，在上报时，为其设置金额和币种参数，即可被 Adjust 识别为收入事件。\n1 2 3 4 AdjustEvent adjustEvent = new AdjustEvent(\u0026#34;abc123\u0026#34;); adjustEvent.setRevenue(0.01, \u0026#34;USD\u0026#34;); adjustEvent.setTransactionId(\u0026#34;transactionId\u0026#34;); Adjust.trackEvent(adjustEvent); 补充说明：\nsetRevenue：币种需要设置为USD，即默认币种；\nsetTransactionId：为了防止重复统计内购收入，可设置为订单唯一标识； 参考文档 [Adjust] Track revenue events (with the Adjust SDK) [GitHub] Ad revenue tracking 方式二（S2S方式） 方法描述 自备服务器，且需要设置跟 Adjust 沟通的参数（见 Required parameters ），当发生内购事件时，Adjust 服务器发给我们服务器；\n参考文档 [Adjust] Track revenue events (server-to-server) [Adjust] Server-to-server (S2S) events 追踪订阅收入 方法描述 构造 subscription 对象，直接上报即可。\n⚠️ 注意：price 为 long 类型，假定订阅价格是 $9.99，则需要上报为 9.99 * 1000000 = 9990000，详见 getPriceAmountMicros 1 2 3 4 5 6 7 8 9 10 AdjustPlayStoreSubscription subscription = new AdjustPlayStoreSubscription( price, currency, sku, orderId, signature, purchaseToken); subscription.setPurchaseTime(purchaseTime); Adjust.trackPlayStoreSubscription(subscription); 参考文档 [Adjust] Measure subscriptions [GitHub] Subscription tracking ","description":"广告收入通过聚合 SDK 转发而来（额外收费），内购收入通过设置带有金额和币种参数的普通事件而来，订阅收入有专门的 subscription API（额外收费）。","id":35,"section":"zh","tags":["Adjust"],"title":"使用 Adjust 追踪事件和收入数据","uri":"https://mollywangup.com/zh/posts/tracking-event-and-revenue-with-adjust-sdk/"},{"content":"本文旨在手动解析一手的 Referrer 信息，并设置为 Firebase 用户属性。如果已经接了 MMP，可直接略过。（🤝 感兴趣也可了解下）\n实现方法： 工具：Play Install Referrer API； 体现：Firebase 的用户属性campaign_id； 局限性： 仅支持安卓系统； 仅支持 Facebook Ads； 方法概述 共三步：\nStep1. 获取 referrerUrl 先接 Play Install Referrer 客户端库； 再通过客户端库的方法获取原始的 referrerUrl； Step2. 解析 referrerUrl（核心） 先从referrerUrl中获取utm_content； 再解密utm_content。方法见官方的 Understand Facebook App Ads Referral URLs，需要用到 Facebook Decryption Key； Step3. 处理解析结果 先从解密后的utm_content中获取campaign_group_id； 再将campaign_group_id设置为用户属性campaign_id； 具体实现 Step1. 获取 referrerUrl 先接 Play Install Referrer 客户端库：\n官方文档：Play Install Referrer Library 他人做法参考：How to Use Google Play Install Referrer API in Android? 再获取原始的 referrerUrl：\n官方方法：Getting the install referrer 1 2 3 4 5 ReferrerDetails response = referrerClient.getInstallReferrer(); String referrerUrl = response.getInstallReferrer(); // 就是这个东西，且仅需这一个 long referrerClickTime = response.getReferrerClickTimestampSeconds(); long appInstallTime = response.getInstallBeginTimestampSeconds(); boolean instantExperienceLaunched = response.getGooglePlayInstantParam(); Step2. 解析 referrerUrl referrerUrl 格式说明 格式（以下使用的是同一个例子）：\n原始格式 decode后的格式 1 utm_source%3Dutm_source_xxx%26utm_campaign%3Dutm_campaign_xxx%26utm_medium%3Dutm_medium_xxx%26utm_content%3D%7B%22source%22%3A%20%7B%22data%22%3A%20%223154158d7cfc829685fab52df9b47ba67b89947743514445d11ad23788bb6467fcf3775aa3c7e87e47db0bc38a6ddd4a0cd49b0100bc036ec10b1082714416132495ac4cc09953805ab282865f2d2620a0914496188f15c649424752fa8a6edd78b6c85f2dc1c1de175c29a3efaf47b14afda86826fe1adbfe170ed1759186cbee98944c539641f55e0f42937ae4c1a6f84d4b9335087306d9af8c3d7379ad56bcfe1e021b93da20595f3ba14500c3056508fc154dac3175db2f5f45756afc914f9d910cd867e23b1d430158690dbc53b9aa098bbb056f8152502dcdb64d6ec96eccd908895f34262ce5c5068fb64cdb4595d6eb44553acc1bd56b40789192de7cf78f0c951a0aab2ede8a9eae23b60f95e26ca14c9c84076ab73927c88bf5d496c5cf4fe642d5e550add78fa84796383cb1c71f062a39f5297fb8e4a4717d13f2d7a3c738d37303b5080bdcb08a%22%2C%20%22nonce%22%3A%20%22ee8501a143b5d3950cf820b1ee1c4f9f%22%7D%7D 1 utm_source=utm_source_xxx\u0026amp;utm_campaign=utm_campaign_xxx\u0026amp;utm_medium=utm_medium_xxx\u0026amp;utm_content={\u0026#34;source\u0026#34;: {\u0026#34;data\u0026#34;: \u0026#34;3154158d7cfc829685fab52df9b47ba67b89947743514445d11ad23788bb6467fcf3775aa3c7e87e47db0bc38a6ddd4a0cd49b0100bc036ec10b1082714416132495ac4cc09953805ab282865f2d2620a0914496188f15c649424752fa8a6edd78b6c85f2dc1c1de175c29a3efaf47b14afda86826fe1adbfe170ed1759186cbee98944c539641f55e0f42937ae4c1a6f84d4b9335087306d9af8c3d7379ad56bcfe1e021b93da20595f3ba14500c3056508fc154dac3175db2f5f45756afc914f9d910cd867e23b1d430158690dbc53b9aa098bbb056f8152502dcdb64d6ec96eccd908895f34262ce5c5068fb64cdb4595d6eb44553acc1bd56b40789192de7cf78f0c951a0aab2ede8a9eae23b60f95e26ca14c9c84076ab73927c88bf5d496c5cf4fe642d5e550add78fa84796383cb1c71f062a39f5297fb8e4a4717d13f2d7a3c738d37303b5080bdcb08a\u0026#34;, \u0026#34;nonce\u0026#34;: \u0026#34;ee8501a143b5d3950cf820b1ee1c4f9f\u0026#34;}} 结构（重点是处理utm_content）：\n/ 说明 是否Firebase已自动统计 例子 utm_source 指流量来源；\n字符串格式； 是；\n体现在BigQuery的traffic_source.source (direct)\napps.facebook.com\ngoogle-play utm_medium 同上 是；\n体现在BigQuery的traffic_source.medium (none)\norganic utm_campaign 同上 / / utm_content 一般主要用于解析来自Facebook Ads的广告；\njson字符串格式； 否；\n因此重点是这里 详见下方；\nFacebook Ads需进一步解密； utm_content 格式说明 参考来自 Facebook 官方文档：Understand Facebook App Ads Referral URLs\n原始格式 decode后的格式 解密并decode最核心的data后的格式 1 %7B%22source%22%3A%20%7B%22data%22%3A%20%223154158d7cfc829685fab52df9b47ba67b89947743514445d11ad23788bb6467fcf3775aa3c7e87e47db0bc38a6ddd4a0cd49b0100bc036ec10b1082714416132495ac4cc09953805ab282865f2d2620a0914496188f15c649424752fa8a6edd78b6c85f2dc1c1de175c29a3efaf47b14afda86826fe1adbfe170ed1759186cbee98944c539641f55e0f42937ae4c1a6f84d4b9335087306d9af8c3d7379ad56bcfe1e021b93da20595f3ba14500c3056508fc154dac3175db2f5f45756afc914f9d910cd867e23b1d430158690dbc53b9aa098bbb056f8152502dcdb64d6ec96eccd908895f34262ce5c5068fb64cdb4595d6eb44553acc1bd56b40789192de7cf78f0c951a0aab2ede8a9eae23b60f95e26ca14c9c84076ab73927c88bf5d496c5cf4fe642d5e550add78fa84796383cb1c71f062a39f5297fb8e4a4717d13f2d7a3c738d37303b5080bdcb08a%22%2C%20%22nonce%22%3A%20%22ee8501a143b5d3950cf820b1ee1c4f9f%22%7D%7D 1 {\u0026#34;source\u0026#34;: {\u0026#34;data\u0026#34;: \u0026#34;3154158d7cfc829685fab52df9b47ba67b89947743514445d11ad23788bb6467fcf3775aa3c7e87e47db0bc38a6ddd4a0cd49b0100bc036ec10b1082714416132495ac4cc09953805ab282865f2d2620a0914496188f15c649424752fa8a6edd78b6c85f2dc1c1de175c29a3efaf47b14afda86826fe1adbfe170ed1759186cbee98944c539641f55e0f42937ae4c1a6f84d4b9335087306d9af8c3d7379ad56bcfe1e021b93da20595f3ba14500c3056508fc154dac3175db2f5f45756afc914f9d910cd867e23b1d430158690dbc53b9aa098bbb056f8152502dcdb64d6ec96eccd908895f34262ce5c5068fb64cdb4595d6eb44553acc1bd56b40789192de7cf78f0c951a0aab2ede8a9eae23b60f95e26ca14c9c84076ab73927c88bf5d496c5cf4fe642d5e550add78fa84796383cb1c71f062a39f5297fb8e4a4717d13f2d7a3c738d37303b5080bdcb08a\u0026#34;, \u0026#34;nonce\u0026#34;: \u0026#34;ee8501a143b5d3950cf820b1ee1c4f9f\u0026#34;}} 1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;ad_id\u0026#34;:\u0026#34;{ad-id}\u0026#34;, \u0026#34;adgroup_id\u0026#34;:\u0026#34;{ad-group-id}\u0026#34;, \u0026#34;adgroup_name\u0026#34;:\u0026#34;{ad-group-name}\u0026#34;, \u0026#34;campaign_id\u0026#34;:\u0026#34;{campaign-id}\u0026#34;, \u0026#34;campaign_name\u0026#34;:\u0026#34;{campaign-name}\u0026#34;, \u0026#34;campaign_group_id\u0026#34;:\u0026#34;23851271281990526\u0026#34;, // 目标就是获取这个 \u0026#34;campaign_group_name\u0026#34;:\u0026#34;{campaign-group-name}\u0026#34;, \u0026#34;account_id\u0026#34;:\u0026#34;act_484103070416836\u0026#34;, \u0026#34;ad_objective_name\u0026#34;:\u0026#34;APP_INSTALLS\u0026#34; } 解析方法 先从 referrerUrl 中获取 utm_content；\n进行下一步之前，记得先 decode utm_content； 再解密 utm_content（最核心的一步）：\n官方方法：Example Decryption with PHP\n具体方法如下： 加密方式：AES256-GCM； 解密对象/密文：utm_content -\u0026gt; source -\u0026gt; data； 解密共需以下3个信息： Facebook Decryption Key：即密钥，来自Facebook开发者后台； data：即解密对象/密文。 nonce：随机数，无实际意义，解密需要；\n重要说明：data 中包含了 tag，因此处理时需要先忽略/截断。其中，关于 tag：\n对应上述例子：7d13f2d7a3c738d37303b5080bdcb08a； 位置：后缀； 长度：固定长度的32个16进制字符，即16个字节； https://pycryptodome.readthedocs.io/en/latest/src/cipher/aes.html\nhttps://developers.facebook.com/docs/app-ads/install-referrer/\n最后，使用以上信息，解密；\n其中，解密后的明文见 utm_content 格式说明 中的 解密并decode最核心的data后的格式； Step3. 处理解析结果 先获取 campaign_group_id：解密后的明文 -\u0026gt; campaign_group_id； 设置用户属性 campaign_id： 触发场景：新用户首次启动时触发，且仅触发一次（越早越好）； 方法：Set user properties 1 2 3 4 5 // 正常获取时 mFirebaseAnalytics.setUserProperty(\u0026#34;campaign_id\u0026#34;, campaign_group_id); // 异常时（无法获取或解析） mFirebaseAnalytics.setUserProperty(\u0026#34;campaign_id\u0026#34;, \u0026#34;unknown\u0026#34;); 测试方法 使用本文中的 referrerUrl 格式说明 中的例子即可；\n附 Firebase User Property 配额限制 见 https://support.google.com/firebase/answer/9237506?hl=en\n个数：\u0026lt;= 25； 命名长度：\u0026lt;= 24个字符； 取值长度：\u0026lt;= 36个字符； referrerUrl 格式参考 见 Adjust Placeholders for Partners\n1 utm_source%3Dmy.apps.com%26utm_campaign%3Dmy_campaign%26utm_content%3D%7B%22key1%22%3A0%2C%22key2%22%3A1623237220%7D GA4 Scopes [GA4] Scopes of traffic-source dimensions\n","description":"手动解密 Facebook Campaign.","id":36,"section":"posts","tags":["Play Install Referrer API"],"title":"使用 Play Install Referrer API 解密 Facebook Campaign","uri":"https://mollywangup.com/posts/decrypt-facebook-campaigns-with-play-install-referrer-api/"},{"content":"本文旨在手动解析一手的 Referrer 信息，并设置为 Firebase 用户属性。如果已经接了 MMP，可直接略过。（🤝 感兴趣也可了解下）\n实现方法： 工具：Play Install Referrer API； 体现：Firebase 的用户属性campaign_id； 局限性： 仅支持安卓系统； 仅支持 Facebook Ads； 方法概述 共三步：\nStep1. 获取 referrerUrl 先接 Play Install Referrer 客户端库； 再通过客户端库的方法获取原始的 referrerUrl； Step2. 解析 referrerUrl（核心） 先从referrerUrl中获取utm_content； 再解密utm_content。方法见官方的 Understand Facebook App Ads Referral URLs，需要用到 Facebook Decryption Key； Step3. 处理解析结果 先从解密后的utm_content中获取campaign_group_id； 再将campaign_group_id设置为用户属性campaign_id； 具体实现 Step1. 获取 referrerUrl 先接 Play Install Referrer 客户端库：\n官方文档：Play Install Referrer Library 他人做法参考：How to Use Google Play Install Referrer API in Android? 再获取原始的 referrerUrl：\n官方方法：Getting the install referrer 1 2 3 4 5 ReferrerDetails response = referrerClient.getInstallReferrer(); String referrerUrl = response.getInstallReferrer(); // 就是这个东西，且仅需这一个 long referrerClickTime = response.getReferrerClickTimestampSeconds(); long appInstallTime = response.getInstallBeginTimestampSeconds(); boolean instantExperienceLaunched = response.getGooglePlayInstantParam(); Step2. 解析 referrerUrl referrerUrl 格式说明 格式（以下使用的是同一个例子）：\n原始格式 decode后的格式 1 utm_source%3Dutm_source_xxx%26utm_campaign%3Dutm_campaign_xxx%26utm_medium%3Dutm_medium_xxx%26utm_content%3D%7B%22source%22%3A%20%7B%22data%22%3A%20%223154158d7cfc829685fab52df9b47ba67b89947743514445d11ad23788bb6467fcf3775aa3c7e87e47db0bc38a6ddd4a0cd49b0100bc036ec10b1082714416132495ac4cc09953805ab282865f2d2620a0914496188f15c649424752fa8a6edd78b6c85f2dc1c1de175c29a3efaf47b14afda86826fe1adbfe170ed1759186cbee98944c539641f55e0f42937ae4c1a6f84d4b9335087306d9af8c3d7379ad56bcfe1e021b93da20595f3ba14500c3056508fc154dac3175db2f5f45756afc914f9d910cd867e23b1d430158690dbc53b9aa098bbb056f8152502dcdb64d6ec96eccd908895f34262ce5c5068fb64cdb4595d6eb44553acc1bd56b40789192de7cf78f0c951a0aab2ede8a9eae23b60f95e26ca14c9c84076ab73927c88bf5d496c5cf4fe642d5e550add78fa84796383cb1c71f062a39f5297fb8e4a4717d13f2d7a3c738d37303b5080bdcb08a%22%2C%20%22nonce%22%3A%20%22ee8501a143b5d3950cf820b1ee1c4f9f%22%7D%7D 1 utm_source=utm_source_xxx\u0026amp;utm_campaign=utm_campaign_xxx\u0026amp;utm_medium=utm_medium_xxx\u0026amp;utm_content={\u0026#34;source\u0026#34;: {\u0026#34;data\u0026#34;: \u0026#34;3154158d7cfc829685fab52df9b47ba67b89947743514445d11ad23788bb6467fcf3775aa3c7e87e47db0bc38a6ddd4a0cd49b0100bc036ec10b1082714416132495ac4cc09953805ab282865f2d2620a0914496188f15c649424752fa8a6edd78b6c85f2dc1c1de175c29a3efaf47b14afda86826fe1adbfe170ed1759186cbee98944c539641f55e0f42937ae4c1a6f84d4b9335087306d9af8c3d7379ad56bcfe1e021b93da20595f3ba14500c3056508fc154dac3175db2f5f45756afc914f9d910cd867e23b1d430158690dbc53b9aa098bbb056f8152502dcdb64d6ec96eccd908895f34262ce5c5068fb64cdb4595d6eb44553acc1bd56b40789192de7cf78f0c951a0aab2ede8a9eae23b60f95e26ca14c9c84076ab73927c88bf5d496c5cf4fe642d5e550add78fa84796383cb1c71f062a39f5297fb8e4a4717d13f2d7a3c738d37303b5080bdcb08a\u0026#34;, \u0026#34;nonce\u0026#34;: \u0026#34;ee8501a143b5d3950cf820b1ee1c4f9f\u0026#34;}} 结构（重点是处理utm_content）：\n/ 说明 是否Firebase已自动统计 例子 utm_source 指流量来源；\n字符串格式； 是；\n体现在BigQuery的traffic_source.source (direct)\napps.facebook.com\ngoogle-play utm_medium 同上 是；\n体现在BigQuery的traffic_source.medium (none)\norganic utm_campaign 同上 / / utm_content 一般主要用于解析来自Facebook Ads的广告；\njson字符串格式； 否；\n因此重点是这里 详见下方；\nFacebook Ads需进一步解密； utm_content 格式说明 参考来自 Facebook 官方文档：Understand Facebook App Ads Referral URLs\n原始格式 decode后的格式 解密并decode最核心的data后的格式 1 %7B%22source%22%3A%20%7B%22data%22%3A%20%223154158d7cfc829685fab52df9b47ba67b89947743514445d11ad23788bb6467fcf3775aa3c7e87e47db0bc38a6ddd4a0cd49b0100bc036ec10b1082714416132495ac4cc09953805ab282865f2d2620a0914496188f15c649424752fa8a6edd78b6c85f2dc1c1de175c29a3efaf47b14afda86826fe1adbfe170ed1759186cbee98944c539641f55e0f42937ae4c1a6f84d4b9335087306d9af8c3d7379ad56bcfe1e021b93da20595f3ba14500c3056508fc154dac3175db2f5f45756afc914f9d910cd867e23b1d430158690dbc53b9aa098bbb056f8152502dcdb64d6ec96eccd908895f34262ce5c5068fb64cdb4595d6eb44553acc1bd56b40789192de7cf78f0c951a0aab2ede8a9eae23b60f95e26ca14c9c84076ab73927c88bf5d496c5cf4fe642d5e550add78fa84796383cb1c71f062a39f5297fb8e4a4717d13f2d7a3c738d37303b5080bdcb08a%22%2C%20%22nonce%22%3A%20%22ee8501a143b5d3950cf820b1ee1c4f9f%22%7D%7D 1 {\u0026#34;source\u0026#34;: {\u0026#34;data\u0026#34;: \u0026#34;3154158d7cfc829685fab52df9b47ba67b89947743514445d11ad23788bb6467fcf3775aa3c7e87e47db0bc38a6ddd4a0cd49b0100bc036ec10b1082714416132495ac4cc09953805ab282865f2d2620a0914496188f15c649424752fa8a6edd78b6c85f2dc1c1de175c29a3efaf47b14afda86826fe1adbfe170ed1759186cbee98944c539641f55e0f42937ae4c1a6f84d4b9335087306d9af8c3d7379ad56bcfe1e021b93da20595f3ba14500c3056508fc154dac3175db2f5f45756afc914f9d910cd867e23b1d430158690dbc53b9aa098bbb056f8152502dcdb64d6ec96eccd908895f34262ce5c5068fb64cdb4595d6eb44553acc1bd56b40789192de7cf78f0c951a0aab2ede8a9eae23b60f95e26ca14c9c84076ab73927c88bf5d496c5cf4fe642d5e550add78fa84796383cb1c71f062a39f5297fb8e4a4717d13f2d7a3c738d37303b5080bdcb08a\u0026#34;, \u0026#34;nonce\u0026#34;: \u0026#34;ee8501a143b5d3950cf820b1ee1c4f9f\u0026#34;}} 1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;ad_id\u0026#34;:\u0026#34;{ad-id}\u0026#34;, \u0026#34;adgroup_id\u0026#34;:\u0026#34;{ad-group-id}\u0026#34;, \u0026#34;adgroup_name\u0026#34;:\u0026#34;{ad-group-name}\u0026#34;, \u0026#34;campaign_id\u0026#34;:\u0026#34;{campaign-id}\u0026#34;, \u0026#34;campaign_name\u0026#34;:\u0026#34;{campaign-name}\u0026#34;, \u0026#34;campaign_group_id\u0026#34;:\u0026#34;23851271281990526\u0026#34;, // 目标就是获取这个 \u0026#34;campaign_group_name\u0026#34;:\u0026#34;{campaign-group-name}\u0026#34;, \u0026#34;account_id\u0026#34;:\u0026#34;act_484103070416836\u0026#34;, \u0026#34;ad_objective_name\u0026#34;:\u0026#34;APP_INSTALLS\u0026#34; } 解析方法 先从 referrerUrl 中获取 utm_content；\n进行下一步之前，记得先 decode utm_content； 再解密 utm_content（最核心的一步）：\n官方方法：Example Decryption with PHP\n具体方法如下： 加密方式：AES256-GCM； 解密对象/密文：utm_content -\u0026gt; source -\u0026gt; data； 解密共需以下3个信息： Facebook Decryption Key：即密钥，来自Facebook开发者后台； data：即解密对象/密文。 nonce：随机数，无实际意义，解密需要；\n重要说明：data 中包含了 tag，因此处理时需要先忽略/截断。其中，关于 tag：\n对应上述例子：7d13f2d7a3c738d37303b5080bdcb08a； 位置：后缀； 长度：固定长度的32个16进制字符，即16个字节； https://pycryptodome.readthedocs.io/en/latest/src/cipher/aes.html\nhttps://developers.facebook.com/docs/app-ads/install-referrer/\n最后，使用以上信息，解密；\n其中，解密后的明文见 utm_content 格式说明 中的 解密并decode最核心的data后的格式； Step3. 处理解析结果 先获取 campaign_group_id：解密后的明文 -\u0026gt; campaign_group_id； 设置用户属性 campaign_id： 触发场景：新用户首次启动时触发，且仅触发一次（越早越好）； 方法：Set user properties 1 2 3 4 5 // 正常获取时 mFirebaseAnalytics.setUserProperty(\u0026#34;campaign_id\u0026#34;, campaign_group_id); // 异常时（无法获取或解析） mFirebaseAnalytics.setUserProperty(\u0026#34;campaign_id\u0026#34;, \u0026#34;unknown\u0026#34;); 测试方法 使用本文中的 referrerUrl 格式说明 中的例子即可；\n附 Firebase User Property 配额限制 见 https://support.google.com/firebase/answer/9237506?hl=en\n个数：\u0026lt;= 25； 命名长度：\u0026lt;= 24个字符； 取值长度：\u0026lt;= 36个字符； referrerUrl 格式参考 见 Adjust Placeholders for Partners\n1 utm_source%3Dmy.apps.com%26utm_campaign%3Dmy_campaign%26utm_content%3D%7B%22key1%22%3A0%2C%22key2%22%3A1623237220%7D GA4 Scopes [GA4] Scopes of traffic-source dimensions\n","description":"手动解密 Facebook Campaign.","id":37,"section":"zh","tags":["Play Install Referrer API"],"title":"使用 Play Install Referrer API 解密 Facebook Campaign","uri":"https://mollywangup.com/zh/posts/decrypt-facebook-campaigns-with-play-install-referrer-api/"},{"content":"本文适用于侧重广告变现的 Unity 游戏。\n涉及到隐私政策，👉 指路我的另外一篇文章 广告风控指南：隐私政策\nFirebase SDK 理解：Firebase 项目实际上只是一个启用了额外的 Firebase 特定配置和服务的 Google Cloud 项目；\n常用功能 事件统计和设置用户属性；（Log Events \u0026amp; setUserProperty） 统计bug/崩溃等，且支持自定义 key 细化发生场景；（Firebase Crashlytics） 云端配置控制；（Remote Config） 收集启动时长，监控网络请求等性能数据；（Performance） 接入多种登录方式如 Facebook/PlayGames 等；（Firebase Authentication） 官方文档 [Firebase] Google Analytics for Unity： Get started Log events Set user properties [Firebase] Firebase Crashlytics： Get started Add custom keys [Firebase] Remote Config： Get started with Firebase Remote Config [Firebase] Performance Monitoring： Get started with Performance Monitoring for Android [Firebase] Firebase Authentication： Get Started with Firebase Authentication in Unity Facebook Login Play Games Login 测试方法 测试 Crashlytics：Test your Crashlytics implementation 测试 Performance：Performance Monitoring troubleshooting and FAQ Facebook SDK 常用功能 事件统计功能（Log Events）：只要接了Facebook SDK，就等同于可实现在Facebook Ads上进行推广； 自动事件统计功能； 手动事件统计功能； 登录功能（Facebook Login）：可直接接入，也可通过其他集成服务如Firebase接； 分享功能（Sharing）； 深度链接（Deep Link）； 官方文档 [Facebook] ： Getting Started with the Facebook Unity SDK How to Log App Events [GitHub] Facebook SDK for Unity 测试方法 面向开发：\nEnabling Debug Logs 面向运营：\n方法一：App Ads Helper\nhttps://developers.facebook.com/tools/app-ads-helper/?id={replace_your_app_id} 方法二：Events Manager\nhttps://business.facebook.com/events_manager2/list/app/{replace_your_app_id}/overview 注意事项 创建 Facebook 开发者账号时，需要以下两个信息（由研发反馈）：\nGP 正式包的 key 的哈希值；\n👉 方法指路 GP 包签名管理（Release Key） 启动 Facebook SDK 的类名； MAX SDK 常用功能 作为广告聚合平台（Mediation）： 接入不同的广告格式（Ad Formats）：Rewarded/Interstitial 等； 接入多个广告源（Ad Networks）： 自有广告源：AppLovin； 非自有广告源：AdMob/Meta/Unity/Vungle 等几十个； 获取广告收入； 官方文档 [MAX]： Integrate MAX for Unity Ad Formats: Rewarded Interstitial Ad Networks： Meta Audience Network AdMob bidding AdMob waterfall Unity Ads Liftoff Monetize (原Vungle) Chartboost DT Exchange (原AdColony) Mintegral [MAX] Impression-Level User Revenue API 测试方法 使用 Mediation Debugger 也就是测试套件：\n官方网站：Displaying the Mediation Debugger\n1 2 3 4 MaxSdkCallbacks.OnSdkInitializedEvent += (MaxSdkBase.SdkConfiguration sdkConfiguration) =\u0026gt; { // Show Mediation Debugger MaxSdk.ShowMediationDebugger(); }; 线下PDF版：Mediation Debugger 使用说明 - v23.2\nAdjust SDK 常用功能 👉 指路我的另一篇文章 使用 Adjust 追踪事件和收入数据\n事件统计功能；（Log Events） 手动统计广告收入；（Ad Revenue） 手动统计内购收入；（Purchase） 手动统计订阅收入；（Subscription） 官方文档 [Adjust] ： Integrate Adjust SDK for Unity [GitHub] ： Track events： Track an event Add Event parameters Track ad revenue： Track AppLovin MAX ad revenue with Adjust SDK Ad revenue tracking Track IAP： Track revenue Revenue deduplication Subscription tracking 测试方法 @运营 配合测试\nIAP \u0026amp; Subscription（Unity） 常用功能 非订阅性质的内购； 订阅性质的内购； 官方文档 [Unity] Set up and integrating Unity IAP [Unity] ErrorCode InitializationFailureReason PurchaseFailureReason Helpshift SDK 常用功能 客服； FAQs； \u0026hellip; 官方文档 [Helpshift] Integrating Contact Us \u0026amp; In App Messaging\nAPT（Android Performance Tuner） 常用功能 监控游戏性能；\n官方文档 [Android] Overview of Android Performance Tuner (Unity)\nPlay Install Referrer API 注意：接了 MMP 就可以不用接这个了。 常用功能 获取用户来源，仅限安卓；（主要通过解析referrerUrl）\n👉 指路我的另一篇文章 使用 Play Install Referrer API 解密 Facebook Campaign\n官方文档 [Android] Play Install Referrer Library [Facebook] Understand Facebook App Ads Referral URLs ","description":"Firebase, Facebook, MAX, Adjust, Helpshift, APT","id":38,"section":"posts","tags":["Firebase","Facebook Ads","MAX","Adjust","IAP","Subscription","Helpshift","APT"],"title":"通用：上架 GP 常用 SDK/Service 集成需求","uri":"https://mollywangup.com/posts/sdk-or-service-integration-requirements-for-unity-games/"},{"content":"本文适用于侧重广告变现的 Unity 游戏。\n涉及到隐私政策，👉 指路我的另外一篇文章 广告风控指南：隐私政策\nFirebase SDK 理解：Firebase 项目实际上只是一个启用了额外的 Firebase 特定配置和服务的 Google Cloud 项目；\n常用功能 事件统计和设置用户属性；（Log Events \u0026amp; setUserProperty） 统计bug/崩溃等，且支持自定义 key 细化发生场景；（Firebase Crashlytics） 云端配置控制；（Remote Config） 收集启动时长，监控网络请求等性能数据；（Performance） 接入多种登录方式如 Facebook/PlayGames 等；（Firebase Authentication） 官方文档 [Firebase] Google Analytics for Unity： Get started Log events Set user properties [Firebase] Firebase Crashlytics： Get started Add custom keys [Firebase] Remote Config： Get started with Firebase Remote Config [Firebase] Performance Monitoring： Get started with Performance Monitoring for Android [Firebase] Firebase Authentication： Get Started with Firebase Authentication in Unity Facebook Login Play Games Login 测试方法 测试 Crashlytics：Test your Crashlytics implementation 测试 Performance：Performance Monitoring troubleshooting and FAQ Facebook SDK 常用功能 事件统计功能（Log Events）：只要接了Facebook SDK，就等同于可实现在Facebook Ads上进行推广； 自动事件统计功能； 手动事件统计功能； 登录功能（Facebook Login）：可直接接入，也可通过其他集成服务如Firebase接； 分享功能（Sharing）； 深度链接（Deep Link）； 官方文档 [Facebook] ： Getting Started with the Facebook Unity SDK How to Log App Events [GitHub] Facebook SDK for Unity 测试方法 面向开发：\nEnabling Debug Logs 面向运营：\n方法一：App Ads Helper\nhttps://developers.facebook.com/tools/app-ads-helper/?id={replace_your_app_id} 方法二：Events Manager\nhttps://business.facebook.com/events_manager2/list/app/{replace_your_app_id}/overview 注意事项 创建 Facebook 开发者账号时，需要以下两个信息（由研发反馈）：\nGP 正式包的 key 的哈希值；\n👉 方法指路 GP 包签名管理（Release Key） 启动 Facebook SDK 的类名； MAX SDK 常用功能 作为广告聚合平台（Mediation）： 接入不同的广告格式（Ad Formats）：Rewarded/Interstitial 等； 接入多个广告源（Ad Networks）： 自有广告源：AppLovin； 非自有广告源：AdMob/Meta/Unity/Vungle 等几十个； 获取广告收入； 官方文档 [MAX]： Integrate MAX for Unity Ad Formats: Rewarded Interstitial Ad Networks： Meta Audience Network AdMob bidding AdMob waterfall Unity Ads Liftoff Monetize (原Vungle) Chartboost DT Exchange (原AdColony) Mintegral [MAX] Impression-Level User Revenue API 测试方法 使用 Mediation Debugger 也就是测试套件：\n官方网站：Displaying the Mediation Debugger\n1 2 3 4 MaxSdkCallbacks.OnSdkInitializedEvent += (MaxSdkBase.SdkConfiguration sdkConfiguration) =\u0026gt; { // Show Mediation Debugger MaxSdk.ShowMediationDebugger(); }; 线下PDF版：Mediation Debugger 使用说明 - v23.2\nAdjust SDK 常用功能 👉 指路我的另一篇文章 使用 Adjust 追踪事件和收入数据\n事件统计功能；（Log Events） 手动统计广告收入；（Ad Revenue） 手动统计内购收入；（Purchase） 手动统计订阅收入；（Subscription） 官方文档 [Adjust] ： Integrate Adjust SDK for Unity [GitHub] ： Track events： Track an event Add Event parameters Track ad revenue： Track AppLovin MAX ad revenue with Adjust SDK Ad revenue tracking Track IAP： Track revenue Revenue deduplication Subscription tracking 测试方法 @运营 配合测试\nIAP \u0026amp; Subscription（Unity） 常用功能 非订阅性质的内购； 订阅性质的内购； 官方文档 [Unity] Set up and integrating Unity IAP [Unity] ErrorCode InitializationFailureReason PurchaseFailureReason Helpshift SDK 常用功能 客服； FAQs； \u0026hellip; 官方文档 [Helpshift] Integrating Contact Us \u0026amp; In App Messaging\nAPT（Android Performance Tuner） 常用功能 监控游戏性能；\n官方文档 [Android] Overview of Android Performance Tuner (Unity)\nPlay Install Referrer API 注意：接了 MMP 就可以不用接这个了。 常用功能 获取用户来源，仅限安卓；（主要通过解析referrerUrl）\n👉 指路我的另一篇文章 使用 Play Install Referrer API 解密 Facebook Campaign\n官方文档 [Android] Play Install Referrer Library [Facebook] Understand Facebook App Ads Referral URLs ","description":"Firebase, Facebook, MAX, Adjust, Helpshift, APT","id":39,"section":"zh","tags":["Firebase","Facebook Ads","MAX","Adjust","IAP","Subscription","Helpshift","APT"],"title":"通用：上架 GP 常用 SDK/Service 集成需求","uri":"https://mollywangup.com/zh/posts/sdk-or-service-integration-requirements-for-unity-games/"},{"content":"上架 GP 时，除了内测轨道，必须使用正式签名（Release Key）。\n创建方法 方法一：IDE直接生成；\n方法二：命令行生成；（推荐）\n1 keytool -genkey -v -keystore \u0026lt;RELEASE_KEY_PATH\u0026gt; -alias \u0026lt;RELEASE_KEY_ALIAS\u0026gt; -storepass \u0026lt;STOREPASS\u0026gt; -keypass \u0026lt;KEYPASS\u0026gt; -keyalg RSA -keysize 2048 -validity 36500 查看方法 1 2 # 需要输入key store的密码 keytool -v -list -keystore \u0026lt;RELEASE_KEY_PATH\u0026gt; 获取 Key 的哈希值 方法详见 Create a Release Key Hash\n1 keytool -exportcert -alias \u0026lt;RELEASE_KEY_ALIAS\u0026gt; -keystore \u0026lt;RELEASE_KEY_PATH\u0026gt; | openssl sha1 -binary | openssl base64 ","description":"GP 包正式签名（Release Key）的创建、查看哈希值。","id":40,"section":"posts","tags":["GP"],"title":"GP 包签名管理（Release Key）","uri":"https://mollywangup.com/posts/solution-for-gp-release-key-management/"},{"content":"上架 GP 时，除了内测轨道，必须使用正式签名（Release Key）。\n创建方法 方法一：IDE直接生成；\n方法二：命令行生成；（推荐）\n1 keytool -genkey -v -keystore \u0026lt;RELEASE_KEY_PATH\u0026gt; -alias \u0026lt;RELEASE_KEY_ALIAS\u0026gt; -storepass \u0026lt;STOREPASS\u0026gt; -keypass \u0026lt;KEYPASS\u0026gt; -keyalg RSA -keysize 2048 -validity 36500 查看方法 1 2 # 需要输入key store的密码 keytool -v -list -keystore \u0026lt;RELEASE_KEY_PATH\u0026gt; 获取 Key 的哈希值 方法详见 Create a Release Key Hash\n1 keytool -exportcert -alias \u0026lt;RELEASE_KEY_ALIAS\u0026gt; -keystore \u0026lt;RELEASE_KEY_PATH\u0026gt; | openssl sha1 -binary | openssl base64 ","description":"GP 包正式签名（Release Key）的创建、查看哈希值。","id":41,"section":"zh","tags":["GP"],"title":"GP 包签名管理（Release Key）","uri":"https://mollywangup.com/zh/posts/solution-for-gp-release-key-management/"},{"content":"本文旨在使用 Firebase SDK 统计事件、设置用户属性，并提供测试方法。\n统计事件 见 Log events\n1 2 3 4 5 6 7 8 9 10 11 12 13 Firebase.Analytics.FirebaseAnalytics.LogEvent( Firebase.Analytics.FirebaseAnalytics.EventSelectContent, new Firebase.Analytics.Parameter( Firebase.Analytics.FirebaseAnalytics.ParameterItemId, id), new Firebase.Analytics.Parameter( Firebase.Analytics.FirebaseAnalytics.ParameterItemName, \u0026#34;name\u0026#34;), new Firebase.Analytics.Parameter( Firebase.Analytics.FirebaseAnalytics.UserPropertySignUpMethod, \u0026#34;Google\u0026#34;), new Firebase.Analytics.Parameter( \u0026#34;favorite_food\u0026#34;, mFavoriteFood), new Firebase.Analytics.Parameter( \u0026#34;user_id\u0026#34;, mUserId) ); 设置用户属性 见 Set user properties\n1 Firebase.Analytics.FirebaseAnalytics.SetUserProperty(\u0026#34;favorite_food\u0026#34;, \u0026#34;ice cream\u0026#34;); 测试方法 无论哪种方法，都需要先打开测试机的调试模式，方法见 Enable debug mode\n1 adb shell setprop debug.firebase.analytics.app PACKAGE_NAME 方式一：ADB 在终端打印日志，见 View events in the log output\n1 2 3 adb shell setprop log.tag.FA VERBOSE adb shell setprop log.tag.FA-SVC VERBOSE adb logcat -v time -s FA FA-SVC ✍ 😱 emmm\u0026hellip; 怎么不算竞品调研神器呢。 方式二：DebugView 在 Firebase/GA 后台，打开 DebugView，如下图：\n","description":"追踪方法，测试方法（竞品调研神器）。","id":42,"section":"posts","tags":["Firebase"],"title":"使用 Firebase 统计事件\u0026设置用户属性","uri":"https://mollywangup.com/posts/tracking-logevent-and-setuserproperty-with-firebase-sdk/"},{"content":"本文旨在使用 Firebase SDK 统计事件、设置用户属性，并提供测试方法。\n统计事件 见 Log events\n1 2 3 4 5 6 7 8 9 10 11 12 13 Firebase.Analytics.FirebaseAnalytics.LogEvent( Firebase.Analytics.FirebaseAnalytics.EventSelectContent, new Firebase.Analytics.Parameter( Firebase.Analytics.FirebaseAnalytics.ParameterItemId, id), new Firebase.Analytics.Parameter( Firebase.Analytics.FirebaseAnalytics.ParameterItemName, \u0026#34;name\u0026#34;), new Firebase.Analytics.Parameter( Firebase.Analytics.FirebaseAnalytics.UserPropertySignUpMethod, \u0026#34;Google\u0026#34;), new Firebase.Analytics.Parameter( \u0026#34;favorite_food\u0026#34;, mFavoriteFood), new Firebase.Analytics.Parameter( \u0026#34;user_id\u0026#34;, mUserId) ); 设置用户属性 见 Set user properties\n1 Firebase.Analytics.FirebaseAnalytics.SetUserProperty(\u0026#34;favorite_food\u0026#34;, \u0026#34;ice cream\u0026#34;); 测试方法 无论哪种方法，都需要先打开测试机的调试模式，方法见 Enable debug mode\n1 adb shell setprop debug.firebase.analytics.app PACKAGE_NAME 方式一：ADB 在终端打印日志，见 View events in the log output\n1 2 3 adb shell setprop log.tag.FA VERBOSE adb shell setprop log.tag.FA-SVC VERBOSE adb logcat -v time -s FA FA-SVC ✍ 😱 emmm\u0026hellip; 怎么不算竞品调研神器呢。 方式二：DebugView 在 Firebase/GA 后台，打开 DebugView，如下图：\n","description":"追踪方法，测试方法（竞品调研神器）。","id":43,"section":"zh","tags":["Firebase"],"title":"使用 Firebase 统计事件\u0026设置用户属性","uri":"https://mollywangup.com/zh/posts/tracking-logevent-and-setuserproperty-with-firebase-sdk/"},{"content":"背景信息 三个目标 1. 提高用户标识的唯一性 首次打开时：强行匿名注册，并生成唯一标识user_id； 首次非匿名登录时：取该登录方式对应的唯一标识，并与user_id进行关联； 每次登录游戏时：指点击开始游戏按钮时，需确保有user_id信息； 2. 保存游戏进度 非匿名登录：将与之关联的游戏进度上传至服务端； 主要用途：清除全部数据、卸载重装、跨设备，非匿名登录后可直接下载游戏进度； 匿名登录：不用管； 3. 社交：分享、互赠礼物、查看排行榜等 不同登录方式的对比 Facebook 登录：强社交 + 跨设备系统 + 接入简单，最优先建议； Play Games 登录：游戏 + 弱社交 + 谷歌全家桶 + 仅限安卓系统； Google 登录：优先级最低，暂不考虑； 方式一：直接接入 接入 Facebook 登录 官方文档 [Facebook] Facebook SDK for Unity Reference [Facebook] Facebook Login Best Practices [Facebook] User Experience Design 流程概述 登入（未登录 -\u0026gt; 登录）：\n点击登录按钮 -\u0026gt; 处理登录流程 -\u0026gt;（可选）登录成功/失败的交互反馈 -\u0026gt; 同步按钮状态； 登出（登录 -\u0026gt; 未登录）：\n点击退出按钮 -\u0026gt; 处理退出流程 -\u0026gt;（可选）退出成功的交互反馈 -\u0026gt; 同步按钮状态； 测试方法 需要测试以下三种可能的情形：\n设备上未安装 Facebook，跳转至设备浏览器的 Facebook web 登录界面（m.facebook.com）； 设备上已安装 Facebook 但未登录，跳转至 Facebook app 登录界面； 设备上已安装 Facebook 且已登录，直接原地申请获取玩家权限； 接入 Play Games 登录 官方文档 [Android] Get started with the Google Play Games plugin for Unity [GitHub] Sign in 流程概述 设备无谷歌服务框架的，直接跳过，不作任何处理； 已创建 Play 游戏账号的，系统自动登录； 未创建 Play 游戏账号的，需要手动处理（ManuallyAuthenticate）： 可直接放弃集成； 可强制引导登录，引导玩家以当前谷歌账号创建 Play 游戏账号； ⚠️ 仅需登入，无登出入口（因为方法已被官方删除）； 测试方法 需要测试以下三种可能的情形：\n设备上无谷歌服务框架，无需测试； 设备上有谷歌服务框架，但未创建 Play 游戏账号，引导创建 Play 游戏账号； 未登录 Google 账号，未创建 Play 游戏账号； 已登录 Google 账号，未创建 Play 游戏账号； 设备上有谷歌服务框架，且已创建 Play 游戏账号，直接自动登录； 补充说明：创建和删除 Play 游戏账号，直接在设备层级操作； 方式二：间接接入 通过 Firebase Authentication 接入。\n关于 Firebase Authentication 支持的登录方式见 Firebase Authentication\n结论：支持第三方登录如 Facebook/Google/Play Games 等，也支持直接注册如邮件/电话/匿名； 收费标准：\n结论：月活5W以内免费，超过部分每个$0.0025-$0.0055； Firebase全产品线：Pricing plans Firebase Authenticate：No cost and Pay as you go 官方文档 [Firebase] Firebase Authentication in Unity： Get Started Anonymous Login Facebook Login Play Games Login Link Multiple Auth Providers to an Account [Facebook] Facebook SDK for Unity： Facebook Login Examples Facebook Login Permissions\n关于权限范围：\n默认可向玩家申请：email和public_profile； 如需核心的社交功能，则需要额外的权限：user_friends，具体申请路径是： Facebook开发者后台 -\u0026gt; App Review； [GitHub] Google Play Games plugin for Unity： Sign in Add Achievements and Leaderboards ","description":"可直接接入，可间接接入。常见登录方式有 Facebook/Google/Play Games.","id":44,"section":"posts","tags":["Firebase"],"title":"为 Unity 游戏接入各种登录方式","uri":"https://mollywangup.com/posts/implement-authentication-in-games/"},{"content":"背景信息 三个目标 1. 提高用户标识的唯一性 首次打开时：强行匿名注册，并生成唯一标识user_id； 首次非匿名登录时：取该登录方式对应的唯一标识，并与user_id进行关联； 每次登录游戏时：指点击开始游戏按钮时，需确保有user_id信息； 2. 保存游戏进度 非匿名登录：将与之关联的游戏进度上传至服务端； 主要用途：清除全部数据、卸载重装、跨设备，非匿名登录后可直接下载游戏进度； 匿名登录：不用管； 3. 社交：分享、互赠礼物、查看排行榜等 不同登录方式的对比 Facebook 登录：强社交 + 跨设备系统 + 接入简单，最优先建议； Play Games 登录：游戏 + 弱社交 + 谷歌全家桶 + 仅限安卓系统； Google 登录：优先级最低，暂不考虑； 方式一：直接接入 接入 Facebook 登录 官方文档 [Facebook] Facebook SDK for Unity Reference [Facebook] Facebook Login Best Practices [Facebook] User Experience Design 流程概述 登入（未登录 -\u0026gt; 登录）：\n点击登录按钮 -\u0026gt; 处理登录流程 -\u0026gt;（可选）登录成功/失败的交互反馈 -\u0026gt; 同步按钮状态； 登出（登录 -\u0026gt; 未登录）：\n点击退出按钮 -\u0026gt; 处理退出流程 -\u0026gt;（可选）退出成功的交互反馈 -\u0026gt; 同步按钮状态； 测试方法 需要测试以下三种可能的情形：\n设备上未安装 Facebook，跳转至设备浏览器的 Facebook web 登录界面（m.facebook.com）； 设备上已安装 Facebook 但未登录，跳转至 Facebook app 登录界面； 设备上已安装 Facebook 且已登录，直接原地申请获取玩家权限； 接入 Play Games 登录 官方文档 [Android] Get started with the Google Play Games plugin for Unity [GitHub] Sign in 流程概述 设备无谷歌服务框架的，直接跳过，不作任何处理； 已创建 Play 游戏账号的，系统自动登录； 未创建 Play 游戏账号的，需要手动处理（ManuallyAuthenticate）： 可直接放弃集成； 可强制引导登录，引导玩家以当前谷歌账号创建 Play 游戏账号； ⚠️ 仅需登入，无登出入口（因为方法已被官方删除）； 测试方法 需要测试以下三种可能的情形：\n设备上无谷歌服务框架，无需测试； 设备上有谷歌服务框架，但未创建 Play 游戏账号，引导创建 Play 游戏账号； 未登录 Google 账号，未创建 Play 游戏账号； 已登录 Google 账号，未创建 Play 游戏账号； 设备上有谷歌服务框架，且已创建 Play 游戏账号，直接自动登录； 补充说明：创建和删除 Play 游戏账号，直接在设备层级操作； 方式二：间接接入 通过 Firebase Authentication 接入。\n关于 Firebase Authentication 支持的登录方式见 Firebase Authentication\n结论：支持第三方登录如 Facebook/Google/Play Games 等，也支持直接注册如邮件/电话/匿名； 收费标准：\n结论：月活5W以内免费，超过部分每个$0.0025-$0.0055； Firebase全产品线：Pricing plans Firebase Authenticate：No cost and Pay as you go 官方文档 [Firebase] Firebase Authentication in Unity： Get Started Anonymous Login Facebook Login Play Games Login Link Multiple Auth Providers to an Account [Facebook] Facebook SDK for Unity： Facebook Login Examples Facebook Login Permissions\n关于权限范围：\n默认可向玩家申请：email和public_profile； 如需核心的社交功能，则需要额外的权限：user_friends，具体申请路径是： Facebook开发者后台 -\u0026gt; App Review； [GitHub] Google Play Games plugin for Unity： Sign in Add Achievements and Leaderboards ","description":"可直接接入，可间接接入。常见登录方式有 Facebook/Google/Play Games.","id":45,"section":"zh","tags":["Firebase"],"title":"为 Unity 游戏接入各种登录方式","uri":"https://mollywangup.com/zh/posts/implement-authentication-in-games/"},{"content":"背景信息 Unity IAP； 目标是对支付异常情况的捕捉及处理； 具体实现 异常列表完善 内置的异常如下： 初始化阶段：InitializationFailureReason（3个） 支付阶段：PurchaseFailureReason（8个） 新增的异常如下（初始化阶段之前）： NetworkUnavailable：初始化阶段的第一优先级判断，玩家本地无网络连接时； 因此，最终的异常列表如下（异常描述就省略了，🙊 当然不是因为表格太丑二删掉的）：\n类型 具体异常 处理方案 判断网络\n（初始化前） NetworkUnavailable 网络异常 InitializationFailureReason\n（3个） AppNotKnown 支付失败 NoProductsAvailable 支付失败 PurchasingUnavailable 支付失败 PurchaseFailureReason\n（8个） DuplicateTransaction / ExistingPurchasePending / PaymentDeclined / ProductUnavailable 支付失败 PurchasingUnavailable 支付失败 SignatureInvalid 支付失败 Unknown 支付失败 UserCancelled / 异常处理方案 按照捕捉到的具体异常进行分类处理，共如下三类：\n网络异常：需要交互； 支付失败：需要交互； 其他（取消/重复购买/仅iOS的特殊异常）：暂不处理； 附：IAP 官方流程 ","description":"内置异常共两种，初始化阶段异常和支付阶段异常。网络异常需要手动处理。","id":46,"section":"posts","tags":["IAP"],"title":"优化支付 (IAP) 时的异常处理","uri":"https://mollywangup.com/posts/exception-handling-during-iap-for-unity-games/"},{"content":"背景信息 Unity IAP； 目标是对支付异常情况的捕捉及处理； 具体实现 异常列表完善 内置的异常如下： 初始化阶段：InitializationFailureReason（3个） 支付阶段：PurchaseFailureReason（8个） 新增的异常如下（初始化阶段之前）： NetworkUnavailable：初始化阶段的第一优先级判断，玩家本地无网络连接时； 因此，最终的异常列表如下（异常描述就省略了，🙊 当然不是因为表格太丑二删掉的）：\n类型 具体异常 处理方案 判断网络\n（初始化前） NetworkUnavailable 网络异常 InitializationFailureReason\n（3个） AppNotKnown 支付失败 NoProductsAvailable 支付失败 PurchasingUnavailable 支付失败 PurchaseFailureReason\n（8个） DuplicateTransaction / ExistingPurchasePending / PaymentDeclined / ProductUnavailable 支付失败 PurchasingUnavailable 支付失败 SignatureInvalid 支付失败 Unknown 支付失败 UserCancelled / 异常处理方案 按照捕捉到的具体异常进行分类处理，共如下三类：\n网络异常：需要交互； 支付失败：需要交互； 其他（取消/重复购买/仅iOS的特殊异常）：暂不处理； 附：IAP 官方流程 ","description":"内置异常共两种，初始化阶段异常和支付阶段异常。网络异常需要手动处理。","id":47,"section":"zh","tags":["IAP"],"title":"优化支付 (IAP) 时的异常处理","uri":"https://mollywangup.com/zh/posts/exception-handling-during-iap-for-unity-games/"},{"content":"无效流量，也常称作无效活动，以下统一口径为无效流量。\n结论 减少误点击（划重点：各广告平台权重最高的数据指标是 CTR ）： 可通过使用测试广告单元 ID 及添加测试设备，来避免开发者的误点击； 可通过遵守广告格式植入指南，来避免用户的误点击； 可通过优化广告请求及展示逻辑，来进行频次控制； 使用最新的变现 SDK： 可避免因 SDK 自身 bug 引发的相关问题； 无效流量 定义见 Invalid traffic\n可理解为：广告点击表现异常时，会被AdMob（各个广告平台大同小异）判定为无效流量。且无效流量不会产生收益，已产生的收益也会被收回； 所有可能会虚增广告客户费用或发布商收入的点击或展示都属于无效流量。这其中包括蓄意制造的欺诈性流量，也包括误点击。\n被判定为无效流量的后果： 轻则限制广告填充，即在广告请求环节返回ERROR_CODE_NO_FILL；\nERROR_CODE_NO_FILL The ad request was successful, but no ad was returned due to lack of ad inventory. 重则封变现账户； 如何风控 建议做法一：使用测试广告 结论：添加测试设备就安全；\n是否使用测试广告单元ID 是否添加测试设备 安全性评估 建议程度 yes yes 最安全 强烈建议 no yes 100%安全 建议 yes no 不太安全 不建议 no no 不安全 禁止 建议做法二：遵守广告格式植入指南 原生广告（Native Advanced） 植入指南：Native ads policies \u0026amp; guidelines\n需手动添加广告标识（Ad Attribution），即下图中的黄色badge：\n广告背景必须不可点击：\n广告背景必须是不可点击的（即不含可供点击的“空白区域”）。如果您将图片要素用作广告背景，则该图片必须是不可点击的。\n插屏广告（Interstitial） 植入指南：Interstitial ad guidance\n插屏广告展示前后必须是不同的页面，即如 A页面 -\u0026gt; 插屏广告 -\u0026gt; B页面：\n当进行插屏广告的展示时，需要确保App暂停跑接下来的流程；\nhttps://developers.google.com/admob/android/interstitial#some_best_practices\nRemember to pause the action when displaying an interstitial ad.\nFor example, when you make the call to display an interstitial ad, be sure to pause any audio output being produced by your app.\n开屏广告（App Open） 植入指南：App open ad guidance\n合规做法：\n启动页 -\u0026gt; 开屏广告（展示在启动页动画上） -\u0026gt; 主界面\n违规做法：\n启动页 -\u0026gt; 主界面 -\u0026gt; 开屏广告（展示在主界面上） 启动页 -\u0026gt; 开屏广告（展示在空白/未知内容上） -\u0026gt; 主界面 建议做法三：基于 CTR 的优化 经验 CTR AdMob: 5%左右； Facebook Audience Network: 5%内是安全线，10%是会判违规； 优化启动规则 目标：降低广告请求的频次，同时提升用户体验；\n具体做法：\n设置固定的启动时长，如10s； 设置启动时间间隔，如10s； 优化开屏位置的广告展示 目标：降低误点击，使广告展示没那么突兀；\n具体做法：给用户3s至10s的缓冲时间；\n优化 App 内页面间切换的动画 目标：页面切换丝滑，广告载入载出也丝滑；\n具体做法：\n设置页面间的左滑/右滑规则； 适配 RTL； 完整且准确的跟踪广告活动 目标：对于用户在应用中完整的广告活动，做到有较高程度的把控；\n具体做法：在广告加载、广告展示、广告点击事件中，收集点击的唯一标识ad_response_id参数；\n全屏广告格式阅后即焚 目标：降低误点击，不重复的无效展示全屏广告；\n具体做法：\n展示全屏广告后 -\u0026gt; 用户立即切到后台 -\u0026gt; 再次热启动回到前台 -\u0026gt; 该全屏广告不应该还在； 当用户回到前台后，按照手动关闭全屏广告的流程，展示相应流程的下一步的页面； 建议做法四：使用最新的变现 SDK 详见各个 SDK 文档的 release notes.\n参考别人的经验 来自呼伟：Admob账户“无效流量”被限制，账户解封经历 来自 AdMob 官方案例分享：AdMob 开发者成功解除无效流量限制的亲身案例分享 ","description":"使用测试广告，遵守广告格式植入指南，基于 CTR 的优化，使用最新的变现 SDK.","id":48,"section":"posts","tags":["Invalid activity","Monetization","AdMob"],"title":"广告风控指南：无效流量","uri":"https://mollywangup.com/posts/solution-for-invalid-activity-policy/"},{"content":"无效流量，也常称作无效活动，以下统一口径为无效流量。\n结论 减少误点击（划重点：各广告平台权重最高的数据指标是 CTR ）： 可通过使用测试广告单元 ID 及添加测试设备，来避免开发者的误点击； 可通过遵守广告格式植入指南，来避免用户的误点击； 可通过优化广告请求及展示逻辑，来进行频次控制； 使用最新的变现 SDK： 可避免因 SDK 自身 bug 引发的相关问题； 无效流量 定义见 Invalid traffic\n可理解为：广告点击表现异常时，会被AdMob（各个广告平台大同小异）判定为无效流量。且无效流量不会产生收益，已产生的收益也会被收回； 所有可能会虚增广告客户费用或发布商收入的点击或展示都属于无效流量。这其中包括蓄意制造的欺诈性流量，也包括误点击。\n被判定为无效流量的后果： 轻则限制广告填充，即在广告请求环节返回ERROR_CODE_NO_FILL；\nERROR_CODE_NO_FILL The ad request was successful, but no ad was returned due to lack of ad inventory. 重则封变现账户； 如何风控 建议做法一：使用测试广告 结论：添加测试设备就安全；\n是否使用测试广告单元ID 是否添加测试设备 安全性评估 建议程度 yes yes 最安全 强烈建议 no yes 100%安全 建议 yes no 不太安全 不建议 no no 不安全 禁止 建议做法二：遵守广告格式植入指南 原生广告（Native Advanced） 植入指南：Native ads policies \u0026amp; guidelines\n需手动添加广告标识（Ad Attribution），即下图中的黄色badge：\n广告背景必须不可点击：\n广告背景必须是不可点击的（即不含可供点击的“空白区域”）。如果您将图片要素用作广告背景，则该图片必须是不可点击的。\n插屏广告（Interstitial） 植入指南：Interstitial ad guidance\n插屏广告展示前后必须是不同的页面，即如 A页面 -\u0026gt; 插屏广告 -\u0026gt; B页面：\n当进行插屏广告的展示时，需要确保App暂停跑接下来的流程；\nhttps://developers.google.com/admob/android/interstitial#some_best_practices\nRemember to pause the action when displaying an interstitial ad.\nFor example, when you make the call to display an interstitial ad, be sure to pause any audio output being produced by your app.\n开屏广告（App Open） 植入指南：App open ad guidance\n合规做法：\n启动页 -\u0026gt; 开屏广告（展示在启动页动画上） -\u0026gt; 主界面\n违规做法：\n启动页 -\u0026gt; 主界面 -\u0026gt; 开屏广告（展示在主界面上） 启动页 -\u0026gt; 开屏广告（展示在空白/未知内容上） -\u0026gt; 主界面 建议做法三：基于 CTR 的优化 经验 CTR AdMob: 5%左右； Facebook Audience Network: 5%内是安全线，10%是会判违规； 优化启动规则 目标：降低广告请求的频次，同时提升用户体验；\n具体做法：\n设置固定的启动时长，如10s； 设置启动时间间隔，如10s； 优化开屏位置的广告展示 目标：降低误点击，使广告展示没那么突兀；\n具体做法：给用户3s至10s的缓冲时间；\n优化 App 内页面间切换的动画 目标：页面切换丝滑，广告载入载出也丝滑；\n具体做法：\n设置页面间的左滑/右滑规则； 适配 RTL； 完整且准确的跟踪广告活动 目标：对于用户在应用中完整的广告活动，做到有较高程度的把控；\n具体做法：在广告加载、广告展示、广告点击事件中，收集点击的唯一标识ad_response_id参数；\n全屏广告格式阅后即焚 目标：降低误点击，不重复的无效展示全屏广告；\n具体做法：\n展示全屏广告后 -\u0026gt; 用户立即切到后台 -\u0026gt; 再次热启动回到前台 -\u0026gt; 该全屏广告不应该还在； 当用户回到前台后，按照手动关闭全屏广告的流程，展示相应流程的下一步的页面； 建议做法四：使用最新的变现 SDK 详见各个 SDK 文档的 release notes.\n参考别人的经验 来自呼伟：Admob账户“无效流量”被限制，账户解封经历 来自 AdMob 官方案例分享：AdMob 开发者成功解除无效流量限制的亲身案例分享 ","description":"使用测试广告，遵守广告格式植入指南，基于 CTR 的优化，使用最新的变现 SDK.","id":49,"section":"zh","tags":["Invalid activity","Monetization","AdMob"],"title":"广告风控指南：无效流量","uri":"https://mollywangup.com/zh/posts/solution-for-invalid-activity-policy/"},{"content":"背景信息 移动应用/游戏出海业务（不考虑Web） 广告变现角度（开发者角度） AdMob 作为聚合平台 GP 包 结论 隐私政策的核心思想：\n可以概括为：约束开发者利用隐私数据进行相关盈利的行为，更具体一点指收集设备信息标识用户，用以对不同用户进行差异化的广告展示，即展示个性化广告。\n因此，遵守隐私政策的核心是：\n政策允许才能收集设备标识信息； 注意：用户仍有权在设备层级进行控制，使得开发者收集到的是一串零； 政策不允许需要显示声明未收集设备标识信息； 💡 保护隐私和向用户展示非个性化广告是不冲突的，因为此时用户是匿名的； 如何确定该遵守哪些隐私政策：\n如果受众包含儿童，则必须遵守《儿童在线隐私保护法》(COPPA)； 如果受众包含美国加州，则必须遵守《加利福尼亚消费者隐私法》(CCPA)； 如果受众包含欧盟、英国，则必须遵守《欧盟通用数据保护条例》(GDPR)； 如果受众包含巴西，则必须遵守《巴西通用数据保护法》(LGPD)； ⚠️️ 是坑也是技巧：\n受众和年龄评级是两个东西，是允许年龄评级是全年龄段但受众是排除了儿童了的。 如何风控 总结起来：设置年龄tag、移除广告ID权限；\nGoogle长远规划 Privacy Sandbox技术\n一劳永逸的方法 Remove ADID权限\n亦可参考同行做法：https://jinyoung.dev/posts/android_ads_policy/\n1 2 \u0026lt;uses-permission android:name=\u0026#34;com.google.android.gms.permission.AD_ID\u0026#34; tools:node=\u0026#34;remove\u0026#34;/\u0026gt; 逐个SDK声明 AdMob SDK 说明：COPPA 和 GDPR 的tag二选一即可；\nChild-directed setting (COPPA)\nUsers under the age of consent (GDPR)\nRestricted Data Processing (CCPA)\n1 2 3 4 5 // COPPA .setTagForChildDirectedTreatment(RequestConfiguration.TAG_FOR_CHILD_DIRECTED_TREATMENT_TRUE) // GDPR .setTagForUnderAgeOfConsent(RequestConfiguration.TAG_FOR_UNDER_AGE_OF_CONSENT_TRUE) Facebook SDK Disable Collection of Advertiser IDs\n1 2 3 4 5 6 \u0026lt;application\u0026gt; ... \u0026lt;meta-data android:name=\u0026#34;com.facebook.sdk.AdvertiserIDCollectionEnabled\u0026#34; android:value=\u0026#34;false\u0026#34;/\u0026gt; ... \u0026lt;/application\u0026gt; Firebase SDK Disable Advertising ID collection\n1 \u0026lt;meta-data android:name=\u0026#34;google_analytics_adid_collection_enabled\u0026#34; android:value=\u0026#34;false\u0026#34; /\u0026gt; AppLovin SDK setIsAgeRestrictedUser (COPPA)\nsetHasUserConsent (GDPR)\nsetDoNotSell (CCPA)\n1 2 3 AppLovinPrivacySettings.setIsAgeRestrictedUser(true, context); AppLovinPrivacySettings.setHasUserConsent(true, context); AppLovinPrivacySettings.setDoNotSell(true, context); Unity Ads SDK GDPR\nCCPA\n1 2 3 4 5 6 7 MetaData gdprMetaData = new MetaData(this); gdprMetaData.set(\u0026#34;gdpr.consent\u0026#34;, true); gdprMetaData.commit(); MetaData ccpaMetaData = new MetaData(this); ccpaMetaData.set(\u0026#34;privacy.consent\u0026#34;, true); ccpaMetaData.commit(); Vungle SDK GDPR\nCCPA\n1 2 Vungle.updateConsentStatus(Vungle.Consent.OPTED_IN, \u0026#34;1.0.0\u0026#34;); Vungle.updateCCPAStatus(Vungle.Consent.OPTED_IN); 附：概念定义 常看常新 Keeping Google Play Safe with New Features and Programs\n隐私 隐私在不同政策（国家）法律/平台下的定义：\n\u0026ldquo;Personally Identifiable Information\u0026rdquo; (PII) Google Play Services AdMob Google Analytics for Firebase Firebase Crashlytics Facebook Unity Ads AppLovin 个性化广告 基于用户兴趣，来对用户进行个性化广告展示； 使用device identifiers、cookies，用于个性化广告； AdMob定义的：Personalized ads IAB定义的： 非个性化广告 (NPA) 基于当前的上下文信息，及粗略的地理位置估计，来对用户进行非个性化广告展示； 会使用device identifiers、cookies，但是不能用于个性化广告，仅可用于频次控制、反作弊等； AdMob定义的：Non-personalized ads (NPA) 谷歌儿童政策 https://support.google.com/googleplay/android-developer/answer/11043825?hl=en\nApps that target both children and older audiences must not transmit AAID, SIM serial, build serial, BSSID, MAC, SSID, IMEI and/or IMSI from children or users of unknown age.\n附：四大隐私政策 COPPA The Children’s Online Privacy Protection Act (COPPA)\n针对受众群体中包含儿童/未成年用户的App（也称为Family Policy）\nTag an ad request from an app for child-directed treatment Comply with Google Play’s Families Policy using AdMob Set a maximum ad content rating Complying with COPPA: Frequently Asked Questions GDPR EU user consent policy (GDPR)\n针对欧盟、英国、瑞士的用户\nTools to help publishers comply with the GDPR EU user consent policy Helping publishers and advertisers with consent IAB CMP list IAB Europe Transparency \u0026amp; Consent Framework Policies CCPA California Consumer Privacy Act (CCPA)\n针对美国加利福尼亚洲的用户\nHelping publishers comply with the California Consumer Privacy Act (CCPA)\nThe California Privacy Rights Act (CPRA) is a data privacy law that amends and expands upon the CCPA. The law takes effect on January 1, 2023. LGPD Lei Geral de Proteção de Dados (LGPD)\n针对巴西的用户\nHelping users comply with the Lei Geral de Proteção de Dados (LGPD)\n","description":"COPPA/CCPA/GDPR/LGPD","id":50,"section":"posts","tags":["Monetization","AdMob","GP"],"title":"广告风控指南：隐私政策","uri":"https://mollywangup.com/posts/solution-for-ad-privacy/"},{"content":"背景信息 移动应用/游戏出海业务（不考虑Web） 广告变现角度（开发者角度） AdMob 作为聚合平台 GP 包 结论 隐私政策的核心思想：\n可以概括为：约束开发者利用隐私数据进行相关盈利的行为，更具体一点指收集设备信息标识用户，用以对不同用户进行差异化的广告展示，即展示个性化广告。\n因此，遵守隐私政策的核心是：\n政策允许才能收集设备标识信息； 注意：用户仍有权在设备层级进行控制，使得开发者收集到的是一串零； 政策不允许需要显示声明未收集设备标识信息； 💡 保护隐私和向用户展示非个性化广告是不冲突的，因为此时用户是匿名的； 如何确定该遵守哪些隐私政策：\n如果受众包含儿童，则必须遵守《儿童在线隐私保护法》(COPPA)； 如果受众包含美国加州，则必须遵守《加利福尼亚消费者隐私法》(CCPA)； 如果受众包含欧盟、英国，则必须遵守《欧盟通用数据保护条例》(GDPR)； 如果受众包含巴西，则必须遵守《巴西通用数据保护法》(LGPD)； ⚠️️ 是坑也是技巧：\n受众和年龄评级是两个东西，是允许年龄评级是全年龄段但受众是排除了儿童了的。 如何风控 总结起来：设置年龄tag、移除广告ID权限；\nGoogle长远规划 Privacy Sandbox技术\n一劳永逸的方法 Remove ADID权限\n亦可参考同行做法：https://jinyoung.dev/posts/android_ads_policy/\n1 2 \u0026lt;uses-permission android:name=\u0026#34;com.google.android.gms.permission.AD_ID\u0026#34; tools:node=\u0026#34;remove\u0026#34;/\u0026gt; 逐个SDK声明 AdMob SDK 说明：COPPA 和 GDPR 的tag二选一即可；\nChild-directed setting (COPPA)\nUsers under the age of consent (GDPR)\nRestricted Data Processing (CCPA)\n1 2 3 4 5 // COPPA .setTagForChildDirectedTreatment(RequestConfiguration.TAG_FOR_CHILD_DIRECTED_TREATMENT_TRUE) // GDPR .setTagForUnderAgeOfConsent(RequestConfiguration.TAG_FOR_UNDER_AGE_OF_CONSENT_TRUE) Facebook SDK Disable Collection of Advertiser IDs\n1 2 3 4 5 6 \u0026lt;application\u0026gt; ... \u0026lt;meta-data android:name=\u0026#34;com.facebook.sdk.AdvertiserIDCollectionEnabled\u0026#34; android:value=\u0026#34;false\u0026#34;/\u0026gt; ... \u0026lt;/application\u0026gt; Firebase SDK Disable Advertising ID collection\n1 \u0026lt;meta-data android:name=\u0026#34;google_analytics_adid_collection_enabled\u0026#34; android:value=\u0026#34;false\u0026#34; /\u0026gt; AppLovin SDK setIsAgeRestrictedUser (COPPA)\nsetHasUserConsent (GDPR)\nsetDoNotSell (CCPA)\n1 2 3 AppLovinPrivacySettings.setIsAgeRestrictedUser(true, context); AppLovinPrivacySettings.setHasUserConsent(true, context); AppLovinPrivacySettings.setDoNotSell(true, context); Unity Ads SDK GDPR\nCCPA\n1 2 3 4 5 6 7 MetaData gdprMetaData = new MetaData(this); gdprMetaData.set(\u0026#34;gdpr.consent\u0026#34;, true); gdprMetaData.commit(); MetaData ccpaMetaData = new MetaData(this); ccpaMetaData.set(\u0026#34;privacy.consent\u0026#34;, true); ccpaMetaData.commit(); Vungle SDK GDPR\nCCPA\n1 2 Vungle.updateConsentStatus(Vungle.Consent.OPTED_IN, \u0026#34;1.0.0\u0026#34;); Vungle.updateCCPAStatus(Vungle.Consent.OPTED_IN); 附：概念定义 常看常新 Keeping Google Play Safe with New Features and Programs\n隐私 隐私在不同政策（国家）法律/平台下的定义：\n\u0026ldquo;Personally Identifiable Information\u0026rdquo; (PII) Google Play Services AdMob Google Analytics for Firebase Firebase Crashlytics Facebook Unity Ads AppLovin 个性化广告 基于用户兴趣，来对用户进行个性化广告展示； 使用device identifiers、cookies，用于个性化广告； AdMob定义的：Personalized ads IAB定义的： 非个性化广告 (NPA) 基于当前的上下文信息，及粗略的地理位置估计，来对用户进行非个性化广告展示； 会使用device identifiers、cookies，但是不能用于个性化广告，仅可用于频次控制、反作弊等； AdMob定义的：Non-personalized ads (NPA) 谷歌儿童政策 https://support.google.com/googleplay/android-developer/answer/11043825?hl=en\nApps that target both children and older audiences must not transmit AAID, SIM serial, build serial, BSSID, MAC, SSID, IMEI and/or IMSI from children or users of unknown age.\n附：四大隐私政策 COPPA The Children’s Online Privacy Protection Act (COPPA)\n针对受众群体中包含儿童/未成年用户的App（也称为Family Policy）\nTag an ad request from an app for child-directed treatment Comply with Google Play’s Families Policy using AdMob Set a maximum ad content rating Complying with COPPA: Frequently Asked Questions GDPR EU user consent policy (GDPR)\n针对欧盟、英国、瑞士的用户\nTools to help publishers comply with the GDPR EU user consent policy Helping publishers and advertisers with consent IAB CMP list IAB Europe Transparency \u0026amp; Consent Framework Policies CCPA California Consumer Privacy Act (CCPA)\n针对美国加利福尼亚洲的用户\nHelping publishers comply with the California Consumer Privacy Act (CCPA)\nThe California Privacy Rights Act (CPRA) is a data privacy law that amends and expands upon the CCPA. The law takes effect on January 1, 2023. LGPD Lei Geral de Proteção de Dados (LGPD)\n针对巴西的用户\nHelping users comply with the Lei Geral de Proteção de Dados (LGPD)\n","description":"COPPA/CCPA/GDPR/LGPD","id":51,"section":"zh","tags":["Monetization","AdMob","GP"],"title":"广告风控指南：隐私政策","uri":"https://mollywangup.com/zh/posts/solution-for-ad-privacy/"},{"content":"共包含三种主流的连接协议：IKEv2/OpenVPN/WireGuard.\n无论使用哪种连接协议，核心都是 在服务端生成配置 -\u0026gt; 在客户端导入配置；\n准备工作 一个服务器；（本文以 Ubuntu/Debian 为例） 一点点 Linux 知识； IKEv2 Server-side IPsec VPN Server Auto Setup Scripts\n（建议）先更新软件包和系统：\n1 sudo apt-get update \u0026amp;\u0026amp; sudo apt-get dist-upgrade 安装 IKEv2 VPN：（👉 密码纠结症指路 快速生成一个安全的随机密码）\n1 2 3 4 5 wget https://get.vpnsetup.net -O vpn.sh sudo VPN_IPSEC_PSK=\u0026#39;your_ipsec_pre_shared_key\u0026#39; \\ VPN_USER=\u0026#39;your_vpn_username\u0026#39; \\ VPN_PASSWORD=\u0026#39;your_vpn_password\u0026#39; \\ sh vpn.sh 获取客户端配置文件：\n1 2 3 sudo ikev2.sh --listclients sudo ikev2.sh --addclient [client name] sudo ikev2.sh --exportclient [client name] 例子：导出名称为 vpnclient 的客户端配置 导出 1 sudo ikev2.sh --exportclient vpnclient 结果如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ================================================ IKEv2 client \u0026#34;vpnclient\u0026#34; exported! VPN server address: xxx.xx.xx.xx Client configuration is available at: /path/vpnclient.p12 (for Windows \u0026amp; Linux) /path/vpnclient.sswan (for Android) /path/vpnclient.mobileconfig (for iOS \u0026amp; macOS) Next steps: Configure IKEv2 clients. See: https://vpnsetup.net/clients ================================================ Client-side 根据不同客户端类型，导出对应后缀的配置文件，然后傻瓜式操作即可。\n注意：一般是在系统层级的网络中配置。\nOpenVPN Server-side openvpn-install\n安装 OpenVPN VPN：\n1 wget https://git.io/vpn -O openvpn-install.sh \u0026amp;\u0026amp; bash openvpn-install.sh Client-side 根据不同客户端类型，下载对应的客户端应用程序，然后傻瓜式操作即可。\nWireGuard Server-side wireguard-install\n安装 WireGuard VPN：\n1 wget https://git.io/wireguard -O wireguard-install.sh \u0026amp;\u0026amp; bash wireguard-install.sh Client-side 根据不同客户端类型，下载对应的客户端应用程序，然后傻瓜式操作即可。\nmacOS 无法从 App Store 下载时的替代方案 由此下载 安装 CLI tool for WireGuard：\n1 brew install wireguard-tools 配置 wg0.conf 文件：\n1 2 cd /etc/wireguard vim wg0.conf ","description":"共包含三种主流的连接协议：IKEv2/OpenVPN/WireGuard.","id":52,"section":"posts","tags":["VPN"],"title":"搭建属于你自己的 VPN 服务器","uri":"https://mollywangup.com/posts/build-your-own-vpn-server/"},{"content":"共包含三种主流的连接协议：IKEv2/OpenVPN/WireGuard.\n无论使用哪种连接协议，核心都是 在服务端生成配置 -\u0026gt; 在客户端导入配置；\n准备工作 一个服务器；（本文以 Ubuntu/Debian 为例） 一点点 Linux 知识； IKEv2 Server-side IPsec VPN Server Auto Setup Scripts\n（建议）先更新软件包和系统：\n1 sudo apt-get update \u0026amp;\u0026amp; sudo apt-get dist-upgrade 安装 IKEv2 VPN：（👉 密码纠结症指路 快速生成一个安全的随机密码）\n1 2 3 4 5 wget https://get.vpnsetup.net -O vpn.sh sudo VPN_IPSEC_PSK=\u0026#39;your_ipsec_pre_shared_key\u0026#39; \\ VPN_USER=\u0026#39;your_vpn_username\u0026#39; \\ VPN_PASSWORD=\u0026#39;your_vpn_password\u0026#39; \\ sh vpn.sh 获取客户端配置文件：\n1 2 3 sudo ikev2.sh --listclients sudo ikev2.sh --addclient [client name] sudo ikev2.sh --exportclient [client name] 例子：导出名称为 vpnclient 的客户端配置 导出 1 sudo ikev2.sh --exportclient vpnclient 结果如下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ================================================ IKEv2 client \u0026#34;vpnclient\u0026#34; exported! VPN server address: xxx.xx.xx.xx Client configuration is available at: /path/vpnclient.p12 (for Windows \u0026amp; Linux) /path/vpnclient.sswan (for Android) /path/vpnclient.mobileconfig (for iOS \u0026amp; macOS) Next steps: Configure IKEv2 clients. See: https://vpnsetup.net/clients ================================================ Client-side 根据不同客户端类型，导出对应后缀的配置文件，然后傻瓜式操作即可。\n注意：一般是在系统层级的网络中配置。\nOpenVPN Server-side openvpn-install\n安装 OpenVPN VPN：\n1 wget https://git.io/vpn -O openvpn-install.sh \u0026amp;\u0026amp; bash openvpn-install.sh Client-side 根据不同客户端类型，下载对应的客户端应用程序，然后傻瓜式操作即可。\nWireGuard Server-side wireguard-install\n安装 WireGuard VPN：\n1 wget https://git.io/wireguard -O wireguard-install.sh \u0026amp;\u0026amp; bash wireguard-install.sh Client-side 根据不同客户端类型，下载对应的客户端应用程序，然后傻瓜式操作即可。\nmacOS 无法从 App Store 下载时的替代方案 由此下载 安装 CLI tool for WireGuard：\n1 brew install wireguard-tools 配置 wg0.conf 文件：\n1 2 cd /etc/wireguard vim wg0.conf ","description":"共包含三种主流的连接协议：IKEv2/OpenVPN/WireGuard.","id":53,"section":"zh","tags":["VPN"],"title":"搭建属于你自己的 VPN 服务器","uri":"https://mollywangup.com/zh/posts/build-your-own-vpn-server/"},{"content":"Step1. 安装 Crontab macOS 一般系统自带，可以直接下一步。\nLinux 1 2 3 4 5 6 7 8 # 安装 sudo yum install cronie # 启动服务 sudo service crond start # 开机自启 sudo chkconfig crond on Step2. 编写定时任务 1. 编辑 crontab 文件 1 crontab -e 2. 设置定时任务 示例任务：每天凌晨清除该路径下的日志文件；\n其中，前五个位置表示五个时间字段，依次是：分钟、小时、日期、月份、星期几；\n1 0 0 * * * sudo rm /path/*.log 3. 保存并关闭 ESC+:wq\n4. 查看任务列表 1 crontab -l ","description":"使用 Crontab 创建简单的定时任务，适用于 macOS/Linux.","id":54,"section":"posts","tags":["Crontab"],"title":"使用 Crontab 添加定时任务","uri":"https://mollywangup.com/posts/add-crontab-task-on-linux/"},{"content":"Step1. 安装 Crontab macOS 一般系统自带，可以直接下一步。\nLinux 1 2 3 4 5 6 7 8 # 安装 sudo yum install cronie # 启动服务 sudo service crond start # 开机自启 sudo chkconfig crond on Step2. 编写定时任务 1. 编辑 crontab 文件 1 crontab -e 2. 设置定时任务 示例任务：每天凌晨清除该路径下的日志文件；\n其中，前五个位置表示五个时间字段，依次是：分钟、小时、日期、月份、星期几；\n1 0 0 * * * sudo rm /path/*.log 3. 保存并关闭 ESC+:wq\n4. 查看任务列表 1 crontab -l ","description":"使用 Crontab 创建简单的定时任务，适用于 macOS/Linux.","id":55,"section":"zh","tags":["Crontab"],"title":"使用 Crontab 添加定时任务","uri":"https://mollywangup.com/zh/posts/add-crontab-task-on-linux/"},{"content":"问题描述 当打开自己的网站时，浏览器报错：ERR_TOO_MANY_REDIRECTS\n问题定位 这个报错通常是由于重定向死循环导致，如下图:\n解决思路 检查网站的重定向设置，无论是主动设置的还是被动设置的。\n思路一：排除 Cloudflare 设置 如果有接 Cloudflare, 可以尝试将 SSL/TLS encryption mode 修改为 Full (strict)\nCloudflare 官方参考文档：ERR_TOO_MANY_REDIRECTS\n","description":"自建的网站，当添加 Cloudflare 后，忽然报错 ERR_TOO_MANY_REDIRECTS.","id":56,"section":"posts","tags":["Cloudflare"],"title":"踩坑：ERR_TOO_MANY_REDIRECTS","uri":"https://mollywangup.com/posts/troubleshooting-err-too-many-redirects/"},{"content":"问题描述 当打开自己的网站时，浏览器报错：ERR_TOO_MANY_REDIRECTS\n问题定位 这个报错通常是由于重定向死循环导致，如下图:\n解决思路 检查网站的重定向设置，无论是主动设置的还是被动设置的。\n思路一：排除 Cloudflare 设置 如果有接 Cloudflare, 可以尝试将 SSL/TLS encryption mode 修改为 Full (strict)\nCloudflare 官方参考文档：ERR_TOO_MANY_REDIRECTS\n","description":"自建的网站，当添加 Cloudflare 后，忽然报错 ERR_TOO_MANY_REDIRECTS.","id":57,"section":"zh","tags":["Cloudflare"],"title":"踩坑：ERR_TOO_MANY_REDIRECTS","uri":"https://mollywangup.com/zh/posts/troubleshooting-err-too-many-redirects/"},{"content":"专业密码管理的工具有很多，比如 1Password/LastPass，以下仅仅是为了方便 快速生成一个安全的随机密码。\n使用 OpenSSL 使用以下命令行生成的密码形如：T1W+MDI0nf1d0XZyiJze1Q==\n1 openssl rand -base64 16 👇 未安装 OpenSSL 的看这里 1 2 3 4 5 # for macOS brew install openssl # for Debian sudo apt-get install openssl 使用 pwgen 使用以下命令行生成的密码形如：shohTh7zoYooRi9c\n1 pwgen -c -n -B -1 16 其中，常用参数如下：\n1 2 3 4 5 6 7 -c：指定生成的密码包含大小写字母。 -n：指定生成的密码包含数字。 -y：指定生成的密码包含符号，例如!@#$%^\u0026amp;*()_+-={}[]|:;\u0026#34;\u0026#39;\u0026lt;\u0026gt;,.?/等。 -B：指定生成的密码不能包含斜杠（/）字符。 -s：指定生成的密码只包含字符，没有数字或符号。 -1：指定生成一行密码，而不是多行密码。 \u0026lt;length\u0026gt;：指定生成密码的长度，默认为8。 👇 未安装 pwgen 的看这里 1 2 3 4 5 # for macOS brew install pwgen # for Debian sudo apt-get install pwgen ","description":"选择困难症患者的福音。使用的是 OpenSSL 和 pwgen.","id":58,"section":"posts","tags":[null],"title":"快速生成一个安全的随机密码","uri":"https://mollywangup.com/posts/generate-a-secure-password/"},{"content":"专业密码管理的工具有很多，比如 1Password/LastPass，以下仅仅是为了方便 快速生成一个安全的随机密码。\n使用 OpenSSL 使用以下命令行生成的密码形如：T1W+MDI0nf1d0XZyiJze1Q==\n1 openssl rand -base64 16 👇 未安装 OpenSSL 的看这里 1 2 3 4 5 # for macOS brew install openssl # for Debian sudo apt-get install openssl 使用 pwgen 使用以下命令行生成的密码形如：shohTh7zoYooRi9c\n1 pwgen -c -n -B -1 16 其中，常用参数如下：\n1 2 3 4 5 6 7 -c：指定生成的密码包含大小写字母。 -n：指定生成的密码包含数字。 -y：指定生成的密码包含符号，例如!@#$%^\u0026amp;*()_+-={}[]|:;\u0026#34;\u0026#39;\u0026lt;\u0026gt;,.?/等。 -B：指定生成的密码不能包含斜杠（/）字符。 -s：指定生成的密码只包含字符，没有数字或符号。 -1：指定生成一行密码，而不是多行密码。 \u0026lt;length\u0026gt;：指定生成密码的长度，默认为8。 👇 未安装 pwgen 的看这里 1 2 3 4 5 # for macOS brew install pwgen # for Debian sudo apt-get install pwgen ","description":"选择困难症患者的福音。使用的是 OpenSSL 和 pwgen.","id":59,"section":"zh","tags":[null],"title":"快速生成一个安全的随机密码","uri":"https://mollywangup.com/zh/posts/generate-a-secure-password/"},{"content":"✍ 本文作为学习笔记。\n安装及配置 安装 1 2 # macOS brew install mysql 首次登录 方式一：先登录后设置密码 1 mysql -u root 1 ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026lt;password\u0026gt;; 方式二：直接登录并设置密码 1 mysqladmin -u root -p password \u0026lt;password\u0026gt; 连接数据库 命令行方式 1 2 ssh \u0026lt;sshuser\u0026gt;@\u0026lt;sshhost\u0026gt; # optional mysql -h \u0026lt;host\u0026gt; -P \u0026lt;port\u0026gt; -u \u0026lt;username\u0026gt; -p URI 方式 1 mysql://\u0026lt;username\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/\u0026lt;db_name\u0026gt; 权限管理 以下以用户wangli为例。\n新增用户 1 CREATE USER \u0026#39;wangli\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;12345678\u0026#39;; 查看权限 1 2 SHOW GRANTS FOR root@localhost; SHOW GRANTS FOR admin; 修改权限 1 2 3 4 5 6 7 8 9 10 11 -- 授权所有权限 GRANT ALL PRIVILEGES ON *.* TO \u0026#39;wangli\u0026#39;@\u0026#39;%\u0026#39;; FLUSH PRIVILEGES; -- 移除所有权限 REVOKE ALL PRIVILEGES ON *.* FROM \u0026#39;wangli\u0026#39;@\u0026#39;%\u0026#39;; FLUSH PRIVILEGES; -- 授权指定数据库 GRANT ALL PRIVILEGES ON \u0026lt;db_name\u0026gt;.* TO \u0026#39;admin\u0026#39;@\u0026#39;%\u0026#39;; FLUSH PRIVILEGES; 数据库 创建数据库 1 CREATE DATABASE \u0026lt;db_name\u0026gt;; 删除数据库 1 DROP DATABASE \u0026lt;db_name\u0026gt;; 显示数据库 1 SHOW DATABASES; 切换数据库 1 USE \u0026lt;db_name\u0026gt;; 备份与恢复 备份 1 mysqldump -uroot -p\u0026lt;password\u0026gt; --log-error=/path/xxx.err -B \u0026lt;db_name\u0026gt; \u0026gt; /path/xxx.sql 恢复 1 2 3 # 如果是.zip格式需先解压，解压后后缀为.sql # 恢复整个数据库 mysql -uroot -p\u0026lt;password\u0026gt; \u0026lt;db_name\u0026gt; \u0026lt; /path/xxx.sql 数据表 创建数据表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 -- 复制已有数据库表 CREATE TABLE `new_table` AS (SELECT * FROM `old_table`); -- 直接创建数据库表 CREATE TABLE IF NOT EXISTS `table_name`( `id` INT UNSIGNED AUTO_INCREMENT, `account_id` VARCHAR(25) NOT NULL COMMENT \u0026#39;广告账户ID\u0026#39;, `account_name` VARCHAR(50), `media_source` VARCHAR(25) NOT NULL, `data_source` VARCHAR(25) NOT NULL, `created_time` TIMESTAMP NOT NULL, `account_status` VARCHAR(10), `disable_reason` VARCHAR(30), `currency` VARCHAR(3), `spend_cap` FLOAT, `amount_spent` FLOAT, `amount_remain` FLOAT, `updated_time` TIMESTAMP NOT NULL, `timezone` VARCHAR(33), PRIMARY KEY ( `id`), UNIQUE KEY ( `account_id` ) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin; 删除数据表 1 DROP TABLE \u0026lt;table_name\u0026gt;; 显示数据表 1 SHOW TABLES; 修改数据表 DELETE 1 DELETE FROM \u0026lt;table_name\u0026gt; WHERE some_condition(s); INSERT 1 INSERT INTO `users` (`email`, `password`) VALUES (%s, %s) ALTER 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 -- 新增字段 ALTER TABLE \u0026lt;table_name\u0026gt; ADD `new_int_col` INT DEFAULT 0; -- 修改字段定义 ALTER TABLE \u0026lt;table_name\u0026gt; MODIFY `old_str_col` VARCHAR(20); -- 删除 UNIQUE KEY 后并新增 SHOW KEYS FROM \u0026lt;table_name\u0026gt;; ALTER TABLE \u0026lt;table_name\u0026gt; DROP INDEX `app_name`; ALTER TABLE \u0026lt;table_name\u0026gt; ADD UNIQUE KEY (`app_name`, `os_name`, `store_type`, `channel_id`,`login_type_code`, `date_paying`, `country`, `timezone`); -- 删除字段 ALTER TABLE \u0026lt;table_name\u0026gt; DROP `days_x`; -- 新增并来源于已有字段的处理 ALTER TABLE \u0026lt;table_name\u0026gt; ADD `event_time_hour` INT; -- 日期处理 ALTER TABLE \u0026lt;table_name\u0026gt; ADD `update_time_utc` DATETIME; UPDATE 1 2 3 UPDATE \u0026lt;table_name\u0026gt; SET event_time_hour = (SELECT HOUR(`Event Time`)); UPDATE \u0026lt;table_name\u0026gt; SET minute_x = (SELECT TIMESTAMPDIFF(MINUTE, first_open_time, event_timestamp)); UPDATE \u0026lt;table_name\u0026gt; SET `update_time_utc` = (SELECT DATE_ADD(update_time, INTERVAL -8 hour)); 查询 查询结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 -- Select columns SELECT col_1, col_2, ... , col_n -- Source of data FROM table t -- Gather info from other sources optional JOIN other_table ot ON (t.key = ot.key) -- Conditions optional WHERE some_condition(s) -- Aggregating optional GROUP BY col_group_list -- Restricting aggregated values optional HAVING some_condition(s) -- Sorting values optional ORDER BY col_order_list -- Limiting number of rows optional LIMIT some_value 表连接 共包含 JOIN（左右连接）和 UNION（上下连接）两种连接方式。\nJOIN 可显示连接，也可隐式连接。前者更灵活。\n1 2 3 4 5 6 7 8 -- 方式一 explicit join FROM table_1 t1 type_of_join table_2 t2 ON t2.key = t1.key -- 方式二 implicit join FROM table_1 t1, table_2 t2 WHERE t2.key = t1.key 💡 显示连接中，当连接的两张表的所有 key 完全一致时，使用 USING 相较于 ON 更为简洁。即以下两个表达式具有相同的作用：\nON t2.key1 = t1.key1 AND t2.key2 = t1.key2\nUSING (key1, key2) 其中，常见 type_of_join 如下：\nINNER JOIN LEFT JOIN RIGHT JOIN FULL JOIN CROSS JOIN（笛卡尔连接，交叉连接） UNION 要求合并的两张表，至少有一个相同列，且自动去重。\n1 2 3 4 5 6 7 SELECT col_1 FROM table_1 UNION SELECT col_1 FROM table_2; 分组聚合 GROUP BY 1 2 3 4 5 SELECT col_1, agg_function(col_2) FROM table GROUP BY col_1; ROLLUP ROLLUP 用于在分组聚合时，包含小计和总计。\n1 2 3 4 5 6 7 SELECT col_1, col_2, agg_function(col_3) FROM table GROUP BY col_1, col_2 WITH ROLLUP; -- GROUP BY ROLLUP(col_1, col_2); ⚠️ 注意：MySQL 中无法使用以下 GROUPING SETS：\n1 2 3 4 5 6 7 GROUP BY GROUPING SETS ( (col_1, col_2), (col_1), (col_2), () ) CTE 官方手册见 Common Table Expressions\n1 2 3 4 5 6 7 8 9 WITH cte_1 AS ( SELECT ... ), cte_2 AS ( SELECT ... ) SELECT ... FROM ... 例子 1 2 3 4 5 6 7 8 WITH cte AS ( SELECT salary, RANK() OVER (ORDER BY salary DESC) AS rk FROM Employee ) SELECT * FROM cte; 其他 查看 Host 1 SELECT SUBSTRING_INDEX(host,\u0026#39;:\u0026#39;,1) AS ip , COUNT(*) FROM information_schema.processlist GROUP BY ip; 查看 Port 1 SHOW VARIABLES WHERE Variable_name = \u0026#39;port\u0026#39;; 查看用户 1 2 USE mysql; SELECT host, user, authentication_string, plugin FROM user; 函数 以下为常用函数，完整列表见 MySQL 8.0 Reference Manual\n数值函数 官方手册见 Numeric Functions and Operators\n保留小数：\nROUND(x, decimals)：四舍五入 TRUNCATE(x, decimals)：直接截取 CEILING(x)：向上取整，即 MIN({\u0026gt;=number}) FLOOR(x)：向下取整，即 MAX({\u0026lt;=number}) 数学运算：\nMOD(x, y)：求余 or x MOD y or x % y SQRT(x)：求平方根 POWER(x, y)：求 x 的 y 幂次方 练习一下 1 2 SELECT ROUND(3.1456, 2), TRUNCATE(3.1456, 2), CEILING(3.1456), FLOOR(3.1456); SELECT MOD(3, 2), SQRT(16), POWER(8, 2); 字符串函数 官方手册见 String Functions and Operators\n常用：\nLENGTH(str)：求长度 UPPER(str)：转大写 LOWER(str)：转小写 REPLACE(str, from_str, to_str)：替换 CONCAT(str1, str2, ...)：拼接 子串提取：\nLEFT(str, len)：自左边取 RIGHT(str, len)：自右边取 MID(str, pos, len)：自指定位置取 or SUBSTR(str, pos, len) or SUBSTRING(str, pos, len) 左右处理：\nLTRIM(str)：删左/头部空格 RTRIM(str)：删右/尾部空格 TRIM(str)：删左右空格 LPAD(str, len, padstr)：左填充，以达到指定长度 RPAD(str, len, padstr)：右填充，以达到指定长度 其他：\nLOCATE(substr, str)：子串第一次出现的位置。不区分大小写 or POSITION(substr IN str) REVERSE(str)：反转字符串 练习一下 1 2 3 4 5 SELECT CONCAT(\u0026#39;first_name\u0026#39;, \u0026#39; \u0026#39;, \u0026#39;last_name\u0026#39;); SELECT LPAD(\u0026#39;molly\u0026#39;, 10, \u0026#39;_\u0026#39;), RPAD(\u0026#39;molly\u0026#39;, 10, \u0026#39;_\u0026#39;); SELECT LOCATE(\u0026#39;com\u0026#39;, \u0026#39;google.com\u0026#39;), POSITION(\u0026#34;COM\u0026#34; IN \u0026#39;google.com\u0026#39;); 日期函数 官方手册见 Date and Time Functions\n获取当前日期时间：\nNOW()：返回当前日期和时间 CURDATE()：返回当前日期 or CURRENT_DATE() CURTIME()：返回当前时间 or CURRENT_TIME() 提取年月日时分秒：\nEXTRACT(unit FROM date)：通用的提取函数（建议）。详见 unit YEAR(date)：年份 QUARTER(date)：季度 MONTH(date)：月份 DAY(date)：该月份的天数 HOUR(time)：小时数 MINUTE(time)：分钟数 SECOND(time)：秒数 MONTHNAME(date)：字符串格式的月份，如 August DAYNAME(date)：字符串格式的星期数，如 Thursday 格式化：\nDATE_FORMAT(date, format)：详见 format CONVERT_TZ(dt, from_tz, to_tz)：转时区 日期运算：\nDATE_ADD(date, INTERVAL expr unit)：unit 同 EXTRACT() 函数 or DATE_SUB(date,INTERVAL -expr unit) DATEDIFF(date1, date2)：计算相差天数，注意是 date1 - date2\n⚠️ 注意，这里不同 DBMS 相差较大 练习一下 1 2 3 4 5 6 7 8 SELECT NOW(), CURDATE(), CURRENT_DATE(), CURTIME(), CURRENT_TIME(); SELECT NOW(), EXTRACT(YEAR FROM NOW()), YEAR(NOW()), QUARTER(NOW()), MONTH(NOW()), DAY(NOW()), HOUR(NOW()), MINUTE(NOW()), SECOND(NOW()), MONTHNAME(NOW()), DAYNAME(NOW()); SELECT DATE_FORMAT(NOW(), \u0026#39;%Y-%m-%d %H:%i:%s\u0026#39;), DATE_FORMAT(NOW(), \u0026#39;%W %M %d %Y %l:%i:%s %p\u0026#39;), DATE_FORMAT(NOW(), \u0026#39;%a %b %d %Y %l:%i:%s %p\u0026#39;), DATE_FORMAT(NOW(), \u0026#39;%r\u0026#39;), DATE_FORMAT(NOW(), \u0026#39;%T\u0026#39;); SELECT DATE_ADD(NOW(), INTERVAL 1 DAY), DATE_SUB(NOW(), INTERVAL -1 DAY); SELECT DATEDIFF(\u0026#39;2017-01-01\u0026#39;, \u0026#39;2016-12-24\u0026#39;); 聚合函数 官方手册见 Aggregate Functions\nMAX(expr)：求最大值 MIN(expr)：求最小值 AVG(expr)：求平均值 SUM(expr)：求和 COUNT(expr)：求次数 窗口函数 官方手册见 Window Functions\n窗口函数基于分区和排序后的查询结果的每行数据进行计算。语法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 window_function OVER ( PARTITION BY some_col ORDER BY another_col ) -- window_name SELECT val, ROW_NUMBER() OVER w AS \u0026#39;row_number\u0026#39;, RANK() OVER w AS \u0026#39;rank\u0026#39;, DENSE_RANK() OVER w AS \u0026#39;dense_rank\u0026#39; FROM numbers WINDOW w AS (ORDER BY val); SELECT DISTINCT year, country, FIRST_VALUE(year) OVER (w ORDER BY year ASC) AS first, FIRST_VALUE(year) OVER (w ORDER BY year DESC) AS last FROM sales WINDOW w AS (PARTITION BY country); 窗口函数可分为以下三类：\n聚合函数：上述 聚合函数 中的都适用；\n排序函数\nROW_NUMBER()：返回排名，如 1, 2, 3, 4, \u0026hellip; RANK()：返回排名，如 1, 2, 2, 4, \u0026hellip; DENSE_RANK()：返回排名，如 1, 2, 2, 3, \u0026hellip; NTILE(n)：分成 n 组，返回组别 PERCENT_RANK()：返回排名的百分比 计算公式：$ (rank - 1) / (rows_{分区} - 1) $ CUME_DIST()：返回值累计分布的百分比，如 top 10% 计算公式：$ rows_{小于或大于等于当前值} / rows_{分区} $ 值函数/偏移函数\nFIRST_VALUE(col)：取第一行值 LAST_VALUE(col)：取最后一行值 NTH_VALUE(col, n)：取第 n 行值 LAG(col, n, defaut)：取向前偏移 n 行的值，若不存在则取 defaut LEAD(col, n, defaut)：取向后偏移 n 行的值，若不存在则取 defaut 【宝藏】带图理解：\nHow to use Window functions in SQL Server Overview of SQL RANK functions Calculate SQL Percentile using the PERCENT_RANK function in SQL Server 控制流函数 官方手册见 Flow Control Functions 和 Comparison Functions and Operators\n说明：CASE 属于运算符且支持多条件，其余为函数。\nCASE WHEN condition THEN expr1 ELSE expr2 END CASE value WHEN compare_value THEN expr1 ELSE expr2 END IF(condition, expr1, expr2)：如果条件为真，则返回 expr1，否则返回 expr2 IFNULL(expr1, expr2)：如果 expr1 不为 null 则返回 expr1，否则返回 expr2 NULLIF(expr1, expr2)：如果相等，则返回 null，否则返回 expr1 COALESCE(expr1, expr2, ...)：返回第一个不为 null 的值，若都为 null 则返回 null\n👏 COALESCE() 很巧妙很好用，以下两个表达式具有相同的作用：\nCOALESCE(expr1, expr2, expr3) IFNULL(expr1, IFNULL(expr2, IFNULL(expr3, NULL))) 使用 CASE 解释三个异常值处理函数 IFNULL()/NULLIF()/COALESCE() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 -- IFNULL(expr1, expr2) CASE WHEN expr1 IS NOT NULL THEN expr1 ELSE expr2 END -- NULLIF(expr1, expr2) CASE WHEN expr1 = expr2 THEN NULL ELSE expr1 END -- COALESCE(expr1, expr2, expr3) CASE WHEN expr1 IS NOT NULL THEN expr1 WHEN expr2 IS NOT NULL THEN expr2 WHEN expr3 IS NOT NULL THEN expr3 ELSE NULL END 练习一下 1 2 3 4 SELECT IFNULL(1/0, \u0026#39;yes\u0026#39;), IFNULL(1/1, \u0026#39;yes\u0026#39;), IFNULL(NULL, NULL); SELECT COALESCE(NULL, 1), COALESCE(NULL, NULL, NULL), COALESCE(NULL, NULL, NULL, \u0026#39;Unknown\u0026#39;); SELECT COALESCE(1/0, 2/0, 3/1), IFNULL(1/0, IFNULL(2/0, IFNULL(3/1, NULL))); 其他函数 CAST(expr AS type)：值类型转换，详见 type，如 CHAR/SIGNED/FLOAT/DOUBLE/DATE/DATETIME 练习一下 1 SELECT CAST(3.1415 AS SIGNED); ","description":"用户及权限管理，常用数据库和数据表操作，窗口函数，表连接等。","id":60,"section":"posts","tags":["MySQL"],"title":"学习笔记：MySQL","uri":"https://mollywangup.com/posts/notes-mysql/"},{"content":"✍ 本文作为学习笔记。\n安装及配置 安装 1 2 # macOS brew install mysql 首次登录 方式一：先登录后设置密码 1 mysql -u root 1 ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026lt;password\u0026gt;; 方式二：直接登录并设置密码 1 mysqladmin -u root -p password \u0026lt;password\u0026gt; 连接数据库 命令行方式 1 2 ssh \u0026lt;sshuser\u0026gt;@\u0026lt;sshhost\u0026gt; # optional mysql -h \u0026lt;host\u0026gt; -P \u0026lt;port\u0026gt; -u \u0026lt;username\u0026gt; -p URI 方式 1 mysql://\u0026lt;username\u0026gt;:\u0026lt;password\u0026gt;@\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/\u0026lt;db_name\u0026gt; 权限管理 以下以用户wangli为例。\n新增用户 1 CREATE USER \u0026#39;wangli\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;12345678\u0026#39;; 查看权限 1 2 SHOW GRANTS FOR root@localhost; SHOW GRANTS FOR admin; 修改权限 1 2 3 4 5 6 7 8 9 10 11 -- 授权所有权限 GRANT ALL PRIVILEGES ON *.* TO \u0026#39;wangli\u0026#39;@\u0026#39;%\u0026#39;; FLUSH PRIVILEGES; -- 移除所有权限 REVOKE ALL PRIVILEGES ON *.* FROM \u0026#39;wangli\u0026#39;@\u0026#39;%\u0026#39;; FLUSH PRIVILEGES; -- 授权指定数据库 GRANT ALL PRIVILEGES ON \u0026lt;db_name\u0026gt;.* TO \u0026#39;admin\u0026#39;@\u0026#39;%\u0026#39;; FLUSH PRIVILEGES; 数据库 创建数据库 1 CREATE DATABASE \u0026lt;db_name\u0026gt;; 删除数据库 1 DROP DATABASE \u0026lt;db_name\u0026gt;; 显示数据库 1 SHOW DATABASES; 切换数据库 1 USE \u0026lt;db_name\u0026gt;; 备份与恢复 备份 1 mysqldump -uroot -p\u0026lt;password\u0026gt; --log-error=/path/xxx.err -B \u0026lt;db_name\u0026gt; \u0026gt; /path/xxx.sql 恢复 1 2 3 # 如果是.zip格式需先解压，解压后后缀为.sql # 恢复整个数据库 mysql -uroot -p\u0026lt;password\u0026gt; \u0026lt;db_name\u0026gt; \u0026lt; /path/xxx.sql 数据表 创建数据表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 -- 复制已有数据库表 CREATE TABLE `new_table` AS (SELECT * FROM `old_table`); -- 直接创建数据库表 CREATE TABLE IF NOT EXISTS `table_name`( `id` INT UNSIGNED AUTO_INCREMENT, `account_id` VARCHAR(25) NOT NULL COMMENT \u0026#39;广告账户ID\u0026#39;, `account_name` VARCHAR(50), `media_source` VARCHAR(25) NOT NULL, `data_source` VARCHAR(25) NOT NULL, `created_time` TIMESTAMP NOT NULL, `account_status` VARCHAR(10), `disable_reason` VARCHAR(30), `currency` VARCHAR(3), `spend_cap` FLOAT, `amount_spent` FLOAT, `amount_remain` FLOAT, `updated_time` TIMESTAMP NOT NULL, `timezone` VARCHAR(33), PRIMARY KEY ( `id`), UNIQUE KEY ( `account_id` ) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin; 删除数据表 1 DROP TABLE \u0026lt;table_name\u0026gt;; 显示数据表 1 SHOW TABLES; 修改数据表 DELETE 1 DELETE FROM \u0026lt;table_name\u0026gt; WHERE some_condition(s); INSERT 1 INSERT INTO `users` (`email`, `password`) VALUES (%s, %s) ALTER 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 -- 新增字段 ALTER TABLE \u0026lt;table_name\u0026gt; ADD `new_int_col` INT DEFAULT 0; -- 修改字段定义 ALTER TABLE \u0026lt;table_name\u0026gt; MODIFY `old_str_col` VARCHAR(20); -- 删除 UNIQUE KEY 后并新增 SHOW KEYS FROM \u0026lt;table_name\u0026gt;; ALTER TABLE \u0026lt;table_name\u0026gt; DROP INDEX `app_name`; ALTER TABLE \u0026lt;table_name\u0026gt; ADD UNIQUE KEY (`app_name`, `os_name`, `store_type`, `channel_id`,`login_type_code`, `date_paying`, `country`, `timezone`); -- 删除字段 ALTER TABLE \u0026lt;table_name\u0026gt; DROP `days_x`; -- 新增并来源于已有字段的处理 ALTER TABLE \u0026lt;table_name\u0026gt; ADD `event_time_hour` INT; -- 日期处理 ALTER TABLE \u0026lt;table_name\u0026gt; ADD `update_time_utc` DATETIME; UPDATE 1 2 3 UPDATE \u0026lt;table_name\u0026gt; SET event_time_hour = (SELECT HOUR(`Event Time`)); UPDATE \u0026lt;table_name\u0026gt; SET minute_x = (SELECT TIMESTAMPDIFF(MINUTE, first_open_time, event_timestamp)); UPDATE \u0026lt;table_name\u0026gt; SET `update_time_utc` = (SELECT DATE_ADD(update_time, INTERVAL -8 hour)); 查询 查询结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 -- Select columns SELECT col_1, col_2, ... , col_n -- Source of data FROM table t -- Gather info from other sources optional JOIN other_table ot ON (t.key = ot.key) -- Conditions optional WHERE some_condition(s) -- Aggregating optional GROUP BY col_group_list -- Restricting aggregated values optional HAVING some_condition(s) -- Sorting values optional ORDER BY col_order_list -- Limiting number of rows optional LIMIT some_value 表连接 共包含 JOIN（左右连接）和 UNION（上下连接）两种连接方式。\nJOIN 可显示连接，也可隐式连接。前者更灵活。\n1 2 3 4 5 6 7 8 -- 方式一 explicit join FROM table_1 t1 type_of_join table_2 t2 ON t2.key = t1.key -- 方式二 implicit join FROM table_1 t1, table_2 t2 WHERE t2.key = t1.key 💡 显示连接中，当连接的两张表的所有 key 完全一致时，使用 USING 相较于 ON 更为简洁。即以下两个表达式具有相同的作用：\nON t2.key1 = t1.key1 AND t2.key2 = t1.key2\nUSING (key1, key2) 其中，常见 type_of_join 如下：\nINNER JOIN LEFT JOIN RIGHT JOIN FULL JOIN CROSS JOIN（笛卡尔连接，交叉连接） UNION 要求合并的两张表，至少有一个相同列，且自动去重。\n1 2 3 4 5 6 7 SELECT col_1 FROM table_1 UNION SELECT col_1 FROM table_2; 分组聚合 GROUP BY 1 2 3 4 5 SELECT col_1, agg_function(col_2) FROM table GROUP BY col_1; ROLLUP ROLLUP 用于在分组聚合时，包含小计和总计。\n1 2 3 4 5 6 7 SELECT col_1, col_2, agg_function(col_3) FROM table GROUP BY col_1, col_2 WITH ROLLUP; -- GROUP BY ROLLUP(col_1, col_2); ⚠️ 注意：MySQL 中无法使用以下 GROUPING SETS：\n1 2 3 4 5 6 7 GROUP BY GROUPING SETS ( (col_1, col_2), (col_1), (col_2), () ) CTE 官方手册见 Common Table Expressions\n1 2 3 4 5 6 7 8 9 WITH cte_1 AS ( SELECT ... ), cte_2 AS ( SELECT ... ) SELECT ... FROM ... 例子 1 2 3 4 5 6 7 8 WITH cte AS ( SELECT salary, RANK() OVER (ORDER BY salary DESC) AS rk FROM Employee ) SELECT * FROM cte; 其他 查看 Host 1 SELECT SUBSTRING_INDEX(host,\u0026#39;:\u0026#39;,1) AS ip , COUNT(*) FROM information_schema.processlist GROUP BY ip; 查看 Port 1 SHOW VARIABLES WHERE Variable_name = \u0026#39;port\u0026#39;; 查看用户 1 2 USE mysql; SELECT host, user, authentication_string, plugin FROM user; 函数 以下为常用函数，完整列表见 MySQL 8.0 Reference Manual\n数值函数 官方手册见 Numeric Functions and Operators\n保留小数：\nROUND(x, decimals)：四舍五入 TRUNCATE(x, decimals)：直接截取 CEILING(x)：向上取整，即 MIN({\u0026gt;=number}) FLOOR(x)：向下取整，即 MAX({\u0026lt;=number}) 数学运算：\nMOD(x, y)：求余 or x MOD y or x % y SQRT(x)：求平方根 POWER(x, y)：求 x 的 y 幂次方 练习一下 1 2 SELECT ROUND(3.1456, 2), TRUNCATE(3.1456, 2), CEILING(3.1456), FLOOR(3.1456); SELECT MOD(3, 2), SQRT(16), POWER(8, 2); 字符串函数 官方手册见 String Functions and Operators\n常用：\nLENGTH(str)：求长度 UPPER(str)：转大写 LOWER(str)：转小写 REPLACE(str, from_str, to_str)：替换 CONCAT(str1, str2, ...)：拼接 子串提取：\nLEFT(str, len)：自左边取 RIGHT(str, len)：自右边取 MID(str, pos, len)：自指定位置取 or SUBSTR(str, pos, len) or SUBSTRING(str, pos, len) 左右处理：\nLTRIM(str)：删左/头部空格 RTRIM(str)：删右/尾部空格 TRIM(str)：删左右空格 LPAD(str, len, padstr)：左填充，以达到指定长度 RPAD(str, len, padstr)：右填充，以达到指定长度 其他：\nLOCATE(substr, str)：子串第一次出现的位置。不区分大小写 or POSITION(substr IN str) REVERSE(str)：反转字符串 练习一下 1 2 3 4 5 SELECT CONCAT(\u0026#39;first_name\u0026#39;, \u0026#39; \u0026#39;, \u0026#39;last_name\u0026#39;); SELECT LPAD(\u0026#39;molly\u0026#39;, 10, \u0026#39;_\u0026#39;), RPAD(\u0026#39;molly\u0026#39;, 10, \u0026#39;_\u0026#39;); SELECT LOCATE(\u0026#39;com\u0026#39;, \u0026#39;google.com\u0026#39;), POSITION(\u0026#34;COM\u0026#34; IN \u0026#39;google.com\u0026#39;); 日期函数 官方手册见 Date and Time Functions\n获取当前日期时间：\nNOW()：返回当前日期和时间 CURDATE()：返回当前日期 or CURRENT_DATE() CURTIME()：返回当前时间 or CURRENT_TIME() 提取年月日时分秒：\nEXTRACT(unit FROM date)：通用的提取函数（建议）。详见 unit YEAR(date)：年份 QUARTER(date)：季度 MONTH(date)：月份 DAY(date)：该月份的天数 HOUR(time)：小时数 MINUTE(time)：分钟数 SECOND(time)：秒数 MONTHNAME(date)：字符串格式的月份，如 August DAYNAME(date)：字符串格式的星期数，如 Thursday 格式化：\nDATE_FORMAT(date, format)：详见 format CONVERT_TZ(dt, from_tz, to_tz)：转时区 日期运算：\nDATE_ADD(date, INTERVAL expr unit)：unit 同 EXTRACT() 函数 or DATE_SUB(date,INTERVAL -expr unit) DATEDIFF(date1, date2)：计算相差天数，注意是 date1 - date2\n⚠️ 注意，这里不同 DBMS 相差较大 练习一下 1 2 3 4 5 6 7 8 SELECT NOW(), CURDATE(), CURRENT_DATE(), CURTIME(), CURRENT_TIME(); SELECT NOW(), EXTRACT(YEAR FROM NOW()), YEAR(NOW()), QUARTER(NOW()), MONTH(NOW()), DAY(NOW()), HOUR(NOW()), MINUTE(NOW()), SECOND(NOW()), MONTHNAME(NOW()), DAYNAME(NOW()); SELECT DATE_FORMAT(NOW(), \u0026#39;%Y-%m-%d %H:%i:%s\u0026#39;), DATE_FORMAT(NOW(), \u0026#39;%W %M %d %Y %l:%i:%s %p\u0026#39;), DATE_FORMAT(NOW(), \u0026#39;%a %b %d %Y %l:%i:%s %p\u0026#39;), DATE_FORMAT(NOW(), \u0026#39;%r\u0026#39;), DATE_FORMAT(NOW(), \u0026#39;%T\u0026#39;); SELECT DATE_ADD(NOW(), INTERVAL 1 DAY), DATE_SUB(NOW(), INTERVAL -1 DAY); SELECT DATEDIFF(\u0026#39;2017-01-01\u0026#39;, \u0026#39;2016-12-24\u0026#39;); 聚合函数 官方手册见 Aggregate Functions\nMAX(expr)：求最大值 MIN(expr)：求最小值 AVG(expr)：求平均值 SUM(expr)：求和 COUNT(expr)：求次数 窗口函数 官方手册见 Window Functions\n窗口函数基于分区和排序后的查询结果的每行数据进行计算。语法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 window_function OVER ( PARTITION BY some_col ORDER BY another_col ) -- window_name SELECT val, ROW_NUMBER() OVER w AS \u0026#39;row_number\u0026#39;, RANK() OVER w AS \u0026#39;rank\u0026#39;, DENSE_RANK() OVER w AS \u0026#39;dense_rank\u0026#39; FROM numbers WINDOW w AS (ORDER BY val); SELECT DISTINCT year, country, FIRST_VALUE(year) OVER (w ORDER BY year ASC) AS first, FIRST_VALUE(year) OVER (w ORDER BY year DESC) AS last FROM sales WINDOW w AS (PARTITION BY country); 窗口函数可分为以下三类：\n聚合函数：上述 聚合函数 中的都适用；\n排序函数\nROW_NUMBER()：返回排名，如 1, 2, 3, 4, \u0026hellip; RANK()：返回排名，如 1, 2, 2, 4, \u0026hellip; DENSE_RANK()：返回排名，如 1, 2, 2, 3, \u0026hellip; NTILE(n)：分成 n 组，返回组别 PERCENT_RANK()：返回排名的百分比 计算公式：$ (rank - 1) / (rows_{分区} - 1) $ CUME_DIST()：返回值累计分布的百分比，如 top 10% 计算公式：$ rows_{小于或大于等于当前值} / rows_{分区} $ 值函数/偏移函数\nFIRST_VALUE(col)：取第一行值 LAST_VALUE(col)：取最后一行值 NTH_VALUE(col, n)：取第 n 行值 LAG(col, n, defaut)：取向前偏移 n 行的值，若不存在则取 defaut LEAD(col, n, defaut)：取向后偏移 n 行的值，若不存在则取 defaut 【宝藏】带图理解：\nHow to use Window functions in SQL Server Overview of SQL RANK functions Calculate SQL Percentile using the PERCENT_RANK function in SQL Server 控制流函数 官方手册见 Flow Control Functions 和 Comparison Functions and Operators\n说明：CASE 属于运算符且支持多条件，其余为函数。\nCASE WHEN condition THEN expr1 ELSE expr2 END CASE value WHEN compare_value THEN expr1 ELSE expr2 END IF(condition, expr1, expr2)：如果条件为真，则返回 expr1，否则返回 expr2 IFNULL(expr1, expr2)：如果 expr1 不为 null 则返回 expr1，否则返回 expr2 NULLIF(expr1, expr2)：如果相等，则返回 null，否则返回 expr1 COALESCE(expr1, expr2, ...)：返回第一个不为 null 的值，若都为 null 则返回 null\n👏 COALESCE() 很巧妙很好用，以下两个表达式具有相同的作用：\nCOALESCE(expr1, expr2, expr3) IFNULL(expr1, IFNULL(expr2, IFNULL(expr3, NULL))) 使用 CASE 解释三个异常值处理函数 IFNULL()/NULLIF()/COALESCE() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 -- IFNULL(expr1, expr2) CASE WHEN expr1 IS NOT NULL THEN expr1 ELSE expr2 END -- NULLIF(expr1, expr2) CASE WHEN expr1 = expr2 THEN NULL ELSE expr1 END -- COALESCE(expr1, expr2, expr3) CASE WHEN expr1 IS NOT NULL THEN expr1 WHEN expr2 IS NOT NULL THEN expr2 WHEN expr3 IS NOT NULL THEN expr3 ELSE NULL END 练习一下 1 2 3 4 SELECT IFNULL(1/0, \u0026#39;yes\u0026#39;), IFNULL(1/1, \u0026#39;yes\u0026#39;), IFNULL(NULL, NULL); SELECT COALESCE(NULL, 1), COALESCE(NULL, NULL, NULL), COALESCE(NULL, NULL, NULL, \u0026#39;Unknown\u0026#39;); SELECT COALESCE(1/0, 2/0, 3/1), IFNULL(1/0, IFNULL(2/0, IFNULL(3/1, NULL))); 其他函数 CAST(expr AS type)：值类型转换，详见 type，如 CHAR/SIGNED/FLOAT/DOUBLE/DATE/DATETIME 练习一下 1 SELECT CAST(3.1415 AS SIGNED); ","description":"用户及权限管理，常用数据库和数据表操作，窗口函数，表连接等。","id":61,"section":"zh","tags":["MySQL"],"title":"学习笔记：MySQL","uri":"https://mollywangup.com/zh/posts/notes-mysql/"},{"content":"无论哪个广告平台，数据抓取整体可概括为以下两步：\n申请接口；（访问令牌/密钥文件） 通过接口请求数据； Facebook Ads 每个 BM 对应一个访问令牌，访问令牌由该 BM 下管理员权限的 system_user 生成，只要授权给该 system_user 的广告账户，其数据都可以通过该访问令牌请求。\n接口申请方法 在 Facebook 开发者后台，创建一个 Business 类型的应用： 方法见 Create an app ； 在 BM 创建一个管理员权限的 system_user： 方法见 Create, Retrieve and Update a System User； 将上述应用绑定至 BM，注意该 BM 需要作为该应用的所有者； 在 BM 中，使用 system_user 生成 access_token 即访问令牌，其中： 点击生成按钮时，必须选择上述创建的那个应用； 勾选数据权限时，必须至少包含以下两个权限： ads_read ads_management Facebook Ads 接口举例 1 2 3 4 5 6 7 8 9 data_source: business_id: business_name: app_id: your_app_id # 必配置项；Facebook app ID app_name: app_secret: your_app_secret # 必配置项；Facebook app secret system_user_id: system_user_name: system_user_access_token: your_access_token # 必配置项；访问令牌 只有已授权给 system_user 的广告账户，访问令牌才能访问到对应广告账户的数据； 每个 BM 对应一个访问令牌，有几个 BM 就需要申请几个访问令牌； 官方文档 [Facebook] Marketing API [GitHub] Facebook Business SDK for Python Google Ads 接口申请方法 见官方保姆级教程 Google Ads API快速上手指南 [2019]\nGoogle Ads 接口举例 1 2 3 4 5 6 7 data_source: manager_account: developer_token: your_developer_token # 必配置项； user_agent: client_id: your_client_id # 必配置项； client_secret: your_client_secret # 必配置项； refresh_token: your_refresh_token # 必配置项； 官方文档 [Google] Google Ads API Apple Search Ads 接口申请方法 接口是物理的文件形式的密钥，见官方保姆级教程 Implementing OAuth for the Apple Search Ads API\n官方文档 [Apple] Apple Search Ads API 附：指标字典参考 编号 字段 定义 数据类型 数据来源 1 app_name App标识 varchar 通过AdSet层级的AdPromotedObject对象的object_store_url或者application_id间接获得 2 os_name 设备类型，如android/ios varchar 同上 3 store_type 应用商店 varchar 同上 4 media_source 流量来源 varchar 通过 Token 配置进行判断 5 account_id 广告账户ID varchar API 6 account_name 广告账户名称 varchar API 7 campaign_id 广告推广计划ID varchar API 8 campaign_name 广告推广计划名称 varchar API 9 date 日期 date API 10 country 国家，ISO 3166标准 varchar API 11 impressions 广告展示量 int API 12 clicks 广告点击量 int API 13 install 广告安装量 int API 14 cost 广告花费 float API 15 purchase_value 广告带来的收入 float API 16 purchase 付费次数 int API 17 purchase_unique 付费人数 int API 18 optimizer 优化师编号 varchar 通过正则 19 data_source 所属BM/MCC varchar 通过 Token 配置 20 currency 币种单位，需要统一为 USD varchar API 21 is_organic 布尔值 varchar 通过映射配置 22 attribution_setting 归因窗口设置 varchar API ","description":"Facebook Ads/Google Ads/Apple Search Ads.","id":62,"section":"posts","tags":["Facebook Ads","Google Ads","Apple Search Ads"],"title":"广告数据抓取方法论","uri":"https://mollywangup.com/posts/ad-insights-api/"},{"content":"无论哪个广告平台，数据抓取整体可概括为以下两步：\n申请接口；（访问令牌/密钥文件） 通过接口请求数据； Facebook Ads 每个 BM 对应一个访问令牌，访问令牌由该 BM 下管理员权限的 system_user 生成，只要授权给该 system_user 的广告账户，其数据都可以通过该访问令牌请求。\n接口申请方法 在 Facebook 开发者后台，创建一个 Business 类型的应用： 方法见 Create an app ； 在 BM 创建一个管理员权限的 system_user： 方法见 Create, Retrieve and Update a System User； 将上述应用绑定至 BM，注意该 BM 需要作为该应用的所有者； 在 BM 中，使用 system_user 生成 access_token 即访问令牌，其中： 点击生成按钮时，必须选择上述创建的那个应用； 勾选数据权限时，必须至少包含以下两个权限： ads_read ads_management Facebook Ads 接口举例 1 2 3 4 5 6 7 8 9 data_source: business_id: business_name: app_id: your_app_id # 必配置项；Facebook app ID app_name: app_secret: your_app_secret # 必配置项；Facebook app secret system_user_id: system_user_name: system_user_access_token: your_access_token # 必配置项；访问令牌 只有已授权给 system_user 的广告账户，访问令牌才能访问到对应广告账户的数据； 每个 BM 对应一个访问令牌，有几个 BM 就需要申请几个访问令牌； 官方文档 [Facebook] Marketing API [GitHub] Facebook Business SDK for Python Google Ads 接口申请方法 见官方保姆级教程 Google Ads API快速上手指南 [2019]\nGoogle Ads 接口举例 1 2 3 4 5 6 7 data_source: manager_account: developer_token: your_developer_token # 必配置项； user_agent: client_id: your_client_id # 必配置项； client_secret: your_client_secret # 必配置项； refresh_token: your_refresh_token # 必配置项； 官方文档 [Google] Google Ads API Apple Search Ads 接口申请方法 接口是物理的文件形式的密钥，见官方保姆级教程 Implementing OAuth for the Apple Search Ads API\n官方文档 [Apple] Apple Search Ads API 附：指标字典参考 编号 字段 定义 数据类型 数据来源 1 app_name App标识 varchar 通过AdSet层级的AdPromotedObject对象的object_store_url或者application_id间接获得 2 os_name 设备类型，如android/ios varchar 同上 3 store_type 应用商店 varchar 同上 4 media_source 流量来源 varchar 通过 Token 配置进行判断 5 account_id 广告账户ID varchar API 6 account_name 广告账户名称 varchar API 7 campaign_id 广告推广计划ID varchar API 8 campaign_name 广告推广计划名称 varchar API 9 date 日期 date API 10 country 国家，ISO 3166标准 varchar API 11 impressions 广告展示量 int API 12 clicks 广告点击量 int API 13 install 广告安装量 int API 14 cost 广告花费 float API 15 purchase_value 广告带来的收入 float API 16 purchase 付费次数 int API 17 purchase_unique 付费人数 int API 18 optimizer 优化师编号 varchar 通过正则 19 data_source 所属BM/MCC varchar 通过 Token 配置 20 currency 币种单位，需要统一为 USD varchar API 21 is_organic 布尔值 varchar 通过映射配置 22 attribution_setting 归因窗口设置 varchar API ","description":"Facebook Ads/Google Ads/Apple Search Ads.","id":63,"section":"zh","tags":["Facebook Ads","Google Ads","Apple Search Ads"],"title":"广告数据抓取方法论","uri":"https://mollywangup.com/zh/posts/ad-insights-api/"}]