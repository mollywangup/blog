<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>S3 on Molly's Blog</title><link>https://mollywangup.com/tags/s3/</link><description>Recent content in S3 on Molly's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh</language><managingEditor>mollywangup@gmail.com (Molly Wang)</managingEditor><webMaster>mollywangup@gmail.com (Molly Wang)</webMaster><copyright>©2025, All content is licensed under<a target="_blank" rel="external noopener" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.</copyright><lastBuildDate>Fri, 30 Jun 2023 07:37:04 +0000</lastBuildDate><atom:link href="https://mollywangup.com/tags/s3/index.xml" rel="self" type="application/rss+xml"/><item><title>踩坑：Druid + S3 批量摄取任务中的各种报错</title><link>https://mollywangup.com/posts/troubleshooting-druid-batch-ingestion-task/</link><pubDate>Fri, 30 Jun 2023 07:37:04 +0000</pubDate><author>mollywangup@gmail.com (Molly Wang)</author><atom:modified>Fri, 30 Jun 2023 07:37:04 +0000</atom:modified><guid>https://mollywangup.com/posts/troubleshooting-druid-batch-ingestion-task/</guid><description>背景信息 Apache Druid: 26.0.0 Batch ingestion task informations: SQL-based ingestion S3 input source Duplicate column entries found 详细报错 1 2 3 4 { &amp;#34;errorCode&amp;#34;: &amp;#34;CannotParseExternalData&amp;#34;, &amp;#34;errorMessage&amp;#34;: &amp;#34;Duplicate column entries found : [0, Facebook]&amp;#34; } 解决方案 Druid 属于列式存储，出现此问题的根本原因是，存在名称相同</description><dc:creator>Molly Wang</dc:creator><category>Apache Druid</category><category>S3</category><category>Troubleshooting</category></item><item><title>BI 方案：Adjust + S3 + Druid + Superset</title><link>https://mollywangup.com/posts/bi-solution-adjust-s3-druid-superset/</link><pubDate>Sun, 07 May 2023 16:03:28 +0000</pubDate><author>mollywangup@gmail.com (Molly Wang)</author><atom:modified>Sun, 07 May 2023 16:03:28 +0000</atom:modified><guid>https://mollywangup.com/posts/bi-solution-adjust-s3-druid-superset/</guid><description>🙇‍♀️ 本文是个文章地图索引。 本文旨在将来自 Adjust 的原始数据可视化在 Superset. 其中，不同的工具分工如下： Adjust： MMP； 用于收集原始数据； S3： 云</description><dc:creator>Molly Wang</dc:creator><category>Adjust</category><category>S3</category><category>Apache Druid</category><category>Apache Superset</category><category>BI</category><category>OLAP</category><category>MMP</category></item><item><title>使用 Druid SQL-based ingestion 批量摄取 S3 数据</title><link>https://mollywangup.com/posts/ingest-s3-data-with-druid-sql-based-ingestion-task/</link><pubDate>Sun, 16 Apr 2023 02:38:06 +0000</pubDate><author>mollywangup@gmail.com (Molly Wang)</author><atom:modified>Sun, 16 Apr 2023 02:38:06 +0000</atom:modified><guid>https://mollywangup.com/posts/ingest-s3-data-with-druid-sql-based-ingestion-task/</guid><description>本文旨在将来自 S3 的 .csv.gz 数据，批量摄取至 Druid. 其中： Apache Druid: 26.0.0 参考文档： SQL-based ingestion S3 input source REPLACE all data 1 2 3 4 5 REPLACE INTO &amp;lt;target table&amp;gt; OVERWRITE ALL &amp;lt; SELECT query &amp;gt; PARTITIONED BY &amp;lt;time granularity&amp;gt; [ CLUSTERED BY &amp;lt;column list&amp;gt; ] REPLACE specific time ranges 1 2 3</description><dc:creator>Molly Wang</dc:creator><category>Apache Druid</category><category>S3</category><category>OLAP</category></item></channel></rss>